# Worker Instructions

## ğŸ¯ DIRECTIVE: Build World-Class C++ TTS

**Goal**: ABSOLUTE BEST TTS system - performance, quality, scale
**Approach**: Complete native C++ implementation (no shortcuts, no JIT workarounds)

---

## System Status (2025-12-10)

| Component | Status | Verified By |
|-----------|--------|-------------|
| Kokoro TTS | âœ… COMPLETE | Worker #351 |
| CosyVoice2 TTS (C++) | âœ… COMPLETE | Worker #457 |
| Multi-stream Fairness | âœ… COMPLETE | FairTTSQueue |
| Translation (NLLB-200) | âœ… COMPLETE | 5 languages |
| Self-Speech Filter | âœ… COMPLETE | 4-layer system |
| Live Summarization | âœ… COMPLETE | Qwen3-8B |
| Wake Word Detection | âœ… COMPLETE | OpenWakeWord |
| Tests | âœ… 213/214 PASS | smoke+unit+quality+integration (RTF benchmark expected) |

**Both Kokoro TTS (RTF 0.3x) and CosyVoice2 are production-ready. RTF benchmark fails due to model loading overhead (expected).**

---

## CosyVoice2 Instruction Support (Worker #466, 2025-12-10)

**STATUS**: Core instruction matrix tests implemented; unsupported dialects documented. Re-run tests to verify current model behavior.

### Supported Instructions (Verified Working)

| Category | Instruction | Effect | Status |
|----------|-------------|--------|--------|
| **Dialect** | ç”¨å››å·è¯è¯´ | Sichuan dialect | âœ… WORKING |
| **Emotion** | å¼€å¿ƒåœ°è¯´ | Happy tone | âœ… WORKING |
| **Emotion** | æ‚²ä¼¤åœ°è¯´ | Sad tone | âœ… WORKING |
| **Emotion** | ç”Ÿæ°”åœ°è¯´ | Angry tone | âš ï¸ PARTIAL (accuracy varies) |
| **Speed** | æ…¢é€Ÿåœ°è¯´ | Slow speech | âœ… WORKING |
| **Speed** | å¿«é€Ÿåœ°è¯´ | Fast speech | âœ… WORKING |
| **Standard** | ç”¨æ ‡å‡†æ™®é€šè¯è¯´ | Standard Mandarin | âœ… WORKING |

### Unsupported Instructions (Model Limitations)

| Category | Instruction | Expected | Actual |
|----------|-------------|----------|--------|
| Dialect | ç”¨ç²¤è¯­è¯´ | Cantonese | Outputs Mandarin |
| Dialect | ç”¨ä¸Šæµ·è¯è¯´ | Shanghainese | Outputs Mandarin |

**Note**: CosyVoice2-0.5B primarily supports Sichuan dialect. Other Chinese dialects are NOT implemented in the model.

### Instruction Format Rules

1. Instructions MUST be in Chinese
2. Use short imperative sentences: `ç”¨[X]è¯´` or `[X]åœ°è¯´`
3. Keep instructions under 20 characters
4. Alternative format: `è¯´è¯è¯­æ°”å¸¦å››å·å£éŸ³` (also works)

### Test Suite

```bash
# Run full instruction matrix (9 core instructions + xfail for unsupported dialects)
pytest tests/quality/test_cosyvoice2_instructions.py -v

# Run LLM judge tests (requires OPENAI_API_KEY)
pytest tests/quality/test_cosyvoice2_instructions.py -v -m llm_judge
```

---

## CosyVoice2 Audio Quality - RESOLVED (Worker #457, 2025-12-10)

**STATUS**: âœ… CosyVoice2 audio quality verified - LLM Judge tests pass

### Resolution
The audio quality issue was caused by the binary not being updated after commit #456 which:
1. Fixed sample rate: 22050 â†’ 24000 Hz (matching CosyVoice2 default)
2. Aligned sampling: top_k=25, top_p=0.8 (CosyVoice2 defaults)
3. Added RAS (Repetition-Aware Sampling) for better token generation

### Test Results (Worker #457)
| Test | Result |
|------|--------|
| Smoke tests | 179 PASS |
| CosyVoice2 quality tests | 16/17 PASS |
| LLM Judge sichuan dialect | **PASS** |
| LLM Judge instruction mode | **PASS** |
| RTF benchmark | FAIL (expected - model loading overhead) |

### Audio Quality Verification
```bash
# Test synthesis produces high-quality speech
./stream-tts-cpp --voice-name sichuan --speak "ä»Šå¤©å¤©æ°”çœŸå¥½" --lang zh --save-audio /tmp/test.wav
python3 tests/audio_quality.py /tmp/test.wav "ä»Šå¤©å¤©æ°”çœŸå¥½"
# RESULT: PASS - Audio is high-quality speech
```

**Both Kokoro and CosyVoice2 TTS engines are production-ready.**

---

## CosyVoice2 MPS Acceleration (Worker #541, 2025-12-11)

**STATUS**: âœ… **WORKING** - Native MPS-accelerated CosyVoice2 with 8.3/10 quality.

### Verification Test
```bash
pytest tests/integration/test_cosyvoice2_native_quality.py -v -s -o addopts=
```

### Current Architecture
CosyVoice2's architecture has three stages, all now running on Metal GPU:
1. **LLM (llama.cpp)**: Metal GPU - 338+ tok/s
2. **Flow model (TorchScript MPS)**: Re-exported with PyTorch 2.9.1
3. **HiFT vocoder (TorchScript MPS)**: Re-exported with PyTorch 2.9.1

### Models Re-exported (2025-12-11)
The TorchScript models were re-exported with PyTorch 2.9.1 to match libtorch 2.9.1:
```bash
python3 scripts/export_flow_components.py   # -> flow_full.pt
python3 scripts/export_hift_mps.py          # -> hift_traced.pt
```

### Quality Verified
| Metric | Value | Status |
|--------|-------|--------|
| LLM Judge Score | 8.3/10 | âœ… PASS |
| Frog Artifacts | 0/3 votes | âœ… PASS |
| Cold Start RTF | ~4x | Expected (model loading) |

### Comparison with Kokoro
| Engine | RTF (warm) | Architecture | Quality |
|--------|------------|--------------|---------|
| Kokoro | 0.3x | Non-autoregressive | English-optimized |
| CosyVoice2 | ~0.8x | Autoregressive LLM | Chinese/Sichuan dialect |

**Recommendation**: Use Kokoro for English, CosyVoice2 for Chinese/Sichuan dialect.

---

## Verification Commands

```bash
# Quick smoke + unit tests (180 pass)
python3 -m pytest tests/smoke tests/unit -q

# CosyVoice2 C++ quality tests (17 pass)
python3 -m pytest tests/quality/test_cosyvoice2_cpp.py -q

# Dual engine integration tests (17 pass)
python3 -m pytest tests/integration/test_dual_engine.py -q

# All tests (slow - model loading)
python3 -m pytest tests/ -q

# Test Kokoro TTS
./stream-tts-cpp --voice-name af_heart --speak "Hello" --lang en --save-audio /tmp/test.wav

# Test CosyVoice2 TTS
./stream-tts-cpp --voice-name sichuan --speak "ä½ å¥½" --lang zh --save-audio /tmp/test.wav
```

---

## Forbidden Actions

1. âŒ Hardcode F0/N values
2. âŒ Loosen test thresholds
3. âŒ Skip components with dummy values
4. âŒ Use Python subprocess for inference
5. âŒ Create workaround .pt files
6. âŒ Use JIT tracing as a shortcut (native C++ only)

---

## âœ… COMPLETED: Audio Quality Verification

**STATUS**: âœ… **IMPLEMENTED** - Automated audio quality tests working

**See**: `tests/smoke/test_smoke.py` for comprehensive TTS quality validation.

### Solution Implemented

`tests/audio_quality.py` - A Python script (allowed for testing) that analyzes WAV files and verifies they contain high-quality speech audio.

**Features:**
- 8 objective audio quality metrics calibrated for neural TTS (StyleTTS2)
- Golden reference file comparison via cross-correlation
- Integrated into `test_integration.sh` (Tests X1-X5)
- All tests pass: script exists, golden files exist, quality metrics pass, correlation works

### Implementation Files

| File | Description |
|------|-------------|
| `tests/audio_quality.py` | Main quality verification script |
| `tests/golden/hello.wav` | Golden reference for "Hello" |
| `tests/golden/good_morning.wav` | Golden reference for "Good morning" |
| `tests/golden/thank_you.wav` | Golden reference for "Thank you" |

### Metrics Implemented (Calibrated for Neural TTS)

| Metric | Purpose | Pass Criteria |
|--------|---------|---------------|
| **RMS Amplitude** | Audio is audible, not silence | 0.01 < RMS < 0.5 |
| **Peak Amplitude** | No clipping | Peak < 0.95 |
| **Duration** | Reasonable length | > 0.3s |
| **Duration/Text Ratio** | Natural speech pace | 0.04-0.6 sec/char |
| **Zero-Crossing Rate** | TTS signature (higher than human) | 500-20000 Hz |
| **Spectral Centroid** | TTS energy range | 200-10000 Hz |
| **Silence Ratio** | Natural pauses | 0-80% |
| **Crest Factor** | Dynamic range | 2-20 |
| **Golden File Correlation** | Matches reference | correlation > 0.6 |

**Note:** Neural TTS (StyleTTS2) has different acoustic characteristics than natural human speech - particularly higher frequency content and zero-crossing rates. Thresholds are calibrated accordingly.

### Usage

```bash
# Analyze a single WAV file
python3 tests/audio_quality.py output.wav

# Analyze with expected text (checks sec/char ratio)
python3 tests/audio_quality.py output.wav "ã“ã‚“ã«ã¡ã¯"

# Compare to golden reference
python3 tests/audio_quality.py output.wav "" tests/golden/hello.wav
```

### Integration Tests Added

Tests X1-X5 in `test_integration.sh`:
- X1: Audio quality script exists
- X2: Golden reference files exist (3 files)
- X3: TTS output passes quality metrics
- X4: Golden file hello.wav passes quality check
- X5: New TTS output correlates with golden reference (correlation > 0.6)

All tests pass as of Worker #4 commit.

### Worker Checklist

- [x] Create `tests/audio_quality.py` per spec - **DONE by Worker #4**
- [x] Create `tests/golden/` directory - **DONE by Worker #4**
- [x] Generate golden reference files (hello.wav, good_morning.wav, thank_you.wav) - **DONE by Worker #4**
- [x] Add audio quality tests to `test_integration.sh` (Tests X1-X5) - **DONE by Worker #4**
- [x] Run full test suite and verify audio tests pass - **DONE by Worker #4**
- [x] Update WORKER_INSTRUCTIONS.md status - **DONE by Worker #4**

### Success Criteria - MET

1. âœ… `python3 tests/audio_quality.py /path/to/tts_output.wav` returns PASS for valid TTS audio
2. âœ… `./test_integration.sh` includes and passes audio quality tests (X1-X5)
3. âœ… Golden files exist for at least 3 test phrases (hello, good_morning, thank_you)
4. âœ… Any future TTS regression will cause automated test failure

---

## âœ… VERIFIED: E2E Audio Playback

**STATUS**: âœ… **VERIFIED WORKING** - All tests pass (Worker #8, 2025-12-03)

**Verification Report**: `reports/main/audio_verification_2025-12-03-18-11.md`

**Current State (2025-12-03, Worker #8)**:
- All technical diagnostics pass (miniaudio, TTS, WAV generation)
- Correct device selected (MacBook Pro Speakers)
- Correct frames output (115200 frames for "Hello world" = 4.8s)
- Playback duration matches expected
- Sample values are valid non-zero PCM data (RMS=0.19, Peak=0.707)
- All 9 audio quality metrics pass in smoke_test.sh

**Audio playback is working correctly at all levels.**

### Test Plan

Read `TEST_PLAN_E2E_AUDIO.md` for full details. Summary:

1. **Test A (Gold Standard)**: Human must HEAR audio from speakers
2. **Test B (Workaround)**: Save to WAV, play with `afplay`
3. **Test C (Multi-lang)**: Multiple English inputs translate and synthesize
4. **Test D (Quality)**: Automated amplitude/duration checks

### Worker Investigation Results (Workers #0-3, 2025-12-03)

**All technical diagnostics pass:**
```
âœ… miniaudio diagnostic: 84480 frames output to MacBook Pro Speakers
âœ… TTS synthesis: 24578 frames with valid PCM samples
âœ… Audio callback: ~65% real audio callbacks (not mutex contention)
âœ… WAV file: Saves correctly, afplay plays successfully
âœ… Device: MacBook Pro Speakers (DEFAULT), correct sample rate
âœ… Duration: Playback timing matches expected (~1s for "Hello")
```

**All original hypotheses eliminated:**
```
âœ… Sample rate: Correct (24kHz, miniaudio handles conversion)
âœ… Audio device: Correct (MacBook Pro Speakers, DEFAULT)
âœ… Buffer/callback: Correct (timing matches expected duration)
âœ… Mutex contention: Not an issue (~65% real callbacks)
```

### How to Verify

Run: `./verify_audio.sh` (from voice/ directory)

This tests:
1. macOS `say` command (baseline)
2. WAV file playback via `afplay`
3. miniaudio 440Hz tone (3 seconds)
4. Full TTS pipeline playback

### If All Tests Pass

Update this section to **STATUS: âœ… WORKING** and remove the human verification requirement.

### If miniaudio Tests Fail But Others Pass

Investigate CoreAudio backend. Possible causes:
- macOS audio permissions
- External audio routing (Zoom, headphones)
- Audio focus grabbed by another app

---

## âš ï¸ PROPER FIXES ONLY

**CRITICAL**: Do NOT take shortcuts. Do NOT inflate claims. Do NOT delete files without understanding their purpose.

### Rules for All Workers:
1. **MEASURE before claiming** - Run actual tests, record actual numbers
2. **NO aspirational claims** - Only document what is MEASURED and VERIFIED
3. **NO deleting files** without explicit user permission
4. **FIX root causes** - Don't paper over bugs with workarounds
5. **TEST your fixes** - Run `./test_integration.sh` before claiming anything works
6. **BE SKEPTICAL** - If something seems too good (e.g., 9ms vocoder), it's probably wrong
7. **VERIFY claims** - Previous workers have made false claims. Don't trust without testing.

### Pre-commit Hook Enforces This:
The git pre-commit hook runs integration tests when CLAUDE.md claims "WORKING". If tests fail, the commit is blocked.

### Recent Issues Fixed (2025-12-02):
- Latency test was parsing timestamp (37ms) instead of actual latency (180ms)
- TTS claimed 18ms but was actually 22-30ms
- Vocoder claimed 9ms but was actually 15-25ms
- Model size claimed 5.3GB but actually loads 7.2GB
- Files were deleted without permission (json_to_text.py, etc.)

**DO IT RIGHT. NO SHORTCUTS.**

---

## âœ… COMPLETED: TTS Thread Safety (2025-12-02)

**STATUS**: âœ… **IMPLEMENTED** - FairTTSQueue with all requirements

**What was implemented:**
- `FairTTSQueue` class in `include/tts_queue.hpp` - Thread-safe multi-stream TTS
- `TTSQueueEngine` wrapper in `include/tts_queue_engine.hpp` - Drop-in replacement for TTSEngineV2
- Integration into `async_pipeline.cpp` and `streaming_pipeline.cpp`
- Unit tests in `test_tts_queue.cpp` - All 8 stress tests passing

**Features:**
- Single worker thread for serialized GPU access (no contention)
- Fair round-robin scheduling across multiple streams
- Priority levels: INTERACTIVE > HIGH > NORMAL > LOW
- Per-stream cancellation via `cancel_stream()` or cancel flags
- Graceful shutdown with pending request cleanup
- Full metrics: latency, synthesis time, queue depth, priority breakdown

### Original Task: Implement Fair Multi-Stream TTS Queue

**MANAGER DIRECTIVE**: Build the CORRECT scalable solution, not the easiest.

**Requirements for multiple concurrent streams:**
- Translation: PARALLEL (multiple streams translate simultaneously)
- TTS: SERIALIZED with FAIRNESS (round-robin across streams)
- Support: Priority levels, cancellation, metrics

### Architecture:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Multiple Voice Streams                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Stream 1 â”€â”€â”                                               â”‚
â”‚  Stream 2 â”€â”€â”¼â”€â”€â–º Translation â”€â”€â–º FairTTSQueue â”€â”€â–º Audio     â”‚
â”‚  Stream 3 â”€â”€â”˜    (parallel)      (serialized)    (per-stream)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Implementation - Fair Multi-Stream TTS Queue:

```cpp
// stream-tts-cpp/include/tts_queue.hpp
#pragma once

#include <queue>
#include <map>
#include <mutex>
#include <condition_variable>
#include <future>
#include <thread>
#include <atomic>
#include <chrono>

namespace StreamTTS {

class FairTTSQueue {
public:
    using StreamId = uint32_t;

    enum class Priority { LOW = 0, NORMAL = 1, HIGH = 2, INTERACTIVE = 3 };

    struct Request {
        StreamId stream_id;
        std::string text;
        Priority priority;
        std::promise<std::vector<float>> promise;
        std::chrono::steady_clock::time_point queued_at;
        std::atomic<bool>* cancelled;  // Pointer to stream's cancel flag
    };

    struct Metrics {
        std::atomic<uint64_t> total_requests{0};
        std::atomic<uint64_t> completed_requests{0};
        std::atomic<uint64_t> cancelled_requests{0};
        std::atomic<uint64_t> total_latency_ms{0};
        std::atomic<size_t> current_queue_depth{0};
    };

    FairTTSQueue(StyleTTS2Complete* engine)
        : engine_(engine), running_(true) {
        worker_ = std::thread(&FairTTSQueue::worker_loop, this);
    }

    ~FairTTSQueue() {
        shutdown();
    }

    void shutdown() {
        running_ = false;
        cv_.notify_one();
        if (worker_.joinable()) worker_.join();
    }

    // Submit request with stream ID for fairness
    std::future<std::vector<float>> synthesize(
        StreamId stream_id,
        const std::string& text,
        Priority priority = Priority::NORMAL,
        std::atomic<bool>* cancel_flag = nullptr
    ) {
        Request req;
        req.stream_id = stream_id;
        req.text = text;
        req.priority = priority;
        req.queued_at = std::chrono::steady_clock::now();
        req.cancelled = cancel_flag;

        auto future = req.promise.get_future();

        {
            std::lock_guard<std::mutex> lock(mutex_);
            stream_queues_[stream_id].push(std::move(req));
            metrics_.total_requests++;
            metrics_.current_queue_depth++;
        }
        cv_.notify_one();

        return future;
    }

    // Cancel all pending requests for a stream
    void cancel_stream(StreamId stream_id) {
        std::lock_guard<std::mutex> lock(mutex_);
        if (stream_queues_.count(stream_id)) {
            auto& q = stream_queues_[stream_id];
            while (!q.empty()) {
                auto& req = q.front();
                req.promise.set_exception(
                    std::make_exception_ptr(std::runtime_error("Cancelled")));
                metrics_.cancelled_requests++;
                metrics_.current_queue_depth--;
                q.pop();
            }
            stream_queues_.erase(stream_id);
        }
    }

    const Metrics& get_metrics() const { return metrics_; }

private:
    void worker_loop() {
        while (running_) {
            Request req;
            bool got_request = false;

            {
                std::unique_lock<std::mutex> lock(mutex_);
                cv_.wait(lock, [this] {
                    return !all_queues_empty() || !running_;
                });

                if (!running_ && all_queues_empty()) return;

                // Fair round-robin with priority boost
                got_request = select_next_request(req);
            }

            if (got_request) {
                // Check if cancelled before processing
                if (req.cancelled && req.cancelled->load()) {
                    req.promise.set_exception(
                        std::make_exception_ptr(std::runtime_error("Cancelled")));
                    metrics_.cancelled_requests++;
                    continue;
                }

                // Single-threaded TTS execution - no GPU contention
                try {
                    auto audio = engine_->synthesize(req.text);
                    req.promise.set_value(std::move(audio));

                    // Update metrics
                    auto latency = std::chrono::duration_cast<std::chrono::milliseconds>(
                        std::chrono::steady_clock::now() - req.queued_at).count();
                    metrics_.total_latency_ms += latency;
                    metrics_.completed_requests++;
                } catch (const std::exception& e) {
                    req.promise.set_exception(std::current_exception());
                }
                metrics_.current_queue_depth--;
            }
        }
    }

    bool all_queues_empty() const {
        for (const auto& [id, q] : stream_queues_) {
            if (!q.empty()) return false;
        }
        return true;
    }

    // Fair selection: round-robin with priority boost
    bool select_next_request(Request& out_req) {
        if (stream_queues_.empty()) return false;

        // First pass: find highest priority request
        Priority highest = Priority::LOW;
        for (const auto& [id, q] : stream_queues_) {
            if (!q.empty() && q.front().priority > highest) {
                highest = q.front().priority;
            }
        }

        // Second pass: round-robin among streams with highest priority
        auto it = stream_queues_.upper_bound(last_served_stream_);
        if (it == stream_queues_.end()) it = stream_queues_.begin();

        auto start = it;
        do {
            if (!it->second.empty() && it->second.front().priority == highest) {
                out_req = std::move(it->second.front());
                it->second.pop();
                last_served_stream_ = it->first;
                if (it->second.empty()) {
                    stream_queues_.erase(it);
                }
                return true;
            }
            ++it;
            if (it == stream_queues_.end()) it = stream_queues_.begin();
        } while (it != start);

        return false;
    }

    StyleTTS2Complete* engine_;
    std::map<StreamId, std::queue<Request>> stream_queues_;
    StreamId last_served_stream_ = 0;
    std::mutex mutex_;
    std::condition_variable cv_;
    std::thread worker_;
    std::atomic<bool> running_;
    Metrics metrics_;
};

} // namespace StreamTTS
```

### Usage Example:

```cpp
// Create queue
FairTTSQueue tts_queue(styletts2_engine.get());

// Stream 1 submits requests
std::atomic<bool> stream1_cancel{false};
auto future1 = tts_queue.synthesize(1, "Hello", Priority::NORMAL, &stream1_cancel);

// Stream 2 submits with higher priority (interactive user)
auto future2 = tts_queue.synthesize(2, "Hi", Priority::INTERACTIVE, nullptr);

// Stream 2 processed first (higher priority), then fair round-robin

// Cancel stream 1 if user disconnects
stream1_cancel = true;  // Current request checked before processing
tts_queue.cancel_stream(1);  // Cancel all pending

// Get metrics
auto& m = tts_queue.get_metrics();
spdlog::info("Queue depth: {}, Avg latency: {}ms",
    m.current_queue_depth.load(),
    m.completed_requests > 0 ? m.total_latency_ms / m.completed_requests : 0);
```

### Files to Create/Modify:
- `stream-tts-cpp/include/tts_queue.hpp` - NEW: FairTTSQueue class
- `stream-tts-cpp/src/tts_engine_v2.cpp` - Use FairTTSQueue
- `stream-tts-cpp/src/async_pipeline.cpp` - Pass stream IDs, use priorities
- `stream-tts-cpp/src/main.cpp` - Add metrics logging endpoint

### Acceptance Criteria:
1. **Fairness**: Stream 1 cannot starve Stream 2 (round-robin)
2. **Priority**: INTERACTIVE requests processed before NORMAL
3. **Cancellation**: Streams can cancel pending requests cleanly
4. **Metrics**: Queue depth, latency tracking available
5. **No GPU contention**: Single worker thread for TTS
6. **No deadlocks**: Clean shutdown, exception safety
7. **Low overhead**: Queue operations < 1ms

### Testing:
```bash
# Stress test with multiple concurrent streams
./stress_test.sh --streams=3 --duration=60s

# Verify fairness (each stream should get ~33% of TTS time)
# Verify no GPU errors in logs
# Verify metrics show reasonable latency distribution
```

**THIS IS THE CORRECT SCALABLE ARCHITECTURE.**

---

## Cleanup Status

**Files in voice/ directory have been consolidated.** Current documentation files:

| File | Purpose |
|------|---------|
| `CLAUDE.md` | Main project documentation |
| `README.md` | Quick start guide |
| `WORKER_INSTRUCTIONS.md` | This file - worker guidelines |
| `TESTING.md` | Test documentation |
| `USAGE.md` | Usage guide |

Other .md files are historical context and can be removed if not referenced.
