#!/usr/bin/env python3
"""
Generate Japanese misaki phoneme lexicon (Kokoro's native G2P).

misaki.ja.JAG2P outputs the exact phoneme strings Kokoro was trained on.
We precompute a lexicon for common words to keep runtime C++ fully native.

Usage:
    python scripts/generate_japanese_misaki_lexicon.py > stream-tts-cpp/include/japanese_misaki_lexicon.hpp

Copyright 2025 Andrew Yates. All rights reserved.
"""

import sys
import argparse

try:
    from misaki.ja import JAG2P
except ImportError:
    print("Error: Install misaki with: pip install misaki", file=sys.stderr)
    sys.exit(1)


# Common Japanese words for coding/assistant context
COMMON_WORDS = [
    # Greetings (full and polite forms)
    "こんにちは", "こんばんは", "おはよう", "おはようございます", "おやすみ", "おやすみなさい",
    "さようなら", "ありがとう", "ありがとうございます", "すみません", "ごめんなさい",
    "はい", "いいえ", "お願いします", "失礼します",
    "ございます", "ございました", "いらっしゃい", "いらっしゃいませ",

    # Pronouns
    "私", "僕", "俺", "彼", "彼女", "あなた", "誰", "何",
    "これ", "それ", "あれ", "ここ", "そこ", "あそこ",

    # Numbers
    "一", "二", "三", "四", "五", "六", "七", "八", "九", "十",
    "百", "千", "万", "零",
    "一つ", "二つ", "三つ", "四つ", "五つ",

    # Time
    "今", "今日", "明日", "昨日", "今年", "来年", "去年",
    "朝", "昼", "夜", "午前", "午後",
    "時間", "分", "秒", "日", "週", "月", "年",

    # Programming terms (common in coding context)
    "関数", "変数", "配列", "文字列", "数値", "型",
    "クラス", "オブジェクト", "メソッド", "プロパティ",
    "エラー", "バグ", "テスト", "デバッグ", "コード",
    "コンパイル", "実行", "処理", "入力", "出力",
    "ファイル", "フォルダ", "ディレクトリ",
    "データ", "データベース", "サーバー", "クライアント",
    "ネットワーク", "インターネット", "ウェブ",
    "プログラム", "ソフトウェア", "ハードウェア",
    "アルゴリズム", "ロジック", "条件", "ループ",

    # Actions
    "する", "なる", "ある", "いる", "行く", "来る", "見る", "聞く",
    "言う", "書く", "読む", "作る", "使う", "分かる", "知る",
    "思う", "考える", "決める", "始める", "終わる", "続ける",
    "開く", "閉じる", "動く", "止まる", "変わる", "変える",

    # Adjectives
    "良い", "悪い", "大きい", "小さい", "多い", "少ない",
    "新しい", "古い", "高い", "低い", "長い", "短い",
    "早い", "遅い", "速い", "難しい", "簡単", "正しい",
    "同じ", "違う", "必要", "重要", "大切", "大丈夫",

    # Particles and conjunctions (for context)
    "です", "ます", "だから", "しかし", "また", "そして",
    "もし", "ただし", "例えば", "つまり", "それで",

    # Technical status words
    "成功", "失敗", "完了", "開始", "停止", "待機",
    "実行中", "処理中", "読み込み中", "保存中",
    "エラー", "警告", "情報", "確認",

    # Common nouns
    "日本", "日本語", "英語", "言語", "言葉",
    "人", "名前", "場所", "時", "物", "事", "所",
    "問題", "答え", "質問", "説明", "例",
    "結果", "理由", "方法", "目的", "意味",

    # Tokyo and common places
    "東京", "大阪", "京都", "横浜", "名古屋",

    # Coding-specific phrases
    "インポート", "エクスポート", "インストール",
    "アップデート", "ダウンロード", "アップロード",
    "セーブ", "ロード", "リセット", "クリア",
    "コピー", "ペースト", "カット", "アンドゥ",
    "プルリクエスト", "コミット", "プッシュ", "プル",
    "マージ", "ブランチ", "リポジトリ",
]

# High-frequency function words (top 100 list)
FREQUENCY_WORDS = [
    "の", "に", "は", "を", "た", "が", "で", "て", "と", "し",
    "れ", "さ", "ある", "いる", "も", "する", "から", "な", "こと", "として",
    "い", "や", "れる", "など", "なっ", "ない", "この", "ため", "その", "あっ",
    "よう", "また", "もの", "という", "あり", "まで", "られ", "なる", "へ", "か",
    "だ", "これ", "によって", "により", "おり", "より", "による", "ず", "なり", "られる",
    "において", "ば", "なかっ", "なく", "しかし", "について", "せ", "だっ", "その後", "できる",
    "それ", "う", "ので", "なお", "のみ", "でき", "き", "つ", "における", "および",
    "いう", "さらに", "でも", "ら", "たり", "その他", "に関する", "たち", "ます", "ん",
    "なら", "に対して", "特に", "せる", "及び", "これら", "とき", "では", "にて", "ほか",
    "ながら", "うち", "そう", "もっとも", "ところ", "ただし", "にあたって", "として", "場合", "において",
]


def generate_lexicon():
    g2p = JAG2P()

    all_words = list(set(COMMON_WORDS + FREQUENCY_WORDS))
    all_words.sort()

    entries = {}

    # Generate word-level phonemes
    for word in all_words:
        try:
            result = g2p(word)
            # Handle both tuple (phonemes, metadata) and plain string returns
            phonemes = result[0] if isinstance(result, tuple) else result
            if phonemes:
                entries[word] = phonemes
        except Exception as exc:  # pragma: no cover - logging only
            print(f"// Warning: Failed to process '{word}': {exc}", file=sys.stderr)

    # Fallback: single characters not already present
    single_chars = list(set("".join(all_words)))
    for ch in single_chars:
        if ch in entries:
            continue
        try:
            result = g2p(ch)
            phonemes = result[0] if isinstance(result, tuple) else result
            if phonemes:
                entries[ch] = phonemes
        except Exception:
            continue

    # Sort: longer words first, then lexicographic
    sorted_entries = sorted(entries.items(), key=lambda x: (-len(x[0]), x[0]))

    print("""#pragma once
// Japanese misaki phoneme lexicon - AUTO-GENERATED
// Generated by scripts/generate_japanese_misaki_lexicon.py using misaki.ja.JAG2P
//
// IMPORTANT: Kokoro was trained on misaki phonemes. Use this lexicon to match
// the model's expected inputs (e.g., こんにちは -> koɲɲiʨiβa).
//
// Copyright 2025 Andrew Yates. All rights reserved.

#include <string>
#include <unordered_map>
#include <sstream>

namespace japanese_misaki {

// Japanese text -> misaki phonemes (training format)
inline const std::unordered_map<std::string, std::string> PHONEME_LEXICON = {""")

    for word, phonemes in sorted_entries:
        phonemes_escaped = phonemes.replace("\\", "\\\\").replace('"', '\\"')
        print(f'    {{"{word}", "{phonemes_escaped}"}},')

    print("""};

inline int utf8_char_length(unsigned char c) {
    if ((c & 0x80) == 0) return 1;
    if ((c & 0xE0) == 0xC0) return 2;
    if ((c & 0xF0) == 0xE0) return 3;
    if ((c & 0xF8) == 0xF0) return 4;
    return 1;
}

// Detect Hiragana, Katakana, or CJK characters used in Japanese
inline bool is_japanese_char(const std::string& ch) {
    if (ch.empty()) return false;
    const unsigned char c1 = static_cast<unsigned char>(ch[0]);
    const unsigned char c2 = ch.size() > 1 ? static_cast<unsigned char>(ch[1]) : 0;
    // Hiragana: U+3040-U+309F (E3 81 80 - E3 82 9F)
    if (ch.size() == 3 && c1 == 0xE3 && c2 >= 0x81 && c2 <= 0x82) return true;
    // Katakana: U+30A0-U+30FF (E3 82 A0 - E3 83 BF)
    if (ch.size() == 3 && c1 == 0xE3 && c2 >= 0x82 && c2 <= 0x83) return true;
    // CJK Unified Ideographs (kanji): U+4E00-U+9FFF
    if (ch.size() == 3) {
        if (c1 == 0xE4 && c2 >= 0xB8) return true;
        if (c1 >= 0xE5 && c1 <= 0xE8) return true;
        if (c1 == 0xE9 && c2 <= 0xBF) return true;
    }
    return false;
}

// Check if text contains any Japanese characters
inline bool contains_japanese(const std::string& text) {
    size_t i = 0;
    while (i < text.size()) {
        unsigned char c = static_cast<unsigned char>(text[i]);
        int len = utf8_char_length(c);
        if (i + len > text.size()) break;

        std::string ch = text.substr(i, len);
        if (is_japanese_char(ch)) return true;
        i += len;
    }
    return false;
}

// Longest-match lookup; returns empty string if any unknown Japanese character
inline std::string lookup_phonemes(const std::string& text) {
    auto it_full = PHONEME_LEXICON.find(text);
    if (it_full != PHONEME_LEXICON.end()) {
        return it_full->second;
    }

    std::stringstream result;
    bool found_any = false;
    size_t i = 0;

    while (i < text.size()) {
        unsigned char c = static_cast<unsigned char>(text[i]);
        int char_len = utf8_char_length(c);
        if (i + char_len > text.size()) break;

        bool matched = false;
        for (size_t try_len = std::min(text.size() - i, size_t(18));
             try_len >= static_cast<size_t>(char_len); ) {
            std::string substring = text.substr(i, try_len);
            auto it = PHONEME_LEXICON.find(substring);
            if (it != PHONEME_LEXICON.end()) {
                if (found_any) result << " ";
                result << it->second;
                found_any = true;
                matched = true;
                i += try_len;
                break;
            }

            if (try_len <= static_cast<size_t>(char_len)) break;
            try_len -= char_len;
            while (try_len > 0 && try_len < text.size() - i) {
                unsigned char next_c = static_cast<unsigned char>(text[i + try_len]);
                if ((next_c & 0xC0) != 0x80) break;
                try_len--;
            }
            if (try_len < static_cast<size_t>(char_len)) break;
        }

        if (!matched) {
            std::string ch = text.substr(i, char_len);

            if (is_japanese_char(ch)) {
                // Unknown Japanese character: signal fallback (espeak/JTALK)
                return "";
            }

            // Preserve non-Japanese characters (ASCII/punctuation) verbatim
            if (found_any && !ch.empty() && ch != " ") result << " ";
            result << ch;
            found_any = true;
            i += char_len;
        }
    }

    return found_any ? result.str() : "";
}

}  // namespace japanese_misaki
""")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Generate Japanese misaki lexicon")
    parser.parse_args()
    generate_lexicon()
