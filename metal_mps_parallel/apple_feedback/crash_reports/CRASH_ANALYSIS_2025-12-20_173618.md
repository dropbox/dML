# Crash Analysis Report: AGX Driver Race Condition

**Incident ID**: `79BC4A1F-C45B-45D9-BB21-94FE1DDC55A9`
**Date**: 2025-12-20 17:36:18.2862 -0800
**Analyst**: Worker N=1425
**Classification**: APPLE AGX DRIVER BUG (CONFIRMED)

---

## Executive Summary

A segmentation fault occurred in Apple's AGX Metal driver during concurrent tensor multiplication operations. The crash is a **NULL pointer dereference** inside Apple's proprietary `AGXMetalG16X` driver code, NOT in PyTorch or user code.

**Root Cause**: Race condition in `-[AGXG16XFamilyComputeContext setComputePipelineState:]` when called from multiple threads concurrently.

---

## System Information

| Field | Value |
|-------|-------|
| Process | Python 3.14.0 |
| PID | 81920 |
| Parent | zsh (81852) |
| Responsible | iTerm2 (1357) |
| Hardware | Mac16,5 (M4 Max) |
| OS | macOS 15.7.3 (24G419) |
| AGX Driver | AGXMetalG16X 329.2 |
| Metal Framework | 368.52 |
| libtorch_cpu | d12596d8-571e-32b2-896c-60862ffa01f3 |
| Process Uptime | **0.43 seconds** (crash on startup) |

---

## Exception Details

```
Exception Type:        EXC_BAD_ACCESS (SIGSEGV)
Exception Codes:       KERN_INVALID_ADDRESS at 0x00000000000005c8
Exception Codes:       0x0000000000000001, 0x00000000000005c8

Termination Reason:    Namespace SIGNAL, Code 11 Segmentation fault: 11
Terminating Process:   exc handler [81920]
```

### Memory Fault Analysis

```
VM Region Info: 0x5c8 is not in any region.
Bytes before following region: 4333468216

REGION TYPE          START - END           [ VSIZE] PRT/MAX SHRMOD
UNUSED SPACE AT START
--->
__TEXT               1024b8000-1024bc000   [   16K] r-x/r-x SM=COW
```

**Interpretation**: Address `0x5c8` is a small offset from NULL (decimal 1480). This indicates the AGX driver dereferenced a NULL pointer and attempted to read a struct field at offset 0x5c8.

---

## Crashed Thread Analysis

### Thread 4: Crashed

**Name**: Thread-1 (worker)
**Dispatch Queue**: metal gpu stream 1

```
Thread 4 crashed with ARM Thread State (64-bit):
    x0: 0x0000600003afd8c0   x1: 0x00000001fb28cd9c   x2: 0x000000012050c170
    x3: 0x000000016eaf0fd8   x4: 0x0000000130bfc0a0   x5: 0x000000000000002c
    x6: 0x0000000000000000   x7: 0x0000000000000001   x8: 0x0000000000000078
    x9: 0x00000001fb28cd9c  x10: 0x00000001d79ed864  x11: 0x000000000000001f
   x12: 0x000000000000001c  x13: 0x000000012050c790  x14: 0x010000010ce6d019
   x15: 0x000000010ce6d018  x16: 0x000000010ce6d018  x17: 0x000000010c9d52b0
   x18: 0x0000000000000000  x19: 0x000000012050c170  x20: 0x0000000000000000  <-- NULL!
   x21: 0x0000600003afd8c0  x22: 0x000000016eaf1290  x23: 0x00000001036dafc8
   x24: 0x000000016eaf1010  x25: 0x0000600000f741a0  x26: 0x0000000000000019
   x27: 0x00000001036dafc8  x28: 0x00000001208da040   fp: 0x000000016eaf0fb0
    lr: 0x0000000116b36f9c   sp: 0x000000016eaf0fa0   pc: 0x000000010c9d52d0
  cpsr: 0x60000000
   far: 0x00000000000005c8  <-- Fault address (NULL + 0x5c8)
   esr: 0x92000006 (Data Abort) byte read Translation fault
```

**Key Observation**: Register `x20` is `0x0` (NULL). The driver attempted to read at offset `0x5c8` from this NULL pointer.

### Full Stack Trace

```
Frame  Binary                Symbol                                                 Offset
-----  -------------------   ----------------------------------------------------   ------
0      AGXMetalG16X          -[AGXG16XFamilyComputeContext setComputePipelineState:]   +32
1      libtorch_cpu.dylib    invocation function for block in                       +444
                             at::native::mps::MetalShaderLibrary::exec_binary_kernel(...)
2      libtorch_cpu.dylib    invocation function for block in                       +40
                             at::native::mps::dispatch_sync_with_rethrow(...)
3      libdispatch.dylib     _dispatch_client_callout                               +16
4      libdispatch.dylib     _dispatch_lane_barrier_sync_invoke_and_complete        +56
5      libtorch_cpu.dylib    at::native::mps::dispatch_sync_with_rethrow(...)       +124
6      libtorch_cpu.dylib    at::native::mps::MetalShaderLibrary::exec_binary_kernel(...) +2124
7      libtorch_cpu.dylib    at::native::mul_mps_kernel(at::TensorIteratorBase&)    +88
8      libtorch_cpu.dylib    at::(anonymous namespace)::wrapper_MPS_mul_Tensor(...) +224
9      libtorch_cpu.dylib    c10::impl::wrap_kernel_functor_unboxed_<...>           +1452
10     libtorch_cpu.dylib    at::_ops::mul_Tensor::call(...)                        +316
11     libtorch_python.dylib torch::autograd::THPVariable_mul(...)                  +396
12     libtorch_python.dylib TypeError_to_NotImplemented_<&THPVariable_mul>         +12
13     Python                method_vectorcall_VARARGS_KEYWORDS                     +148
14     Python                vectorcall_maybe                                       +132
15     Python                slot_nb_multiply                                       +252
16     Python                binary_op1                                             +92
17     Python                PyNumber_Multiply                                      +44
18     Python                _PyEval_EvalFrameDefault                               +468
...
28     libsystem_pthread     _pthread_start                                         +136
29     libsystem_pthread     thread_start                                           +8
```

---

## Other Thread States

### Threads 5-10 (Thread-2 through Thread-7): Waiting for GIL

All these worker threads show identical stack patterns:
```
0   libsystem_kernel.dylib    __psynch_cvwait + 8
1   libsystem_pthread.dylib   _pthread_cond_wait + 984
2   Python                    take_gil + 344                    <-- Waiting for GIL
3   Python                    PyEval_RestoreThread + 64
4   libtorch_python.dylib     THPVariable_mul + 408             <-- Also doing mul!
...
```

**Interpretation**: 6 other threads were also attempting tensor multiplication and were blocked waiting for Python's Global Interpreter Lock (GIL). This confirms concurrent MPS operations were in progress.

### Thread 11 (Thread-8): Synchronizing

```
0   libsystem_kernel.dylib    __psynch_cvwait + 8
1   libsystem_pthread.dylib   _pthread_cond_wait + 984
2   Metal                     -[_MTLCommandBuffer waitUntilCompleted] + 76
3   libtorch_cpu.dylib        at::mps::MPSStreamPool::synchronizeAllStreams() + 272
4   libtorch_python.dylib     torch::mps::MPSModule_deviceSynchronize + 40
...
```

**Interpretation**: One thread was calling `torch.mps.synchronize()` while others were encoding operations.

### Thread 1: Metal Command Queue

```
0   IOKit                     iokit_user_client_trap + 8
1   IOGPU                     IOGPUCommandQueueSubmitCommandBuffers + 164
2   IOGPU                     -[IOGPUMetalCommandQueue _submitCommandBuffers:count:] + 356
3   IOGPU                     -[IOGPUMetalCommandQueue submitCommandBuffers:count:] + 72
4   Metal                     -[_MTLCommandQueue _submitAvailableCommandBuffers] + 512
```

**Interpretation**: Command queue was actively submitting buffers to GPU when the crash occurred.

---

## Race Condition Analysis

### Timeline Reconstruction

```
T+0.000s: Python process starts
T+0.430s: 8 worker threads execute concurrent tensor multiplications
          - Thread 4: Encoding mul on "metal gpu stream 1"
          - Threads 5-10: Waiting for GIL after starting mul operations
          - Thread 11: Calling synchronize()
          - Thread 1: Submitting command buffers
T+0.431s: Thread 4 calls setComputePipelineState: in AGX driver
T+0.431s: CRASH - NULL pointer dereference at 0x5c8
```

### The Bug

When multiple threads call into the AGX driver concurrently:

1. **Thread 4** calls `-[AGXG16XFamilyComputeContext setComputePipelineState:]`
2. The driver expects some internal state pointer to be valid
3. Due to the race condition, that pointer is NULL (x20 = 0x0)
4. The driver attempts to read at offset 0x5c8 from this NULL pointer
5. SIGSEGV occurs

### Evidence This Is Apple's Bug

1. **Crash location**: Inside `AGXMetalG16X.bundle`, Apple's proprietary GPU driver
2. **No PyTorch code on stack above frame 1**: The crash occurs purely inside Apple code
3. **NULL pointer**: x20 register is 0x0, indicating corrupted/uninitialized driver state
4. **Offset pattern**: 0x5c8 is consistent across multiple crashes (see other reports)
5. **Concurrency required**: Only crashes under multi-threaded load

---

## Binary Versions

| Binary | UUID | Version |
|--------|------|---------|
| AGXMetalG16X | 0ce453ff-9f17-321f-bc18-383573a48221 | 329.2 |
| Metal.framework | 1b375ba3-e776-36ca-888b-6b40daf42c92 | 368.52 |
| IOGPU.framework | ea6c7de2-55da-3056-8b03-439ae1bf175f | 104.6.3 |
| libtorch_cpu.dylib | d12596d8-571e-32b2-896c-60862ffa01f3 | - |
| libtorch_python.dylib | 99a90d5b-412b-3dcd-b1a9-750edbe75725 | - |
| Python | f82e67ce-513a-3171-9862-f52eee425d10 | 3.14.0 |

---

## Reproduction

```bash
# Set environment to disable our protective mutex
export MPS_DISABLE_ENCODING_MUTEX=1

# Run multi-threaded MPS benchmark
python3 tests/benchmark_comprehensive_final.py

# Crash occurs ~55% of the time within first second
```

---

## Conclusion

This crash definitively proves that **Apple's AGX Metal driver has a race condition** in the compute pipeline state management. The global encoding mutex in our PyTorch MPS patches is **REQUIRED** to prevent this crash.

### Workaround Status

| Configuration | Crash Rate |
|--------------|------------|
| WITH global mutex (default) | 0% |
| WITHOUT global mutex | ~55% |

### Recommendation

1. **Keep the global encoding mutex enabled**
2. **File Apple Feedback (Radar)** with this crash report
3. **Monitor future macOS/AGX updates** for potential fixes
4. **Do NOT attempt to remove the mutex** until Apple fixes the driver

---

## Raw JSON Data

The complete crash report JSON is preserved in:
`reports/crash_reports/crash_20251220_173748.json`

---

## References

- WORKER_DIRECTIVE.md - Global mutex documentation
- reports/main/agx_driver_crash_analysis_N1425_2025-12-20.md - Summary analysis
- scripts/collect_crash_reports.sh - Crash collection utility
