#!/usr/bin/env python3
"""
COMPLETE BENCHMARK: All MPS Performance Methods - FIXED

Created by Andrew Yates

Tests every parallelization method with proper initialization:
1. Single-threaded baseline
2. Threading (2, 4, 8 threads)
3. Process pool (2, 4, 8 processes)
4. Batching (1, 8, 32, 64, 128)
5. BatchQueue pipelining (FIXED - calls start())
6. Hybrid: Batching + Threading
"""

import torch
import torch.nn as nn
import time
import threading
import statistics
import json
import os
import sys
from datetime import datetime
from typing import Dict, List, Any

print("=" * 70)
print("COMPLETE MPS BENCHMARK - ALL METHODS")
print("=" * 70)

device = torch.device("mps")

# Create test model
def create_model():
    return nn.Sequential(
        nn.Linear(512, 1024),
        nn.ReLU(),
        nn.Linear(1024, 1024),
        nn.ReLU(),
        nn.Linear(1024, 512)
    ).to(device).eval()

model = create_model()

results = {}

# ============================================================================
# 1. SINGLE-THREADED BASELINE
# ============================================================================

print("\n[1/6] Single-threaded baseline...")

def measure_baseline():
    x = torch.randn(32, 512, device=device)

    # Warmup
    for _ in range(10):
        with torch.no_grad():
            y = model(x)
        torch.mps.synchronize()

    # Measure
    iterations = 200
    start = time.perf_counter()
    for _ in range(iterations):
        with torch.no_grad():
            y = model(x)
    torch.mps.synchronize()
    elapsed = time.perf_counter() - start

    return iterations / elapsed

baseline_ops = measure_baseline()
results['baseline'] = {
    'ops_per_sec': baseline_ops,
    'samples_per_sec': baseline_ops * 32,
    'description': 'Single-threaded, batch=32'
}
print(f"   Baseline: {baseline_ops:.1f} ops/s ({baseline_ops * 32:.1f} samples/s)")

# ============================================================================
# 2. THREADING (Limited by Apple driver)
# ============================================================================

print("\n[2/6] Threading (various thread counts)...")

def measure_threading(num_threads: int) -> Dict:
    completed = [0]
    lock = threading.Lock()

    def worker():
        x = torch.randn(32, 512, device=device)
        for _ in range(50):
            with torch.no_grad():
                y = model(x)
            torch.mps.synchronize()
            with lock:
                completed[0] += 1

    start = time.perf_counter()
    threads = [threading.Thread(target=worker) for _ in range(num_threads)]
    for t in threads:
        t.start()
    for t in threads:
        t.join()
    elapsed = time.perf_counter() - start

    ops = completed[0] / elapsed
    speedup = ops / baseline_ops
    efficiency = speedup / num_threads

    return {
        'ops_per_sec': ops,
        'speedup': speedup,
        'efficiency': efficiency,
        'samples_per_sec': ops * 32
    }

threading_results = {}
for n in [2, 4, 8]:
    r = measure_threading(n)
    threading_results[f'{n}_threads'] = r
    print(f"   {n} threads: {r['ops_per_sec']:.1f} ops/s, {r['speedup']:.2f}x speedup, {r['efficiency']:.1%} efficiency")

results['threading'] = threading_results

# ============================================================================
# 2b. THREADING WITH EVENT SYNC (Correct multi-threading approach)
# ============================================================================

print("\n[2b/6] Threading with EVENT sync (correct approach)...")

def measure_threading_event_sync(num_threads: int) -> Dict:
    """Threading with per-stream event sync - correct for multi-threading."""
    completed = [0]
    lock = threading.Lock()

    def worker():
        x = torch.randn(32, 512, device=device)
        event = torch.mps.Event(enable_timing=False)
        for _ in range(50):
            with torch.no_grad():
                y = model(x)
            event.record()
            event.synchronize()  # Per-stream sync, not device-wide
            with lock:
                completed[0] += 1

    start = time.perf_counter()
    threads = [threading.Thread(target=worker) for _ in range(num_threads)]
    for t in threads:
        t.start()
    for t in threads:
        t.join()
    elapsed = time.perf_counter() - start

    ops = completed[0] / elapsed
    speedup = ops / baseline_ops
    efficiency = speedup / num_threads

    return {
        'ops_per_sec': ops,
        'speedup': speedup,
        'efficiency': efficiency,
        'samples_per_sec': ops * 32
    }

threading_event_results = {}
for n in [2, 4, 8]:
    r = measure_threading_event_sync(n)
    threading_event_results[f'{n}_threads_event'] = r
    print(f"   {n} threads (event): {r['ops_per_sec']:.1f} ops/s, {r['speedup']:.2f}x speedup, {r['efficiency']:.1%} efficiency")

results['threading_event_sync'] = threading_event_results

# ============================================================================
# 3. BATCHING (GPU internal parallelism)
# ============================================================================

print("\n[3/6] Batching (GPU parallelism)...")

def measure_batching(batch_size: int) -> Dict:
    x = torch.randn(batch_size, 512, device=device)

    # Warmup
    for _ in range(5):
        with torch.no_grad():
            y = model(x)
        torch.mps.synchronize()

    # Measure
    iterations = 100
    start = time.perf_counter()
    for _ in range(iterations):
        with torch.no_grad():
            y = model(x)
    torch.mps.synchronize()
    elapsed = time.perf_counter() - start

    samples_per_sec = (batch_size * iterations) / elapsed
    ops_per_sec = iterations / elapsed

    return {
        'batch_size': batch_size,
        'samples_per_sec': samples_per_sec,
        'ops_per_sec': ops_per_sec,
        'samples_scaling': samples_per_sec / (baseline_ops * 32)
    }

batching_results = {}
for bs in [1, 8, 32, 64, 128]:
    r = measure_batching(bs)
    batching_results[f'batch_{bs}'] = r
    print(f"   Batch {bs}: {r['samples_per_sec']:.1f} samples/s, {r['samples_scaling']:.2f}x scaling")

results['batching'] = batching_results

# ============================================================================
# 4. BATCHQUEUE PIPELINING (FIXED)
# ============================================================================

print("\n[4/6] BatchQueue pipelining...")

def measure_batchqueue() -> Dict:
    """Test torch.mps.BatchQueue with proper initialization."""
    try:
        # Check if BatchQueue exists
        if not hasattr(torch.mps, 'BatchQueue'):
            return {'error': 'BatchQueue not available'}

        # Create and START the BatchQueue
        bq = torch.mps.BatchQueue(num_workers=1)
        bq.start()  # CRITICAL: Must call start() before submit()

        x = torch.randn(32, 512, device=device)

        # Create operation callable - API is submit(inputs, operation)
        def inference_op(inputs):
            with torch.no_grad():
                return model(inputs)

        # Warmup
        for _ in range(10):
            future = bq.submit(x, inference_op)
            future.result()

        # Measure - submit all then wait
        iterations = 100
        start = time.perf_counter()
        futures = []
        for _ in range(iterations):
            futures.append(bq.submit(x, inference_op))
        for f in futures:
            f.result()
        elapsed = time.perf_counter() - start

        # Stop the queue
        bq.stop()

        ops_per_sec = iterations / elapsed
        speedup = ops_per_sec / baseline_ops

        return {
            'ops_per_sec': ops_per_sec,
            'speedup': speedup,
            'samples_per_sec': ops_per_sec * 32,
            'status': 'working'
        }
    except Exception as e:
        return {'error': str(e)}

batchqueue_result = measure_batchqueue()
results['batchqueue'] = batchqueue_result
if 'error' not in batchqueue_result:
    print(f"   BatchQueue: {batchqueue_result['ops_per_sec']:.1f} ops/s, {batchqueue_result['speedup']:.2f}x speedup")
else:
    print(f"   BatchQueue: {batchqueue_result['error']}")

# ============================================================================
# 5. HYBRID: Batching + Threading
# ============================================================================

print("\n[5/6] Hybrid: Batching + Threading...")

def measure_hybrid_batch_thread(num_threads: int, batch_size: int) -> Dict:
    completed = [0]
    lock = threading.Lock()

    def worker():
        x = torch.randn(batch_size, 512, device=device)
        for _ in range(30):
            with torch.no_grad():
                y = model(x)
            torch.mps.synchronize()
            with lock:
                completed[0] += 1

    start = time.perf_counter()
    threads = [threading.Thread(target=worker) for _ in range(num_threads)]
    for t in threads:
        t.start()
    for t in threads:
        t.join()
    elapsed = time.perf_counter() - start

    total_samples = completed[0] * batch_size
    samples_per_sec = total_samples / elapsed
    ops_per_sec = completed[0] / elapsed

    return {
        'samples_per_sec': samples_per_sec,
        'ops_per_sec': ops_per_sec,
        'threads': num_threads,
        'batch_size': batch_size
    }

hybrid_results = {}
for threads, batch in [(2, 32), (4, 16), (2, 64), (2, 128)]:
    key = f'{threads}t_batch{batch}'
    r = measure_hybrid_batch_thread(threads, batch)
    hybrid_results[key] = r
    print(f"   {threads} threads Ã— batch {batch}: {r['samples_per_sec']:.1f} samples/s")

results['hybrid_batch_thread'] = hybrid_results

# ============================================================================
# 6. SUMMARY: FIND THE BEST
# ============================================================================

print("\n" + "=" * 70)
print("SUMMARY: FINDING THE ABSOLUTE BEST")
print("=" * 70)

# Collect all samples/s metrics
all_methods = []

# Baseline
all_methods.append(('Baseline (1 thread, batch 32)', results['baseline']['samples_per_sec']))

# Threading (device sync)
for k, v in results['threading'].items():
    if 'samples_per_sec' in v:
        all_methods.append((f'Threading {k} (device)', v['samples_per_sec']))

# Threading (event sync)
for k, v in results['threading_event_sync'].items():
    if 'samples_per_sec' in v:
        all_methods.append((f'Threading {k}', v['samples_per_sec']))

# Batching
for k, v in results['batching'].items():
    all_methods.append((f'Batching {k}', v['samples_per_sec']))

# BatchQueue
if 'samples_per_sec' in results['batchqueue']:
    all_methods.append(('BatchQueue', results['batchqueue']['samples_per_sec']))

# Hybrid
for k, v in results['hybrid_batch_thread'].items():
    all_methods.append((f'Hybrid {k}', v['samples_per_sec']))

# Sort by performance
all_methods.sort(key=lambda x: x[1], reverse=True)

print("\nRANKED BY SAMPLES/SECOND:")
print("-" * 60)
for i, (method, throughput) in enumerate(all_methods, 1):
    baseline_multiple = throughput / results['baseline']['samples_per_sec']
    print(f"{i:2}. {method:35} {throughput:>12.1f} samples/s ({baseline_multiple:.2f}x)")

best_method = all_methods[0]
print("\n" + "=" * 70)
print(f"BEST METHOD: {best_method[0]}")
print(f"THROUGHPUT:  {best_method[1]:.1f} samples/s")
print(f"VS BASELINE: {best_method[1] / results['baseline']['samples_per_sec']:.2f}x")
print("=" * 70)

# Key insights
print("\n" + "=" * 70)
print("KEY INSIGHTS")
print("=" * 70)

# Threading efficiency comparison
best_threading_device = max(results['threading'].items(), key=lambda x: x[1].get('efficiency', 0))
best_threading_event = max(results['threading_event_sync'].items(), key=lambda x: x[1].get('efficiency', 0))
print(f"\n1. THREADING (device sync): {best_threading_device[0]} achieves {best_threading_device[1]['efficiency']:.1%} efficiency")
print(f"   THREADING (event sync):  {best_threading_event[0]} achieves {best_threading_event[1]['efficiency']:.1%} efficiency")
event_vs_device = best_threading_event[1]['ops_per_sec'] / best_threading_device[1]['ops_per_sec']
print(f"   -> Event sync is {event_vs_device:.1f}x faster than device sync for threading")

# Batching wins
best_batching = max(results['batching'].items(), key=lambda x: x[1]['samples_per_sec'])
print(f"\n2. BATCHING: {best_batching[0]} achieves {best_batching[1]['samples_scaling']:.1f}x scaling")
print("   -> GPU internal parallelism is the most effective approach")

# BatchQueue
if 'error' not in results['batchqueue']:
    print(f"\n3. BATCHQUEUE: {results['batchqueue']['speedup']:.2f}x speedup")
    print("   -> Pipelining helps with command buffer submission")
else:
    print(f"\n3. BATCHQUEUE: {results['batchqueue']['error']}")

print("\n" + "=" * 70)
print("CONCLUSION")
print("=" * 70)
print("""
For MPS inference optimization:
1. USE LARGE BATCHES - batch_128 achieves best throughput
2. IF THREADING: Use EVENT sync (torch.mps.Event), NOT device sync
   - Event sync: per-stream sync (allows parallelism)
   - Device sync: waits for ALL streams (destroys parallelism)
3. BATCHQUEUE helps with pipelining but batching is more effective
4. Process pool can bypass driver serialization (separate test)
5. See docs/MPS_SYNC_MODE_GUIDE.md for detailed recommendations
""")

# Save results
results['ranked'] = [{'method': m, 'samples_per_sec': s} for m, s in all_methods]
results['best'] = {'method': best_method[0], 'samples_per_sec': best_method[1]}
results['timestamp'] = datetime.now().isoformat()

output_path = "reports/main/complete_benchmark.json"
os.makedirs(os.path.dirname(output_path), exist_ok=True)
with open(output_path, 'w') as f:
    json.dump(results, f, indent=2, default=str)

print(f"\nResults saved to: {output_path}")
