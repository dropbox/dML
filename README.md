# dML - Machine Learning Models

Machine learning inference engines optimized for Apple Silicon via MLX.

## Thesis

On-device AI should be fast, private, and free from cloud dependencies. These models run locally on Apple Silicon, enabling real-time speech recognition, text-to-speech, and translation without network latency or data leaving your machine.

## Projects

| Project | Description | Status |
|---------|-------------|--------|
| **model_mlx_migration** | MLX models: Whisper (STT), Kokoro (TTS 38x RT), LLaMA, NLLB, Wake Word | Planned |
| **voice** | Streaming voice I/O (14 languages, P50 48-107ms) | Planned |

## Status

These projects are in **preview** status. APIs may change.

## License

Apache 2.0 - See [LICENSE](LICENSE) for details.

## Release History

See [RELEASES.md](RELEASES.md) for version history.
