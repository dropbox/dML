# SOTA Model MLX Implementations
# Converted from PyTorch for fast inference on Apple Silicon

from . import (
    ast_config,
    ast_mlx,
    beats_config,
    beats_mlx,
    ecapa_config,
    ecapa_tdnn,
    emotion2vec_config,
    emotion2vec_mlx,
    moe_lora_decoder,
    personal_vad,
    phoneme_adaptation,
    phoneme_weighted_trainer,
    speaker_encoder,
    speaker_query_attention,
    suta,
    voice_focus_manager,
    wav2vec2_xlsr_config,
    wav2vec2_xlsr_mlx,
    wavlm_config,
    wavlm_mlx,
)
from .ecapa_config import ECAPATDNNConfig
from .ecapa_tdnn import ECAPATDNN, ECAPATDNNForLanguageID
from .moe_lora_decoder import (
    ExpertRouter,
    LoRAExpert,
    MoELoRAConfig,
    MoELoRADecoder,
    create_moe_lora_decoder,
)
from .personal_vad import (
    PersonalVAD,
    PersonalVADConfig,
    PersonalVADMLX,
    PersonalVADResult,
    PersonalVADTrainer,
    SpeakerGate,
    VADBackbone,
)
from .phoneme_adaptation import (
    AdaptationDecision,
    AdaptationSample,
    AdaptationTier,
    PhonemeAdaptationConfig,
    PhonemeEnhancedAdaptationEngine,
    SpeakerAdaptationState,
    TieredAdaptationFallback,
    create_adaptation_engine,
)
from .phoneme_weighted_trainer import (
    LoRALinear,
    OnlinePhonemeWeightedTrainer,
    PhonemeWeightedTrainer,
    PhonemeWeightedTrainingConfig,
    SpeakerLoRAAdapter,
    TrainingResult,
)
from .speaker_encoder import SpeakerDatabase, SpeakerEncoder
from .speaker_query_attention import (
    SpeakerConditionedEncoder,
    SpeakerQueryAttention,
    SpeakerQueryConfig,
    create_speaker_conditioned_encoder,
)
from .suta import (
    SUTAAdapter,
    SUTAConfig,
    SUTAWithGradients,
    create_suta_adapter,
    diversity_loss,
    entropy_loss,
)
from .voice_focus_manager import (
    FocusMode,
    FocusResult,
    SpeakerPriority,
    SpeakerState,
    VoiceFocusConfig,
    VoiceFocusManager,
    create_voice_focus_manager,
)

__all__ = [
    "ast_config",
    "ast_mlx",
    "beats_config",
    "beats_mlx",
    "ecapa_config",
    "ecapa_tdnn",
    "emotion2vec_config",
    "emotion2vec_mlx",
    "personal_vad",
    "speaker_encoder",
    "wav2vec2_xlsr_config",
    "wav2vec2_xlsr_mlx",
    "wavlm_config",
    "wavlm_mlx",
    "ECAPATDNNConfig",
    "ECAPATDNN",
    "ECAPATDNNForLanguageID",
    "PersonalVAD",
    "PersonalVADConfig",
    "PersonalVADMLX",
    "PersonalVADResult",
    "PersonalVADTrainer",
    "SpeakerDatabase",
    "SpeakerEncoder",
    "SpeakerGate",
    "VADBackbone",
    "speaker_query_attention",
    "SpeakerConditionedEncoder",
    "SpeakerQueryAttention",
    "SpeakerQueryConfig",
    "create_speaker_conditioned_encoder",
    "moe_lora_decoder",
    "ExpertRouter",
    "LoRAExpert",
    "MoELoRAConfig",
    "MoELoRADecoder",
    "create_moe_lora_decoder",
    "suta",
    "SUTAAdapter",
    "SUTAConfig",
    "SUTAWithGradients",
    "create_suta_adapter",
    "diversity_loss",
    "entropy_loss",
    "phoneme_adaptation",
    "AdaptationDecision",
    "AdaptationSample",
    "AdaptationTier",
    "PhonemeAdaptationConfig",
    "PhonemeEnhancedAdaptationEngine",
    "SpeakerAdaptationState",
    "TieredAdaptationFallback",
    "create_adaptation_engine",
    "phoneme_weighted_trainer",
    "LoRALinear",
    "OnlinePhonemeWeightedTrainer",
    "PhonemeWeightedTrainer",
    "PhonemeWeightedTrainingConfig",
    "SpeakerLoRAAdapter",
    "TrainingResult",
    "voice_focus_manager",
    "FocusMode",
    "FocusResult",
    "SpeakerPriority",
    "SpeakerState",
    "VoiceFocusConfig",
    "VoiceFocusManager",
    "create_voice_focus_manager",
]
