2026-01-07 07:34:57,650 [INFO] Acquired training lock
2026-01-07 07:34:57,650 [INFO] Loading encoder from checkpoints/zipformer/en-streaming/exp/pretrained.pt
2026-01-07 07:34:57,780 [INFO] Encoder loaded: output_dim=512
2026-01-07 07:34:57,780 [INFO] Loading data from data/emotion/combined_emotion_hf (dataset=combined)
2026-01-07 07:34:58,515 [INFO] Train batches: 237
2026-01-07 07:34:58,515 [INFO] Val batches: 26
2026-01-07 07:34:58,546 [INFO] Head num_classes: 6
2026-01-07 07:34:58,547 [INFO] Created emotion head with 988,166 parameters
2026-01-07 07:34:58,548 [INFO] Stage 4: 11,754,487 params (UNFROZEN)
2026-01-07 07:34:58,548 [INFO] Stage 5: 3,906,660 params (UNFROZEN)
2026-01-07 07:34:58,548 [INFO] Total unfrozen encoder params: 15,661,147
2026-01-07 07:34:58,548 [INFO] Total trainable parameters: 16,649,313
2026-01-07 07:34:58,548 [WARNING] Learning rate 0.0001 is too high for encoder fine-tuning. This can cause NaN values during training. Automatically reducing to 5e-05.
2026-01-07 07:34:58,548 [INFO] Fine-tuning with encoder unfreezing: lr=5e-05 (encoder_lr parameter is ignored - both encoder and head use same lr)
2026-01-07 07:34:58,548 [INFO] ============================================================
2026-01-07 07:34:58,548 [INFO] Training Configuration
2026-01-07 07:34:58,548 [INFO] ============================================================
2026-01-07 07:34:58,548 [INFO] Head type: emotion
2026-01-07 07:34:58,548 [INFO] Encoder dim: 512
2026-01-07 07:34:58,548 [INFO] Batch size: 32
2026-01-07 07:34:58,548 [INFO] Head learning rate: 5e-05
2026-01-07 07:34:58,548 [INFO] Encoder learning rate: 1e-05
2026-01-07 07:34:58,548 [INFO] Unfrozen encoder stages: 2
2026-01-07 07:34:58,548 [INFO] Gradient clipping: 1.0
2026-01-07 07:34:58,548 [INFO] Cache clearing: every 100 steps
2026-01-07 07:34:58,548 [INFO] Label smoothing: 0.1
2026-01-07 07:34:58,548 [INFO] SpecAugment: True
2026-01-07 07:34:58,548 [INFO] Param dtype: float32
2026-01-07 07:34:58,548 [INFO] Epochs: 10
2026-01-07 07:34:58,548 [INFO] Max steps: 2370
2026-01-07 07:34:58,548 [INFO] Label key: emotion_labels
2026-01-07 07:34:58,548 [INFO] ============================================================
2026-01-07 07:34:58,549 [INFO] Created EncoderHeadModel for fine-tuning (reused across all steps)
2026-01-07 07:34:58,549 [INFO] Epoch 1/10
2026-01-07 07:35:02,550 [INFO] Step 10/2370 | Loss: 1.7863 | Acc: 0.1875 | LR: 9.00e-07
2026-01-07 07:35:05,793 [INFO] Step 20/2370 | Loss: 1.7933 | Acc: 0.1562 | LR: 1.90e-06
2026-01-07 07:35:09,124 [INFO] Step 30/2370 | Loss: 1.7966 | Acc: 0.0625 | LR: 2.90e-06
2026-01-07 07:35:12,496 [INFO] Step 40/2370 | Loss: 1.7910 | Acc: 0.2500 | LR: 3.90e-06
2026-01-07 07:35:15,839 [INFO] Step 50/2370 | Loss: 1.7920 | Acc: 0.1250 | LR: 4.90e-06
2026-01-07 07:35:19,283 [INFO] Step 60/2370 | Loss: 1.7827 | Acc: 0.2500 | LR: 5.90e-06
2026-01-07 07:35:22,730 [INFO] Step 70/2370 | Loss: 1.7969 | Acc: 0.1875 | LR: 6.90e-06
2026-01-07 07:35:26,174 [INFO] Step 80/2370 | Loss: 1.7986 | Acc: 0.1250 | LR: 7.90e-06
2026-01-07 07:35:29,648 [INFO] Step 90/2370 | Loss: 1.7723 | Acc: 0.2188 | LR: 8.90e-06
2026-01-07 07:35:33,505 [INFO] Step 100/2370 | Loss: 1.7746 | Acc: 0.2188 | LR: 9.90e-06
2026-01-07 07:35:37,754 [INFO] [EVAL] Step 100 | Val Loss: 1.7729 | Val Acc: 0.2380
2026-01-07 07:35:37,756 [INFO] New best validation accuracy: 0.2380
2026-01-07 07:35:41,328 [INFO] Step 110/2370 | Loss: 1.7795 | Acc: 0.2500 | LR: 1.09e-05
2026-01-07 07:35:45,066 [INFO] Step 120/2370 | Loss: 1.7431 | Acc: 0.2500 | LR: 1.19e-05
2026-01-07 07:35:48,787 [INFO] Step 130/2370 | Loss: 1.7415 | Acc: 0.2500 | LR: 1.29e-05
2026-01-07 07:35:52,569 [INFO] Step 140/2370 | Loss: 1.7184 | Acc: 0.2188 | LR: 1.39e-05
2026-01-07 07:35:56,307 [INFO] Step 150/2370 | Loss: 1.7844 | Acc: 0.3125 | LR: 1.49e-05
2026-01-07 07:36:00,222 [INFO] Step 160/2370 | Loss: 1.7125 | Acc: 0.4062 | LR: 1.59e-05
2026-01-07 07:36:04,035 [INFO] Step 170/2370 | Loss: 1.7365 | Acc: 0.3125 | LR: 1.69e-05
2026-01-07 07:36:07,788 [INFO] Step 180/2370 | Loss: 1.8729 | Acc: 0.1250 | LR: 1.79e-05
2026-01-07 07:36:11,589 [INFO] Step 190/2370 | Loss: 1.7355 | Acc: 0.1250 | LR: 1.89e-05
2026-01-07 07:36:17,205 [INFO] Step 200/2370 | Loss: 1.7967 | Acc: 0.3125 | LR: 1.99e-05
2026-01-07 07:36:21,355 [INFO] [EVAL] Step 200 | Val Loss: 1.7742 | Val Acc: 0.2212
2026-01-07 07:36:24,578 [INFO] Step 210/2370 | Loss: 1.8114 | Acc: 0.2500 | LR: 2.09e-05
2026-01-07 07:36:27,793 [INFO] Step 220/2370 | Loss: 1.7557 | Acc: 0.1875 | LR: 2.19e-05
2026-01-07 07:36:30,953 [INFO] Step 230/2370 | Loss: 1.6989 | Acc: 0.3750 | LR: 2.29e-05
2026-01-07 07:36:33,160 [INFO] Epoch 1 complete | Avg Loss: 1.7662 | Avg Acc: 0.2211 | Updates: 237 | Micro-batches: 237 | Skipped: 0 (loss=0, logits=0, grads=0)
2026-01-07 07:36:33,160 [INFO] Epoch 2/10
2026-01-07 07:36:34,260 [INFO] Step 240/2370 | Loss: 1.6763 | Acc: 0.3125 | LR: 2.39e-05
2026-01-07 07:36:37,522 [INFO] Step 250/2370 | Loss: 1.6404 | Acc: 0.4062 | LR: 2.49e-05
2026-01-07 07:36:40,799 [INFO] Step 260/2370 | Loss: 1.7891 | Acc: 0.1875 | LR: 2.59e-05
2026-01-07 07:36:44,035 [INFO] Step 270/2370 | Loss: 1.7498 | Acc: 0.1875 | LR: 2.69e-05
2026-01-07 07:36:47,268 [INFO] Step 280/2370 | Loss: 1.7334 | Acc: 0.2812 | LR: 2.79e-05
2026-01-07 07:36:50,501 [INFO] Step 290/2370 | Loss: 1.8029 | Acc: 0.1875 | LR: 2.89e-05
2026-01-07 07:36:54,303 [INFO] Step 300/2370 | Loss: 1.7530 | Acc: 0.3125 | LR: 2.99e-05
2026-01-07 07:36:58,496 [INFO] [EVAL] Step 300 | Val Loss: 1.7262 | Val Acc: 0.2572
2026-01-07 07:36:58,498 [INFO] New best validation accuracy: 0.2572
2026-01-07 07:37:01,751 [INFO] Step 310/2370 | Loss: 1.7348 | Acc: 0.4062 | LR: 3.09e-05
2026-01-07 07:37:05,048 [INFO] Step 320/2370 | Loss: 1.7001 | Acc: 0.3438 | LR: 3.19e-05
2026-01-07 07:37:08,339 [INFO] Step 330/2370 | Loss: 1.7135 | Acc: 0.2500 | LR: 3.29e-05
2026-01-07 07:37:11,501 [INFO] Step 340/2370 | Loss: 1.6337 | Acc: 0.4375 | LR: 3.39e-05
2026-01-07 07:37:14,787 [INFO] Step 350/2370 | Loss: 1.7424 | Acc: 0.2188 | LR: 3.49e-05
2026-01-07 07:37:17,983 [INFO] Step 360/2370 | Loss: 1.6392 | Acc: 0.5000 | LR: 3.59e-05
2026-01-07 07:37:21,217 [INFO] Step 370/2370 | Loss: 1.7224 | Acc: 0.2500 | LR: 3.69e-05
2026-01-07 07:37:24,553 [INFO] Step 380/2370 | Loss: 1.6572 | Acc: 0.4062 | LR: 3.79e-05
2026-01-07 07:37:27,809 [INFO] Step 390/2370 | Loss: 1.7510 | Acc: 0.2812 | LR: 3.89e-05
2026-01-07 07:37:31,527 [INFO] Step 400/2370 | Loss: 1.6531 | Acc: 0.3125 | LR: 3.99e-05
2026-01-07 07:37:35,720 [INFO] [EVAL] Step 400 | Val Loss: 1.6953 | Val Acc: 0.2512
2026-01-07 07:37:38,883 [INFO] Step 410/2370 | Loss: 1.7327 | Acc: 0.1875 | LR: 4.09e-05
2026-01-07 07:37:42,128 [INFO] Step 420/2370 | Loss: 1.6701 | Acc: 0.4375 | LR: 4.19e-05
2026-01-07 07:37:45,307 [INFO] Step 430/2370 | Loss: 1.7714 | Acc: 0.3750 | LR: 4.29e-05
2026-01-07 07:37:48,419 [INFO] Step 440/2370 | Loss: 1.6985 | Acc: 0.2188 | LR: 4.39e-05
2026-01-07 07:37:51,553 [INFO] Step 450/2370 | Loss: 1.7655 | Acc: 0.1562 | LR: 4.49e-05
2026-01-07 07:37:54,832 [INFO] Step 460/2370 | Loss: 1.6734 | Acc: 0.1875 | LR: 4.59e-05
2026-01-07 07:37:58,093 [INFO] Step 470/2370 | Loss: 1.9293 | Acc: 0.1562 | LR: 4.69e-05
2026-01-07 07:37:59,450 [INFO] Epoch 2 complete | Avg Loss: 1.7036 | Avg Acc: 0.2849 | Updates: 237 | Micro-batches: 237 | Skipped: 0 (loss=0, logits=0, grads=0)
2026-01-07 07:37:59,451 [INFO] Epoch 3/10
2026-01-07 07:38:01,542 [INFO] Step 480/2370 | Loss: 1.6703 | Acc: 0.4062 | LR: 4.79e-05
2026-01-07 07:38:04,863 [INFO] Step 490/2370 | Loss: 1.7574 | Acc: 0.2812 | LR: 4.89e-05
2026-01-07 07:38:08,653 [INFO] Step 500/2370 | Loss: 1.5952 | Acc: 0.3750 | LR: 4.99e-05
2026-01-07 07:38:12,915 [INFO] [EVAL] Step 500 | Val Loss: 1.6752 | Val Acc: 0.2861
2026-01-07 07:38:12,917 [INFO] New best validation accuracy: 0.2861
2026-01-07 07:38:16,175 [INFO] Step 510/2370 | Loss: 1.6184 | Acc: 0.4375 | LR: 5.00e-05
2026-01-07 07:38:19,455 [INFO] Step 520/2370 | Loss: 1.7888 | Acc: 0.3125 | LR: 5.00e-05
2026-01-07 07:38:22,652 [INFO] Step 530/2370 | Loss: 1.8512 | Acc: 0.1562 | LR: 5.00e-05
2026-01-07 07:38:25,950 [INFO] Step 540/2370 | Loss: 1.7920 | Acc: 0.2188 | LR: 4.99e-05
2026-01-07 07:38:29,331 [INFO] Step 550/2370 | Loss: 1.5785 | Acc: 0.4062 | LR: 4.99e-05
2026-01-07 07:38:32,639 [INFO] Step 560/2370 | Loss: 1.6980 | Acc: 0.2812 | LR: 4.99e-05
2026-01-07 07:38:35,953 [INFO] Step 570/2370 | Loss: 1.7281 | Acc: 0.2812 | LR: 4.98e-05
2026-01-07 07:38:39,235 [INFO] Step 580/2370 | Loss: 1.6014 | Acc: 0.4062 | LR: 4.98e-05
2026-01-07 07:38:42,550 [INFO] Step 590/2370 | Loss: 1.6241 | Acc: 0.3125 | LR: 4.97e-05
2026-01-07 07:38:46,415 [INFO] Step 600/2370 | Loss: 1.6727 | Acc: 0.3438 | LR: 4.97e-05
2026-01-07 07:38:50,675 [INFO] [EVAL] Step 600 | Val Loss: 1.6702 | Val Acc: 0.2921
2026-01-07 07:38:50,677 [INFO] New best validation accuracy: 0.2921
2026-01-07 07:38:53,944 [INFO] Step 610/2370 | Loss: 1.5868 | Acc: 0.3750 | LR: 4.96e-05
2026-01-07 07:38:57,175 [INFO] Step 620/2370 | Loss: 1.5684 | Acc: 0.2812 | LR: 4.95e-05
2026-01-07 07:39:00,457 [INFO] Step 630/2370 | Loss: 1.6307 | Acc: 0.3438 | LR: 4.94e-05
2026-01-07 07:39:03,654 [INFO] Step 640/2370 | Loss: 1.5478 | Acc: 0.3750 | LR: 4.93e-05
2026-01-07 07:39:06,948 [INFO] Step 650/2370 | Loss: 1.7019 | Acc: 0.2812 | LR: 4.92e-05
2026-01-07 07:39:10,296 [INFO] Step 660/2370 | Loss: 1.5746 | Acc: 0.3125 | LR: 4.91e-05
2026-01-07 07:39:13,591 [INFO] Step 670/2370 | Loss: 1.6698 | Acc: 0.3438 | LR: 4.90e-05
2026-01-07 07:39:16,932 [INFO] Step 680/2370 | Loss: 1.6007 | Acc: 0.3438 | LR: 4.89e-05
2026-01-07 07:39:20,166 [INFO] Step 690/2370 | Loss: 1.6210 | Acc: 0.3125 | LR: 4.88e-05
2026-01-07 07:39:23,956 [INFO] Step 700/2370 | Loss: 1.6770 | Acc: 0.2500 | LR: 4.86e-05
2026-01-07 07:39:28,158 [INFO] [EVAL] Step 700 | Val Loss: 1.5666 | Val Acc: 0.3257
2026-01-07 07:39:28,161 [INFO] New best validation accuracy: 0.3257
2026-01-07 07:39:31,344 [INFO] Step 710/2370 | Loss: 1.6180 | Acc: 0.3125 | LR: 4.85e-05
2026-01-07 07:39:31,639 [INFO] Epoch 3 complete | Avg Loss: 1.6362 | Avg Acc: 0.3273 | Updates: 237 | Micro-batches: 237 | Skipped: 0 (loss=0, logits=0, grads=0)
2026-01-07 07:39:31,639 [INFO] Epoch 4/10
2026-01-07 07:39:34,713 [INFO] Step 720/2370 | Loss: 1.6621 | Acc: 0.3750 | LR: 4.84e-05
2026-01-07 07:39:37,896 [INFO] Step 730/2370 | Loss: 1.4825 | Acc: 0.5000 | LR: 4.82e-05
2026-01-07 07:39:41,147 [INFO] Step 740/2370 | Loss: 1.4666 | Acc: 0.4375 | LR: 4.81e-05
2026-01-07 07:39:44,481 [INFO] Step 750/2370 | Loss: 1.5932 | Acc: 0.2812 | LR: 4.79e-05
2026-01-07 07:39:47,739 [INFO] Step 760/2370 | Loss: 1.6034 | Acc: 0.3438 | LR: 4.77e-05
2026-01-07 07:39:50,989 [INFO] Step 770/2370 | Loss: 1.6608 | Acc: 0.3750 | LR: 4.75e-05
2026-01-07 07:39:54,226 [INFO] Step 780/2370 | Loss: 1.6876 | Acc: 0.2812 | LR: 4.74e-05
2026-01-07 07:39:57,755 [INFO] Step 790/2370 | Loss: 1.5521 | Acc: 0.3125 | LR: 4.72e-05
2026-01-07 07:40:01,604 [INFO] Step 800/2370 | Loss: 1.5176 | Acc: 0.4688 | LR: 4.70e-05
2026-01-07 07:40:05,887 [INFO] [EVAL] Step 800 | Val Loss: 1.5479 | Val Acc: 0.3510
2026-01-07 07:40:05,890 [INFO] New best validation accuracy: 0.3510
2026-01-07 07:40:09,147 [INFO] Step 810/2370 | Loss: 1.4450 | Acc: 0.3438 | LR: 4.68e-05
2026-01-07 07:40:12,303 [INFO] Step 820/2370 | Loss: 1.4691 | Acc: 0.4062 | LR: 4.66e-05
2026-01-07 07:40:15,635 [INFO] Step 830/2370 | Loss: 1.7045 | Acc: 0.2812 | LR: 4.64e-05
2026-01-07 07:40:18,874 [INFO] Step 840/2370 | Loss: 1.5759 | Acc: 0.4375 | LR: 4.61e-05
2026-01-07 07:40:22,084 [INFO] Step 850/2370 | Loss: 1.5155 | Acc: 0.4062 | LR: 4.59e-05
2026-01-07 07:40:25,529 [INFO] Step 860/2370 | Loss: 1.6156 | Acc: 0.3438 | LR: 4.57e-05
2026-01-07 07:40:28,774 [INFO] Step 870/2370 | Loss: 1.5638 | Acc: 0.3125 | LR: 4.54e-05
2026-01-07 07:40:31,993 [INFO] Step 880/2370 | Loss: 1.6188 | Acc: 0.3438 | LR: 4.52e-05
2026-01-07 07:40:35,276 [INFO] Step 890/2370 | Loss: 1.6048 | Acc: 0.3750 | LR: 4.50e-05
2026-01-07 07:40:39,102 [INFO] Step 900/2370 | Loss: 1.5970 | Acc: 0.4062 | LR: 4.47e-05
2026-01-07 07:40:43,340 [INFO] [EVAL] Step 900 | Val Loss: 1.5252 | Val Acc: 0.3786
2026-01-07 07:40:43,342 [INFO] New best validation accuracy: 0.3786
2026-01-07 07:40:46,599 [INFO] Step 910/2370 | Loss: 1.5561 | Acc: 0.3750 | LR: 4.44e-05
2026-01-07 07:40:49,870 [INFO] Step 920/2370 | Loss: 1.5482 | Acc: 0.3125 | LR: 4.42e-05
2026-01-07 07:40:51,072 [WARNING] Skipping batch due to non-finite loss at step=923 (loss=nan, epoch=4).
2026-01-07 07:40:51,949 [WARNING] Skipping batch due to non-finite loss at step=925 (loss=nan, epoch=4).
2026-01-07 07:40:53,147 [WARNING] Skipping batch due to non-finite loss at step=928 (loss=nan, epoch=4).
2026-01-07 07:40:53,653 [WARNING] Skipping batch due to non-finite loss at step=929 (loss=nan, epoch=4).
2026-01-07 07:40:54,001 [INFO] Step 930/2370 | Loss: 1.7457 | Acc: 0.3125 | LR: 4.39e-05
2026-01-07 07:40:54,192 [WARNING] Skipping batch due to non-finite loss at step=930 (loss=nan, epoch=4).
2026-01-07 07:40:55,026 [WARNING] Skipping batch due to non-finite loss at step=932 (loss=nan, epoch=4).
2026-01-07 07:40:55,187 [WARNING] Skipping batch due to non-finite loss at step=932 (loss=nan, epoch=4).
2026-01-07 07:40:56,386 [WARNING] Skipping batch due to non-finite loss at step=935 (loss=nan, epoch=4).
2026-01-07 07:40:58,013 [INFO] Step 940/2370 | Loss: 1.5071 | Acc: 0.5312 | LR: 4.36e-05
2026-01-07 07:40:58,013 [INFO] Epoch 4 complete | Avg Loss: 1.5813 | Avg Acc: 0.3684 | Updates: 229 | Micro-batches: 237 | Skipped: 8 (loss=8, logits=0, grads=0)
2026-01-07 07:40:58,013 [INFO] Epoch 5/10
2026-01-07 07:40:58,666 [WARNING] Skipping batch due to non-finite loss at step=941 (loss=nan, epoch=5).
2026-01-07 07:41:01,558 [INFO] Step 950/2370 | Loss: 1.6747 | Acc: 0.3125 | LR: 4.34e-05
2026-01-07 07:41:04,829 [INFO] Step 960/2370 | Loss: 1.4571 | Acc: 0.4688 | LR: 4.31e-05
2026-01-07 07:41:08,088 [INFO] Step 970/2370 | Loss: 1.7567 | Acc: 0.3125 | LR: 4.28e-05
2026-01-07 07:41:11,343 [INFO] Step 980/2370 | Loss: 1.6416 | Acc: 0.3438 | LR: 4.25e-05
2026-01-07 07:41:14,540 [INFO] Step 990/2370 | Loss: 1.6234 | Acc: 0.3750 | LR: 4.22e-05
2026-01-07 07:41:18,278 [INFO] Step 1000/2370 | Loss: 1.5371 | Acc: 0.3750 | LR: 4.19e-05
2026-01-07 07:41:22,475 [INFO] [EVAL] Step 1000 | Val Loss: 1.4443 | Val Acc: 0.3978
2026-01-07 07:41:22,476 [INFO] New best validation accuracy: 0.3978
2026-01-07 07:41:25,777 [INFO] Step 1010/2370 | Loss: 1.4809 | Acc: 0.4375 | LR: 4.16e-05
2026-01-07 07:41:29,040 [INFO] Step 1020/2370 | Loss: 1.5996 | Acc: 0.3438 | LR: 4.13e-05
2026-01-07 07:41:32,302 [INFO] Step 1030/2370 | Loss: 1.5935 | Acc: 0.3750 | LR: 4.09e-05
2026-01-07 07:41:35,529 [INFO] Step 1040/2370 | Loss: 1.3879 | Acc: 0.5312 | LR: 4.06e-05
2026-01-07 07:41:38,751 [INFO] Step 1050/2370 | Loss: 1.6118 | Acc: 0.3750 | LR: 4.03e-05
2026-01-07 07:41:42,050 [INFO] Step 1060/2370 | Loss: 1.5055 | Acc: 0.3438 | LR: 4.00e-05
2026-01-07 07:41:45,354 [INFO] Step 1070/2370 | Loss: 1.5273 | Acc: 0.4062 | LR: 3.96e-05
2026-01-07 07:41:48,591 [INFO] Step 1080/2370 | Loss: 1.4032 | Acc: 0.5000 | LR: 3.93e-05
2026-01-07 07:41:51,904 [INFO] Step 1090/2370 | Loss: 1.5863 | Acc: 0.3125 | LR: 3.90e-05
2026-01-07 07:41:55,639 [INFO] Step 1100/2370 | Loss: 1.4083 | Acc: 0.4375 | LR: 3.86e-05
2026-01-07 07:41:59,952 [INFO] [EVAL] Step 1100 | Val Loss: 1.4607 | Val Acc: 0.4099
2026-01-07 07:41:59,954 [INFO] New best validation accuracy: 0.4099
2026-01-07 07:42:03,185 [INFO] Step 1110/2370 | Loss: 1.5886 | Acc: 0.3750 | LR: 3.83e-05
2026-01-07 07:42:06,434 [INFO] Step 1120/2370 | Loss: 1.5468 | Acc: 0.3438 | LR: 3.79e-05
2026-01-07 07:42:09,700 [INFO] Step 1130/2370 | Loss: 1.5433 | Acc: 0.3750 | LR: 3.75e-05
2026-01-07 07:42:12,958 [INFO] Step 1140/2370 | Loss: 1.5784 | Acc: 0.3438 | LR: 3.72e-05
2026-01-07 07:42:16,167 [INFO] Step 1150/2370 | Loss: 1.3225 | Acc: 0.5312 | LR: 3.68e-05
2026-01-07 07:42:19,452 [INFO] Step 1160/2370 | Loss: 1.5834 | Acc: 0.3438 | LR: 3.65e-05
2026-01-07 07:42:22,731 [INFO] Step 1170/2370 | Loss: 1.5704 | Acc: 0.3438 | LR: 3.61e-05
2026-01-07 07:42:24,757 [INFO] Epoch 5 complete | Avg Loss: 1.5269 | Avg Acc: 0.4049 | Updates: 236 | Micro-batches: 237 | Skipped: 1 (loss=1, logits=0, grads=0)
2026-01-07 07:42:24,757 [INFO] Epoch 6/10
2026-01-07 07:42:26,287 [INFO] Step 1180/2370 | Loss: 1.4073 | Acc: 0.4688 | LR: 3.57e-05
2026-01-07 07:42:29,635 [INFO] Step 1190/2370 | Loss: 1.4875 | Acc: 0.4062 | LR: 3.53e-05
2026-01-07 07:42:33,388 [INFO] Step 1200/2370 | Loss: 1.5002 | Acc: 0.3750 | LR: 3.50e-05
2026-01-07 07:42:37,588 [INFO] [EVAL] Step 1200 | Val Loss: 1.4278 | Val Acc: 0.4279
2026-01-07 07:42:37,590 [INFO] New best validation accuracy: 0.4279
2026-01-07 07:42:40,793 [INFO] Step 1210/2370 | Loss: 1.4343 | Acc: 0.5625 | LR: 3.46e-05
2026-01-07 07:42:44,004 [INFO] Step 1220/2370 | Loss: 1.4891 | Acc: 0.4062 | LR: 3.42e-05
2026-01-07 07:42:47,243 [INFO] Step 1230/2370 | Loss: 1.5608 | Acc: 0.3750 | LR: 3.38e-05
2026-01-07 07:42:50,488 [INFO] Step 1240/2370 | Loss: 1.4596 | Acc: 0.4062 | LR: 3.34e-05
2026-01-07 07:42:53,656 [INFO] Step 1250/2370 | Loss: 1.5622 | Acc: 0.2812 | LR: 3.30e-05
2026-01-07 07:42:56,801 [INFO] Step 1260/2370 | Loss: 1.7173 | Acc: 0.4062 | LR: 3.26e-05
2026-01-07 07:43:00,108 [INFO] Step 1270/2370 | Loss: 1.4775 | Acc: 0.4062 | LR: 3.22e-05
2026-01-07 07:43:03,365 [INFO] Step 1280/2370 | Loss: 1.4218 | Acc: 0.5625 | LR: 3.18e-05
2026-01-07 07:43:06,561 [INFO] Step 1290/2370 | Loss: 1.5238 | Acc: 0.4375 | LR: 3.14e-05
2026-01-07 07:43:10,242 [INFO] Step 1300/2370 | Loss: 1.3686 | Acc: 0.5625 | LR: 3.10e-05
2026-01-07 07:43:14,532 [INFO] [EVAL] Step 1300 | Val Loss: 1.3936 | Val Acc: 0.4303
2026-01-07 07:43:14,534 [INFO] New best validation accuracy: 0.4303
2026-01-07 07:43:17,843 [INFO] Step 1310/2370 | Loss: 1.4473 | Acc: 0.3438 | LR: 3.06e-05
2026-01-07 07:43:21,100 [INFO] Step 1320/2370 | Loss: 1.5001 | Acc: 0.4062 | LR: 3.02e-05
2026-01-07 07:43:24,395 [INFO] Step 1330/2370 | Loss: 1.4826 | Acc: 0.5000 | LR: 2.98e-05
2026-01-07 07:43:27,569 [INFO] Step 1340/2370 | Loss: 1.4721 | Acc: 0.4062 | LR: 2.94e-05
2026-01-07 07:43:30,920 [INFO] Step 1350/2370 | Loss: 1.4188 | Acc: 0.4688 | LR: 2.90e-05
2026-01-07 07:43:34,277 [INFO] Step 1360/2370 | Loss: 1.4689 | Acc: 0.4688 | LR: 2.86e-05
2026-01-07 07:43:37,592 [INFO] Step 1370/2370 | Loss: 1.4741 | Acc: 0.4062 | LR: 2.82e-05
2026-01-07 07:43:40,948 [INFO] Step 1380/2370 | Loss: 1.4711 | Acc: 0.4688 | LR: 2.78e-05
2026-01-07 07:43:44,173 [INFO] Step 1390/2370 | Loss: 1.6432 | Acc: 0.3125 | LR: 2.74e-05
2026-01-07 07:43:48,003 [INFO] Step 1400/2370 | Loss: 1.4116 | Acc: 0.5938 | LR: 2.70e-05
2026-01-07 07:43:52,399 [INFO] [EVAL] Step 1400 | Val Loss: 1.3973 | Val Acc: 0.4387
2026-01-07 07:43:52,402 [INFO] New best validation accuracy: 0.4387
2026-01-07 07:43:55,658 [INFO] Step 1410/2370 | Loss: 1.5585 | Acc: 0.3438 | LR: 2.66e-05
2026-01-07 07:43:56,649 [INFO] Epoch 6 complete | Avg Loss: 1.4886 | Avg Acc: 0.4235 | Updates: 237 | Micro-batches: 237 | Skipped: 0 (loss=0, logits=0, grads=0)
2026-01-07 07:43:56,649 [INFO] Epoch 7/10
2026-01-07 07:43:59,116 [INFO] Step 1420/2370 | Loss: 1.3983 | Acc: 0.4688 | LR: 2.62e-05
2026-01-07 07:44:02,472 [INFO] Step 1430/2370 | Loss: 1.3705 | Acc: 0.5938 | LR: 2.57e-05
2026-01-07 07:44:05,800 [INFO] Step 1440/2370 | Loss: 1.4022 | Acc: 0.5000 | LR: 2.53e-05
2026-01-07 07:44:09,124 [INFO] Step 1450/2370 | Loss: 1.5605 | Acc: 0.3125 | LR: 2.49e-05
2026-01-07 07:44:12,378 [INFO] Step 1460/2370 | Loss: 1.4468 | Acc: 0.4062 | LR: 2.45e-05
2026-01-07 07:44:15,788 [INFO] Step 1470/2370 | Loss: 1.4390 | Acc: 0.4375 | LR: 2.41e-05
2026-01-07 07:44:19,069 [INFO] Step 1480/2370 | Loss: 1.5667 | Acc: 0.4062 | LR: 2.37e-05
2026-01-07 07:44:22,457 [INFO] Step 1490/2370 | Loss: 1.4333 | Acc: 0.5625 | LR: 2.33e-05
2026-01-07 07:44:26,283 [INFO] Step 1500/2370 | Loss: 1.5054 | Acc: 0.5312 | LR: 2.29e-05
2026-01-07 07:44:30,370 [INFO] [EVAL] Step 1500 | Val Loss: 1.3744 | Val Acc: 0.4327
2026-01-07 07:44:33,679 [INFO] Step 1510/2370 | Loss: 1.4469 | Acc: 0.4375 | LR: 2.25e-05
2026-01-07 07:44:36,934 [INFO] Step 1520/2370 | Loss: 1.4457 | Acc: 0.4375 | LR: 2.21e-05
2026-01-07 07:44:40,293 [INFO] Step 1530/2370 | Loss: 1.4787 | Acc: 0.3438 | LR: 2.16e-05
2026-01-07 07:44:43,538 [INFO] Step 1540/2370 | Loss: 1.4628 | Acc: 0.3125 | LR: 2.12e-05
2026-01-07 07:44:46,856 [INFO] Step 1550/2370 | Loss: 1.5264 | Acc: 0.4375 | LR: 2.08e-05
2026-01-07 07:44:50,203 [INFO] Step 1560/2370 | Loss: 1.5791 | Acc: 0.3125 | LR: 2.04e-05
2026-01-07 07:44:53,518 [INFO] Step 1570/2370 | Loss: 1.3689 | Acc: 0.4062 | LR: 2.00e-05
2026-01-07 07:44:56,730 [INFO] Step 1580/2370 | Loss: 1.5096 | Acc: 0.5000 | LR: 1.96e-05
2026-01-07 07:44:59,974 [INFO] Step 1590/2370 | Loss: 1.4572 | Acc: 0.5000 | LR: 1.92e-05
2026-01-07 07:45:03,809 [INFO] Step 1600/2370 | Loss: 1.5584 | Acc: 0.3750 | LR: 1.88e-05
2026-01-07 07:45:07,951 [INFO] [EVAL] Step 1600 | Val Loss: 1.3625 | Val Acc: 0.4303
2026-01-07 07:45:11,280 [INFO] Step 1610/2370 | Loss: 1.4980 | Acc: 0.3750 | LR: 1.84e-05
2026-01-07 07:45:14,698 [INFO] Step 1620/2370 | Loss: 1.3976 | Acc: 0.5000 | LR: 1.80e-05
2026-01-07 07:45:18,059 [INFO] Step 1630/2370 | Loss: 1.4720 | Acc: 0.3750 | LR: 1.77e-05
2026-01-07 07:45:21,425 [INFO] Step 1640/2370 | Loss: 1.2724 | Acc: 0.5938 | LR: 1.73e-05
2026-01-07 07:45:24,763 [INFO] Step 1650/2370 | Loss: 1.3720 | Acc: 0.5000 | LR: 1.69e-05
2026-01-07 07:45:24,763 [INFO] Epoch 7 complete | Avg Loss: 1.4608 | Avg Acc: 0.4379 | Updates: 237 | Micro-batches: 237 | Skipped: 0 (loss=0, logits=0, grads=0)
2026-01-07 07:45:24,763 [INFO] Epoch 8/10
2026-01-07 07:45:28,155 [INFO] Step 1660/2370 | Loss: 1.3827 | Acc: 0.5625 | LR: 1.65e-05
2026-01-07 07:45:31,574 [INFO] Step 1670/2370 | Loss: 1.4780 | Acc: 0.4062 | LR: 1.61e-05
2026-01-07 07:45:34,774 [INFO] Step 1680/2370 | Loss: 1.5705 | Acc: 0.2812 | LR: 1.57e-05
2026-01-07 07:45:38,180 [INFO] Step 1690/2370 | Loss: 1.3805 | Acc: 0.5000 | LR: 1.54e-05
2026-01-07 07:45:42,020 [INFO] Step 1700/2370 | Loss: 1.5359 | Acc: 0.3438 | LR: 1.50e-05
2026-01-07 07:45:46,352 [INFO] [EVAL] Step 1700 | Val Loss: 1.3754 | Val Acc: 0.4483
2026-01-07 07:45:46,354 [INFO] New best validation accuracy: 0.4483
2026-01-07 07:45:49,610 [INFO] Step 1710/2370 | Loss: 1.3087 | Acc: 0.5625 | LR: 1.46e-05
2026-01-07 07:45:52,836 [INFO] Step 1720/2370 | Loss: 1.3768 | Acc: 0.5312 | LR: 1.42e-05
2026-01-07 07:45:56,231 [INFO] Step 1730/2370 | Loss: 1.3892 | Acc: 0.5000 | LR: 1.39e-05
2026-01-07 07:45:59,634 [INFO] Step 1740/2370 | Loss: 1.3999 | Acc: 0.4375 | LR: 1.35e-05
2026-01-07 07:46:02,891 [INFO] Step 1750/2370 | Loss: 1.5392 | Acc: 0.4062 | LR: 1.32e-05
2026-01-07 07:46:06,175 [INFO] Step 1760/2370 | Loss: 1.4066 | Acc: 0.3750 | LR: 1.28e-05
2026-01-07 07:46:09,543 [INFO] Step 1770/2370 | Loss: 1.4196 | Acc: 0.5312 | LR: 1.25e-05
2026-01-07 07:46:12,927 [INFO] Step 1780/2370 | Loss: 1.5448 | Acc: 0.4375 | LR: 1.21e-05
2026-01-07 07:46:16,262 [INFO] Step 1790/2370 | Loss: 1.4169 | Acc: 0.4375 | LR: 1.18e-05
2026-01-07 07:46:19,914 [INFO] Step 1800/2370 | Loss: 1.6229 | Acc: 0.5000 | LR: 1.14e-05
2026-01-07 07:46:24,066 [INFO] [EVAL] Step 1800 | Val Loss: 1.3501 | Val Acc: 0.4411
2026-01-07 07:46:27,345 [INFO] Step 1810/2370 | Loss: 1.3699 | Acc: 0.5312 | LR: 1.11e-05
2026-01-07 07:46:30,585 [INFO] Step 1820/2370 | Loss: 1.4179 | Acc: 0.4375 | LR: 1.08e-05
2026-01-07 07:46:33,852 [INFO] Step 1830/2370 | Loss: 1.4460 | Acc: 0.4375 | LR: 1.04e-05
2026-01-07 07:46:37,275 [INFO] Step 1840/2370 | Loss: 1.4416 | Acc: 0.4062 | LR: 1.01e-05
2026-01-07 07:46:40,563 [INFO] Step 1850/2370 | Loss: 1.4202 | Acc: 0.4375 | LR: 9.80e-06
2026-01-07 07:46:43,876 [INFO] Step 1860/2370 | Loss: 1.3905 | Acc: 0.5312 | LR: 9.49e-06
2026-01-07 07:46:47,134 [INFO] Step 1870/2370 | Loss: 1.4106 | Acc: 0.4062 | LR: 9.18e-06
2026-01-07 07:46:50,424 [INFO] Step 1880/2370 | Loss: 1.4755 | Acc: 0.5000 | LR: 8.87e-06
2026-01-07 07:46:52,717 [INFO] Epoch 8 complete | Avg Loss: 1.4367 | Avg Acc: 0.4568 | Updates: 237 | Micro-batches: 237 | Skipped: 0 (loss=0, logits=0, grads=0)
2026-01-07 07:46:52,718 [INFO] Epoch 9/10
2026-01-07 07:46:53,896 [INFO] Step 1890/2370 | Loss: 1.3206 | Acc: 0.5625 | LR: 8.57e-06
2026-01-07 07:46:57,557 [INFO] Step 1900/2370 | Loss: 1.5175 | Acc: 0.4375 | LR: 8.28e-06
2026-01-07 07:47:01,551 [INFO] [EVAL] Step 1900 | Val Loss: 1.3533 | Val Acc: 0.4363
2026-01-07 07:47:04,831 [INFO] Step 1910/2370 | Loss: 1.4635 | Acc: 0.4375 | LR: 7.99e-06
2026-01-07 07:47:08,148 [INFO] Step 1920/2370 | Loss: 1.4822 | Acc: 0.4375 | LR: 7.70e-06
2026-01-07 07:47:11,440 [INFO] Step 1930/2370 | Loss: 1.3627 | Acc: 0.5312 | LR: 7.42e-06
2026-01-07 07:47:14,773 [INFO] Step 1940/2370 | Loss: 1.5448 | Acc: 0.3125 | LR: 7.15e-06
2026-01-07 07:47:18,140 [INFO] Step 1950/2370 | Loss: 1.3635 | Acc: 0.5312 | LR: 6.88e-06
2026-01-07 07:47:21,495 [INFO] Step 1960/2370 | Loss: 1.5434 | Acc: 0.3750 | LR: 6.61e-06
2026-01-07 07:47:24,868 [INFO] Step 1970/2370 | Loss: 1.4532 | Acc: 0.4688 | LR: 6.35e-06
2026-01-07 07:47:28,286 [INFO] Step 1980/2370 | Loss: 1.3547 | Acc: 0.4688 | LR: 6.10e-06
2026-01-07 07:47:31,715 [INFO] Step 1990/2370 | Loss: 1.5917 | Acc: 0.2188 | LR: 5.85e-06
2026-01-07 07:47:35,493 [INFO] Step 2000/2370 | Loss: 1.4770 | Acc: 0.4375 | LR: 5.61e-06
2026-01-07 07:47:39,788 [INFO] [EVAL] Step 2000 | Val Loss: 1.3545 | Val Acc: 0.4399
2026-01-07 07:47:43,105 [INFO] Step 2010/2370 | Loss: 1.4492 | Acc: 0.4375 | LR: 5.37e-06
2026-01-07 07:47:46,365 [INFO] Step 2020/2370 | Loss: 1.3318 | Acc: 0.4375 | LR: 5.14e-06
2026-01-07 07:47:49,673 [INFO] Step 2030/2370 | Loss: 1.3089 | Acc: 0.5000 | LR: 4.91e-06
2026-01-07 07:47:53,053 [INFO] Step 2040/2370 | Loss: 1.2825 | Acc: 0.5000 | LR: 4.69e-06
2026-01-07 07:47:56,441 [INFO] Step 2050/2370 | Loss: 1.4243 | Acc: 0.4062 | LR: 4.48e-06
2026-01-07 07:47:59,751 [INFO] Step 2060/2370 | Loss: 1.4367 | Acc: 0.5000 | LR: 4.27e-06
2026-01-07 07:48:03,100 [INFO] Step 2070/2370 | Loss: 1.4497 | Acc: 0.3750 | LR: 4.07e-06
2026-01-07 07:48:06,381 [INFO] Step 2080/2370 | Loss: 1.7047 | Acc: 0.3125 | LR: 3.87e-06
2026-01-07 07:48:09,588 [INFO] Step 2090/2370 | Loss: 1.5643 | Acc: 0.3750 | LR: 3.68e-06
2026-01-07 07:48:13,342 [INFO] Step 2100/2370 | Loss: 1.3400 | Acc: 0.5625 | LR: 3.50e-06
2026-01-07 07:48:17,664 [INFO] [EVAL] Step 2100 | Val Loss: 1.3505 | Val Acc: 0.4459
2026-01-07 07:48:21,026 [INFO] Step 2110/2370 | Loss: 1.4349 | Acc: 0.3750 | LR: 3.32e-06
2026-01-07 07:48:24,276 [INFO] Step 2120/2370 | Loss: 1.2574 | Acc: 0.5312 | LR: 3.15e-06
2026-01-07 07:48:25,648 [INFO] Epoch 9 complete | Avg Loss: 1.4192 | Avg Acc: 0.4651 | Updates: 237 | Micro-batches: 237 | Skipped: 0 (loss=0, logits=0, grads=0)
2026-01-07 07:48:25,648 [INFO] Epoch 10/10
2026-01-07 07:48:27,798 [INFO] Step 2130/2370 | Loss: 1.4037 | Acc: 0.4688 | LR: 2.98e-06
2026-01-07 07:48:31,189 [INFO] Step 2140/2370 | Loss: 1.2679 | Acc: 0.5312 | LR: 2.82e-06
2026-01-07 07:48:34,575 [INFO] Step 2150/2370 | Loss: 1.4055 | Acc: 0.4688 | LR: 2.67e-06
2026-01-07 07:48:37,921 [INFO] Step 2160/2370 | Loss: 1.3767 | Acc: 0.5312 | LR: 2.52e-06
2026-01-07 07:48:41,265 [INFO] Step 2170/2370 | Loss: 1.5371 | Acc: 0.3750 | LR: 2.38e-06
2026-01-07 07:48:44,565 [INFO] Step 2180/2370 | Loss: 1.2659 | Acc: 0.5938 | LR: 2.25e-06
2026-01-07 07:48:47,882 [INFO] Step 2190/2370 | Loss: 1.3516 | Acc: 0.4688 | LR: 2.12e-06
2026-01-07 07:48:51,741 [INFO] Step 2200/2370 | Loss: 1.4553 | Acc: 0.4375 | LR: 2.00e-06
2026-01-07 07:48:55,784 [INFO] [EVAL] Step 2200 | Val Loss: 1.3477 | Val Acc: 0.4447
2026-01-07 07:48:59,026 [INFO] Step 2210/2370 | Loss: 1.4620 | Acc: 0.4688 | LR: 1.89e-06
2026-01-07 07:49:02,315 [INFO] Step 2220/2370 | Loss: 1.4604 | Acc: 0.4375 | LR: 1.78e-06
2026-01-07 07:49:05,598 [INFO] Step 2230/2370 | Loss: 1.3870 | Acc: 0.5000 | LR: 1.68e-06
2026-01-07 07:49:08,824 [INFO] Step 2240/2370 | Loss: 1.4957 | Acc: 0.3750 | LR: 1.59e-06
2026-01-07 07:49:12,104 [INFO] Step 2250/2370 | Loss: 1.1312 | Acc: 0.6562 | LR: 1.50e-06
2026-01-07 07:49:15,377 [INFO] Step 2260/2370 | Loss: 1.4418 | Acc: 0.4688 | LR: 1.42e-06
2026-01-07 07:49:18,630 [INFO] Step 2270/2370 | Loss: 1.5616 | Acc: 0.3750 | LR: 1.35e-06
2026-01-07 07:49:21,925 [INFO] Step 2280/2370 | Loss: 1.3208 | Acc: 0.5625 | LR: 1.29e-06
2026-01-07 07:49:25,195 [INFO] Step 2290/2370 | Loss: 1.4309 | Acc: 0.5000 | LR: 1.23e-06
2026-01-07 07:49:29,141 [INFO] Step 2300/2370 | Loss: 1.3256 | Acc: 0.4688 | LR: 1.17e-06
2026-01-07 07:49:33,467 [INFO] [EVAL] Step 2300 | Val Loss: 1.3483 | Val Acc: 0.4495
2026-01-07 07:49:33,470 [INFO] New best validation accuracy: 0.4495
2026-01-07 07:49:36,768 [INFO] Step 2310/2370 | Loss: 1.2880 | Acc: 0.6250 | LR: 1.13e-06
2026-01-07 07:49:40,129 [INFO] Step 2320/2370 | Loss: 1.4888 | Acc: 0.5312 | LR: 1.09e-06
2026-01-07 07:49:43,475 [INFO] Step 2330/2370 | Loss: 1.4184 | Acc: 0.4062 | LR: 1.06e-06
2026-01-07 07:49:46,681 [INFO] Step 2340/2370 | Loss: 1.4866 | Acc: 0.4375 | LR: 1.03e-06
2026-01-07 07:49:50,021 [INFO] Step 2350/2370 | Loss: 1.3785 | Acc: 0.5625 | LR: 1.02e-06
2026-01-07 07:49:53,391 [INFO] Step 2360/2370 | Loss: 1.5174 | Acc: 0.4062 | LR: 1.00e-06
2026-01-07 07:49:53,694 [INFO] Epoch 10 complete | Avg Loss: 1.4071 | Avg Acc: 0.4760 | Updates: 237 | Micro-batches: 237 | Skipped: 0 (loss=0, logits=0, grads=0)
2026-01-07 07:49:57,864 [INFO] Final validation: Loss=1.3321, Acc=0.4567
2026-01-07 07:49:57,867 [INFO] Training completed in 899.32s (0.25h)
2026-01-07 07:49:57,867 [INFO] Best validation accuracy: 0.4567
