/opt/homebrew/lib/python3.14/site-packages/webrtcvad.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Train: 19734 samples
Val: 2193 samples
Cache-only mode: 17043/19734 samples (86.4% cached)
Cache-only mode: 2193/2193 samples (100.0% cached)
Using cached encoder features from: data/v3_multitask/encoder_cache
Prosody features: ENABLED (from cache)
Model parameters:
  Total: 4,032,008
  Encoder LoRA: 737,280
  Classification head: 3,294,728
  Converted model parameters to bfloat16
Loading weights from checkpoints/rich_decoder_v4_lora_lowmem/best.npz
  Loaded 78 weight tensors
  Using SGD optimizer (momentum=0.9, no state accumulation)

============================================================
Training RichDecoder v4 (Optimized)
============================================================
  Epochs: 10
  Batch size: 4 x 4 = 16
  Total steps: 42610
  bfloat16: True
  Prefetch: 4 batches
  Early stopping: True (patience=3)

Epoch 1/10
  Step 50: loss=0.5128, acc=100.00%, lr=5.00e-06
  Step 100: loss=0.2326, acc=75.00%, lr=1.00e-05
  Step 150: loss=1.2374, acc=50.00%, lr=1.50e-05
  Step 200: loss=0.4840, acc=75.00%, lr=2.00e-05
  Step 250: loss=0.4278, acc=75.00%, lr=2.50e-05
  Step 300: loss=0.4504, acc=100.00%, lr=3.00e-05
  Step 350: loss=0.7003, acc=100.00%, lr=3.50e-05
  Step 400: loss=0.0354, acc=100.00%, lr=4.00e-05
  Step 450: loss=0.5210, acc=75.00%, lr=4.50e-05
  Step 500: loss=1.2597, acc=50.00%, lr=5.00e-05
  Step 550: loss=0.9205, acc=50.00%, lr=5.00e-05
  Step 600: loss=0.6263, acc=75.00%, lr=5.00e-05
  Step 650: loss=0.7711, acc=75.00%, lr=5.00e-05
  Step 700: loss=1.4091, acc=50.00%, lr=5.00e-05
  Step 750: loss=0.8072, acc=50.00%, lr=5.00e-05
  Step 800: loss=0.2531, acc=100.00%, lr=5.00e-05
  Step 850: loss=0.5419, acc=75.00%, lr=5.00e-05
  Step 900: loss=0.8930, acc=75.00%, lr=5.00e-05
  Step 950: loss=0.8278, acc=75.00%, lr=5.00e-05
  Step 1000: loss=0.4566, acc=100.00%, lr=5.00e-05
  Validation: loss=0.6848, acc=73.83%
  New best model! acc=73.83%
  Step 1050: loss=0.4348, acc=75.00%, lr=5.00e-05
  Step 1100: loss=0.7906, acc=75.00%, lr=5.00e-05
  Step 1150: loss=0.1076, acc=100.00%, lr=5.00e-05
  Step 1200: loss=0.0198, acc=100.00%, lr=5.00e-05
  Step 1250: loss=0.0372, acc=100.00%, lr=5.00e-05
  Step 1300: loss=0.0946, acc=100.00%, lr=5.00e-05
  Step 1350: loss=1.3718, acc=50.00%, lr=5.00e-05
  Step 1400: loss=0.0281, acc=100.00%, lr=4.99e-05
  Step 1450: loss=0.2193, acc=100.00%, lr=4.99e-05
  Step 1500: loss=0.4394, acc=100.00%, lr=4.99e-05
  Step 1550: loss=0.1758, acc=100.00%, lr=4.99e-05
  Step 1600: loss=0.4543, acc=75.00%, lr=4.99e-05
  Step 1650: loss=0.0147, acc=100.00%, lr=4.99e-05
  Step 1700: loss=0.4266, acc=100.00%, lr=4.99e-05
  Step 1750: loss=0.3802, acc=100.00%, lr=4.99e-05
  Step 1800: loss=0.4314, acc=75.00%, lr=4.99e-05
  Step 1850: loss=0.5618, acc=75.00%, lr=4.99e-05
  Step 1900: loss=0.8289, acc=75.00%, lr=4.99e-05
  Step 1950: loss=0.9824, acc=50.00%, lr=4.99e-05
  Step 2000: loss=1.9782, acc=0.00%, lr=4.98e-05
  Validation: loss=0.6872, acc=74.42%
  New best model! acc=74.42%
  Step 2050: loss=0.4846, acc=75.00%, lr=4.98e-05
  Step 2100: loss=0.0160, acc=100.00%, lr=4.98e-05
  Step 2150: loss=0.5796, acc=75.00%, lr=4.98e-05
  Step 2200: loss=0.4953, acc=75.00%, lr=4.98e-05
  Step 2250: loss=0.4702, acc=75.00%, lr=4.98e-05
  Step 2300: loss=0.1046, acc=100.00%, lr=4.98e-05
  Step 2350: loss=0.5549, acc=75.00%, lr=4.98e-05
  Step 2400: loss=0.6734, acc=100.00%, lr=4.98e-05
  Step 2450: loss=1.2502, acc=75.00%, lr=4.97e-05
  Step 2500: loss=0.7067, acc=100.00%, lr=4.97e-05
  Step 2550: loss=0.9152, acc=50.00%, lr=4.97e-05
  Step 2600: loss=0.7205, acc=100.00%, lr=4.97e-05
  Step 2650: loss=0.5960, acc=75.00%, lr=4.97e-05
  Step 2700: loss=0.5984, acc=75.00%, lr=4.97e-05
  Step 2750: loss=0.4332, acc=100.00%, lr=4.97e-05
  Step 2800: loss=0.9301, acc=50.00%, lr=4.96e-05
  Step 2850: loss=1.0957, acc=25.00%, lr=4.96e-05
  Step 2900: loss=0.9007, acc=50.00%, lr=4.96e-05
  Step 2950: loss=1.3153, acc=50.00%, lr=4.96e-05
  Step 3000: loss=0.8808, acc=75.00%, lr=4.96e-05
  Validation: loss=0.6860, acc=73.55%
  Step 3050: loss=0.7690, acc=75.00%, lr=4.96e-05
  Step 3100: loss=0.0216, acc=100.00%, lr=4.95e-05
  Step 3150: loss=0.0347, acc=100.00%, lr=4.95e-05
  Step 3200: loss=1.2388, acc=75.00%, lr=4.95e-05
  Step 3250: loss=1.1083, acc=50.00%, lr=4.95e-05
  Step 3300: loss=0.9834, acc=75.00%, lr=4.95e-05
  Step 3350: loss=1.5899, acc=50.00%, lr=4.94e-05
  Step 3400: loss=0.9540, acc=50.00%, lr=4.94e-05
  Step 3450: loss=0.7563, acc=50.00%, lr=4.94e-05
  Step 3500: loss=1.0219, acc=50.00%, lr=4.94e-05
  Step 3550: loss=0.0424, acc=100.00%, lr=4.94e-05
  Step 3600: loss=0.7755, acc=75.00%, lr=4.93e-05
  Step 3650: loss=0.7959, acc=50.00%, lr=4.93e-05
  Step 3700: loss=0.8550, acc=50.00%, lr=4.93e-05
  Step 3750: loss=0.9928, acc=50.00%, lr=4.93e-05
  Step 3800: loss=0.7181, acc=75.00%, lr=4.93e-05
  Step 3850: loss=1.1233, acc=50.00%, lr=4.92e-05
  Step 3900: loss=0.6645, acc=100.00%, lr=4.92e-05
  Step 3950: loss=0.1023, acc=100.00%, lr=4.92e-05
  Step 4000: loss=0.3966, acc=75.00%, lr=4.92e-05
  Validation: loss=0.6852, acc=73.69%
  Early stopping triggered (patience=3)
