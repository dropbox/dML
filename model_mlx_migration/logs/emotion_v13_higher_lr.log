2026-01-07 22:20:11,871 [INFO] Acquired training lock
2026-01-07 22:20:11,871 [INFO] Loading encoder from checkpoints/zipformer/en-streaming/exp/pretrained.pt
2026-01-07 22:20:11,946 [INFO] Encoder loaded: output_dim=512
2026-01-07 22:20:11,946 [INFO] Loading data from data/emotion/combined_emotion_hf (dataset=combined)
2026-01-07 22:20:12,392 [INFO] Train batches: 237
2026-01-07 22:20:12,392 [INFO] Val batches: 26
2026-01-07 22:20:12,420 [INFO] Head num_classes: 6
2026-01-07 22:20:12,421 [INFO] Created emotion head with 988,166 parameters
2026-01-07 22:20:12,421 [INFO] Stage 4: 11,754,487 params (UNFROZEN)
2026-01-07 22:20:12,421 [INFO] Stage 5: 3,906,660 params (UNFROZEN)
2026-01-07 22:20:12,421 [INFO] Total unfrozen encoder params: 15,661,147
2026-01-07 22:20:12,421 [INFO] Total trainable parameters: 16,649,313
2026-01-07 22:20:12,421 [INFO] Fine-tuning with encoder unfreezing: lr=4e-05 (encoder_lr parameter is ignored - both encoder and head use same lr)
2026-01-07 22:20:12,421 [INFO] Adaptive LR enabled: will reduce LR by 0.5x if NaN rate > 10%
2026-01-07 22:20:12,421 [INFO] ============================================================
2026-01-07 22:20:12,421 [INFO] Training Configuration
2026-01-07 22:20:12,421 [INFO] ============================================================
2026-01-07 22:20:12,421 [INFO] Head type: emotion
2026-01-07 22:20:12,421 [INFO] Encoder dim: 512
2026-01-07 22:20:12,421 [INFO] Batch size: 32
2026-01-07 22:20:12,421 [INFO] Head learning rate: 4e-05
2026-01-07 22:20:12,421 [INFO] Encoder learning rate: 1e-05
2026-01-07 22:20:12,421 [INFO] Unfrozen encoder stages: 2
2026-01-07 22:20:12,421 [INFO] Gradient clipping: 1.0
2026-01-07 22:20:12,421 [INFO] Cache clearing: every 100 steps
2026-01-07 22:20:12,421 [INFO] Label smoothing: 0.1
2026-01-07 22:20:12,421 [INFO] Loss function: Cross-Entropy
2026-01-07 22:20:12,421 [INFO] SpecAugment: True
2026-01-07 22:20:12,421 [INFO] Param dtype: float32
2026-01-07 22:20:12,421 [INFO] Epochs: 20
2026-01-07 22:20:12,421 [INFO] Max steps: 4740
2026-01-07 22:20:12,421 [INFO] Label key: emotion_labels
2026-01-07 22:20:12,421 [INFO] ============================================================
2026-01-07 22:20:12,422 [INFO] Created EncoderHeadModel for fine-tuning (reused across all steps)
2026-01-07 22:20:12,422 [INFO] Epoch 1/20
2026-01-07 22:20:17,765 [INFO] Step 10/4740 | Loss: 1.7862 | Acc: 0.1875 | LR: 7.20e-07
2026-01-07 22:20:22,205 [INFO] Step 20/4740 | Loss: 1.7934 | Acc: 0.1562 | LR: 1.52e-06
2026-01-07 22:20:26,346 [INFO] Step 30/4740 | Loss: 1.7974 | Acc: 0.0625 | LR: 2.32e-06
2026-01-07 22:20:30,610 [INFO] Step 40/4740 | Loss: 1.7925 | Acc: 0.1250 | LR: 3.12e-06
2026-01-07 22:20:34,961 [INFO] Step 50/4740 | Loss: 1.7916 | Acc: 0.1250 | LR: 3.92e-06
2026-01-07 22:20:39,178 [INFO] Step 60/4740 | Loss: 1.7848 | Acc: 0.2500 | LR: 4.72e-06
2026-01-07 22:20:43,574 [INFO] Step 70/4740 | Loss: 1.7950 | Acc: 0.1875 | LR: 5.52e-06
2026-01-07 22:20:47,837 [INFO] Step 80/4740 | Loss: 1.7962 | Acc: 0.1562 | LR: 6.32e-06
2026-01-07 22:20:52,345 [INFO] Step 90/4740 | Loss: 1.7765 | Acc: 0.1562 | LR: 7.12e-06
2026-01-07 22:20:56,973 [INFO] Step 100/4740 | Loss: 1.7945 | Acc: 0.1875 | LR: 7.92e-06
2026-01-07 22:21:02,918 [INFO] [EVAL] Step 100 | Val Loss: 1.7784 | Val Acc: 0.2452
2026-01-07 22:21:02,952 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_best.npz
2026-01-07 22:21:02,954 [INFO] New best validation accuracy: 0.2452
2026-01-07 22:21:07,452 [INFO] Step 110/4740 | Loss: 1.7861 | Acc: 0.1562 | LR: 8.72e-06
2026-01-07 22:21:11,849 [INFO] Step 120/4740 | Loss: 1.7681 | Acc: 0.2812 | LR: 9.52e-06
2026-01-07 22:21:16,182 [INFO] Step 130/4740 | Loss: 1.7818 | Acc: 0.2812 | LR: 1.03e-05
2026-01-07 22:21:20,505 [INFO] Step 140/4740 | Loss: 1.7478 | Acc: 0.2812 | LR: 1.11e-05
2026-01-07 22:21:25,012 [INFO] Step 150/4740 | Loss: 1.7593 | Acc: 0.3438 | LR: 1.19e-05
2026-01-07 22:21:29,451 [INFO] Step 160/4740 | Loss: 1.7326 | Acc: 0.3750 | LR: 1.27e-05
2026-01-07 22:21:33,889 [INFO] Step 170/4740 | Loss: 1.7335 | Acc: 0.3125 | LR: 1.35e-05
2026-01-07 22:21:38,035 [INFO] Step 180/4740 | Loss: 1.8853 | Acc: 0.0938 | LR: 1.43e-05
2026-01-07 22:21:42,343 [INFO] Step 190/4740 | Loss: 1.7492 | Acc: 0.0938 | LR: 1.51e-05
2026-01-07 22:21:47,225 [INFO] Step 200/4740 | Loss: 1.8049 | Acc: 0.3125 | LR: 1.59e-05
2026-01-07 22:21:53,099 [INFO] [EVAL] Step 200 | Val Loss: 1.7716 | Val Acc: 0.2188
2026-01-07 22:21:57,678 [INFO] Step 210/4740 | Loss: 1.8038 | Acc: 0.1875 | LR: 1.67e-05
2026-01-07 22:22:02,162 [INFO] Step 220/4740 | Loss: 1.7367 | Acc: 0.1562 | LR: 1.75e-05
2026-01-07 22:22:06,824 [INFO] Step 230/4740 | Loss: 1.6856 | Acc: 0.4062 | LR: 1.83e-05
2026-01-07 22:22:09,677 [INFO] Epoch 1 complete | Avg Loss: 1.7700 | Avg Acc: 0.2164 | Updates: 237 | Micro-batches: 237 | Skipped: 0 (loss=0, logits=0, grads=0)
2026-01-07 22:22:09,677 [INFO] Epoch 2/20
2026-01-07 22:22:11,427 [INFO] Step 240/4740 | Loss: 1.6758 | Acc: 0.2812 | LR: 1.91e-05
2026-01-07 22:22:15,671 [INFO] Step 250/4740 | Loss: 1.6501 | Acc: 0.4062 | LR: 1.99e-05
2026-01-07 22:22:20,275 [INFO] Step 260/4740 | Loss: 1.7764 | Acc: 0.2188 | LR: 2.07e-05
2026-01-07 22:22:24,623 [INFO] Step 270/4740 | Loss: 1.7458 | Acc: 0.1562 | LR: 2.15e-05
2026-01-07 22:22:28,855 [INFO] Step 280/4740 | Loss: 1.7859 | Acc: 0.1562 | LR: 2.23e-05
2026-01-07 22:22:33,136 [INFO] Step 290/4740 | Loss: 1.7416 | Acc: 0.2500 | LR: 2.31e-05
2026-01-07 22:22:37,972 [INFO] Step 300/4740 | Loss: 1.7568 | Acc: 0.2812 | LR: 2.39e-05
2026-01-07 22:22:43,695 [INFO] [EVAL] Step 300 | Val Loss: 1.7367 | Val Acc: 0.2524
2026-01-07 22:22:43,750 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_best.npz
2026-01-07 22:22:43,752 [INFO] New best validation accuracy: 0.2524
2026-01-07 22:22:48,272 [INFO] Step 310/4740 | Loss: 1.7718 | Acc: 0.3750 | LR: 2.47e-05
2026-01-07 22:22:52,628 [INFO] Step 320/4740 | Loss: 1.7271 | Acc: 0.2500 | LR: 2.55e-05
2026-01-07 22:22:56,922 [INFO] Step 330/4740 | Loss: 1.7223 | Acc: 0.2500 | LR: 2.63e-05
2026-01-07 22:23:01,257 [INFO] Step 340/4740 | Loss: 1.6936 | Acc: 0.2812 | LR: 2.71e-05
2026-01-07 22:23:05,657 [INFO] Step 350/4740 | Loss: 1.7402 | Acc: 0.2188 | LR: 2.79e-05
2026-01-07 22:23:09,988 [INFO] Step 360/4740 | Loss: 1.6566 | Acc: 0.3750 | LR: 2.87e-05
2026-01-07 22:23:14,050 [INFO] Step 370/4740 | Loss: 1.6093 | Acc: 0.4062 | LR: 2.95e-05
2026-01-07 22:23:18,560 [INFO] Step 380/4740 | Loss: 1.7113 | Acc: 0.2812 | LR: 3.03e-05
2026-01-07 22:23:23,006 [INFO] Step 390/4740 | Loss: 1.7576 | Acc: 0.1562 | LR: 3.11e-05
2026-01-07 22:23:28,124 [INFO] Step 400/4740 | Loss: 1.6824 | Acc: 0.2812 | LR: 3.19e-05
2026-01-07 22:23:33,962 [INFO] [EVAL] Step 400 | Val Loss: 1.7235 | Val Acc: 0.2356
2026-01-07 22:23:38,105 [INFO] Step 410/4740 | Loss: 1.6927 | Acc: 0.2812 | LR: 3.27e-05
2026-01-07 22:23:42,290 [INFO] Step 420/4740 | Loss: 1.6673 | Acc: 0.4375 | LR: 3.35e-05
2026-01-07 22:23:46,516 [INFO] Step 430/4740 | Loss: 1.7793 | Acc: 0.2812 | LR: 3.43e-05
2026-01-07 22:23:50,807 [INFO] Step 440/4740 | Loss: 1.7069 | Acc: 0.2188 | LR: 3.51e-05
2026-01-07 22:23:55,131 [INFO] Step 450/4740 | Loss: 1.7493 | Acc: 0.1562 | LR: 3.59e-05
2026-01-07 22:23:59,648 [INFO] Step 460/4740 | Loss: 1.7294 | Acc: 0.1562 | LR: 3.67e-05
2026-01-07 22:24:04,081 [INFO] Step 470/4740 | Loss: 1.8660 | Acc: 0.1250 | LR: 3.75e-05
2026-01-07 22:24:05,627 [INFO] Epoch 2 complete | Avg Loss: 1.7146 | Avg Acc: 0.2787 | Updates: 237 | Micro-batches: 237 | Skipped: 0 (loss=0, logits=0, grads=0)
2026-01-07 22:24:05,627 [INFO] Epoch 3/20
2026-01-07 22:24:08,795 [INFO] Step 480/4740 | Loss: 1.7327 | Acc: 0.3125 | LR: 3.83e-05
2026-01-07 22:24:13,320 [INFO] Step 490/4740 | Loss: 1.7731 | Acc: 0.2500 | LR: 3.91e-05
2026-01-07 22:24:18,158 [INFO] Step 500/4740 | Loss: 1.6515 | Acc: 0.3438 | LR: 3.99e-05
2026-01-07 22:24:23,924 [INFO] [EVAL] Step 500 | Val Loss: 1.6695 | Val Acc: 0.2849
2026-01-07 22:24:23,958 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_best.npz
2026-01-07 22:24:23,960 [INFO] New best validation accuracy: 0.2849
2026-01-07 22:24:23,998 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_step_500.npz
2026-01-07 22:24:28,398 [INFO] Step 510/4740 | Loss: 1.5811 | Acc: 0.4688 | LR: 4.00e-05
2026-01-07 22:24:32,573 [INFO] Step 520/4740 | Loss: 1.8689 | Acc: 0.2500 | LR: 4.00e-05
2026-01-07 22:24:36,825 [INFO] Step 530/4740 | Loss: 1.7793 | Acc: 0.2812 | LR: 4.00e-05
2026-01-07 22:24:41,432 [INFO] Step 540/4740 | Loss: 1.6908 | Acc: 0.3125 | LR: 4.00e-05
2026-01-07 22:24:45,877 [INFO] Step 550/4740 | Loss: 1.6090 | Acc: 0.4062 | LR: 4.00e-05
2026-01-07 22:24:50,366 [INFO] Step 560/4740 | Loss: 1.6808 | Acc: 0.3750 | LR: 4.00e-05
2026-01-07 22:24:54,865 [INFO] Step 570/4740 | Loss: 1.6786 | Acc: 0.3438 | LR: 4.00e-05
2026-01-07 22:24:59,460 [INFO] Step 580/4740 | Loss: 1.5969 | Acc: 0.4688 | LR: 4.00e-05
2026-01-07 22:25:03,818 [INFO] Step 590/4740 | Loss: 1.6752 | Acc: 0.2188 | LR: 4.00e-05
2026-01-07 22:25:08,564 [INFO] Step 600/4740 | Loss: 1.7045 | Acc: 0.3125 | LR: 3.99e-05
2026-01-07 22:25:14,543 [INFO] [EVAL] Step 600 | Val Loss: 1.6998 | Val Acc: 0.2608
2026-01-07 22:25:19,042 [INFO] Step 610/4740 | Loss: 1.6660 | Acc: 0.2500 | LR: 3.99e-05
2026-01-07 22:25:21,077 [WARNING] Skipping batch due to non-finite loss at step=614 (loss=nan, epoch=3).
2026-01-07 22:25:23,588 [INFO] Step 620/4740 | Loss: 1.7472 | Acc: 0.2812 | LR: 3.99e-05
2026-01-07 22:25:24,319 [WARNING] Skipping batch due to non-finite loss at step=621 (loss=nan, epoch=3).
2026-01-07 22:25:24,540 [WARNING] Skipping batch due to non-finite loss at step=621 (loss=nan, epoch=3).
2026-01-07 22:25:26,220 [WARNING] Skipping batch due to non-finite loss at step=624 (loss=nan, epoch=3).
2026-01-07 22:25:26,410 [WARNING] Skipping batch due to non-finite loss at step=624 (loss=nan, epoch=3).
2026-01-07 22:25:28,982 [INFO] Step 630/4740 | Loss: 1.6443 | Acc: 0.3438 | LR: 3.99e-05
2026-01-07 22:25:33,313 [INFO] Step 640/4740 | Loss: 1.6900 | Acc: 0.2812 | LR: 3.99e-05
2026-01-07 22:25:37,473 [INFO] Step 650/4740 | Loss: 1.6213 | Acc: 0.3750 | LR: 3.99e-05
2026-01-07 22:25:41,851 [WARNING] Skipping batch due to non-finite loss at step=659 (loss=nan, epoch=3).
2026-01-07 22:25:42,051 [WARNING] Skipping batch due to non-finite loss at step=659 (loss=nan, epoch=3).
2026-01-07 22:25:42,533 [INFO] Step 660/4740 | Loss: 1.6713 | Acc: 0.4062 | LR: 3.99e-05
2026-01-07 22:25:44,945 [WARNING] Skipping batch due to non-finite loss at step=665 (loss=nan, epoch=3).
2026-01-07 22:25:45,975 [WARNING] Skipping batch due to non-finite loss at step=667 (loss=nan, epoch=3).
2026-01-07 22:25:47,251 [WARNING] Skipping batch due to non-finite loss at step=669 (loss=nan, epoch=3).
2026-01-07 22:25:47,779 [INFO] Step 670/4740 | Loss: 1.6182 | Acc: 0.3750 | LR: 3.98e-05
2026-01-07 22:25:52,440 [INFO] Step 680/4740 | Loss: 1.7071 | Acc: 0.2812 | LR: 3.98e-05
2026-01-07 22:25:56,867 [INFO] Step 690/4740 | Loss: 1.6565 | Acc: 0.4688 | LR: 3.98e-05
2026-01-07 22:26:00,486 [INFO] Epoch 3 complete | Avg Loss: 1.6648 | Avg Acc: 0.3133 | Updates: 224 | Micro-batches: 237 | Skipped: 13 (loss=13, logits=0, grads=0)
2026-01-07 22:26:00,486 [INFO] Epoch 4/20
2026-01-07 22:26:02,145 [INFO] Step 700/4740 | Loss: 1.6791 | Acc: 0.4062 | LR: 3.98e-05
2026-01-07 22:26:08,265 [INFO] [EVAL] Step 700 | Val Loss: 1.5789 | Val Acc: 0.3063
2026-01-07 22:26:08,300 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_best.npz
2026-01-07 22:26:08,301 [INFO] New best validation accuracy: 0.3063
2026-01-07 22:26:12,470 [INFO] Step 710/4740 | Loss: 1.6985 | Acc: 0.3125 | LR: 3.98e-05
2026-01-07 22:26:16,747 [INFO] Step 720/4740 | Loss: 1.7839 | Acc: 0.3750 | LR: 3.97e-05
2026-01-07 22:26:21,089 [INFO] Step 730/4740 | Loss: 1.6206 | Acc: 0.3750 | LR: 3.97e-05
2026-01-07 22:26:25,273 [INFO] Step 740/4740 | Loss: 1.5322 | Acc: 0.3750 | LR: 3.97e-05
2026-01-07 22:26:28,655 [WARNING] Skipping batch due to non-finite loss at step=747 (loss=nan, epoch=4).
2026-01-07 22:26:30,108 [INFO] Step 750/4740 | Loss: 1.7218 | Acc: 0.3125 | LR: 3.97e-05
2026-01-07 22:26:31,104 [WARNING] Skipping batch due to non-finite loss at step=752 (loss=nan, epoch=4).
2026-01-07 22:26:34,835 [INFO] Step 760/4740 | Loss: 1.6052 | Acc: 0.3438 | LR: 3.96e-05
2026-01-07 22:26:39,171 [INFO] Step 770/4740 | Loss: 1.5945 | Acc: 0.3438 | LR: 3.96e-05
2026-01-07 22:26:42,105 [WARNING] Skipping batch due to non-finite loss at step=776 (loss=nan, epoch=4).
2026-01-07 22:26:43,924 [INFO] Step 780/4740 | Loss: 1.6183 | Acc: 0.3750 | LR: 3.96e-05
2026-01-07 22:26:48,071 [INFO] Step 790/4740 | Loss: 1.4074 | Acc: 0.4688 | LR: 3.96e-05
2026-01-07 22:26:52,874 [INFO] Step 800/4740 | Loss: 1.5775 | Acc: 0.2812 | LR: 3.95e-05
2026-01-07 22:26:58,777 [INFO] [EVAL] Step 800 | Val Loss: 1.5363 | Val Acc: 0.3798
2026-01-07 22:26:58,814 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_best.npz
2026-01-07 22:26:58,816 [INFO] New best validation accuracy: 0.3798
2026-01-07 22:27:01,243 [WARNING] Skipping batch due to non-finite loss at step=805 (loss=nan, epoch=4).
2026-01-07 22:27:01,459 [WARNING] Skipping batch due to non-finite loss at step=805 (loss=nan, epoch=4).
2026-01-07 22:27:01,716 [WARNING] Skipping batch due to non-finite loss at step=805 (loss=nan, epoch=4).
2026-01-07 22:27:04,162 [INFO] Step 810/4740 | Loss: 1.5767 | Acc: 0.4062 | LR: 3.95e-05
2026-01-07 22:27:04,320 [WARNING] Skipping batch due to non-finite loss at step=810 (loss=nan, epoch=4).
2026-01-07 22:27:07,595 [WARNING] Skipping batch due to non-finite loss at step=817 (loss=nan, epoch=4).
2026-01-07 22:27:09,020 [INFO] Step 820/4740 | Loss: 1.5577 | Acc: 0.1875 | LR: 3.95e-05
2026-01-07 22:27:13,273 [INFO] Step 830/4740 | Loss: 1.4228 | Acc: 0.4688 | LR: 3.94e-05
2026-01-07 22:27:17,831 [INFO] Step 840/4740 | Loss: 1.4607 | Acc: 0.5312 | LR: 3.94e-05
2026-01-07 22:27:22,268 [INFO] Step 850/4740 | Loss: 1.8043 | Acc: 0.2500 | LR: 3.94e-05
2026-01-07 22:27:26,564 [INFO] Step 860/4740 | Loss: 1.5553 | Acc: 0.3750 | LR: 3.93e-05
2026-01-07 22:27:30,754 [INFO] Step 870/4740 | Loss: 1.5906 | Acc: 0.3438 | LR: 3.93e-05
2026-01-07 22:27:35,121 [INFO] Step 880/4740 | Loss: 1.5085 | Acc: 0.2812 | LR: 3.92e-05
2026-01-07 22:27:39,711 [INFO] Step 890/4740 | Loss: 1.6062 | Acc: 0.4375 | LR: 3.92e-05
2026-01-07 22:27:44,552 [INFO] Step 900/4740 | Loss: 1.6436 | Acc: 0.2500 | LR: 3.92e-05
2026-01-07 22:27:50,347 [INFO] [EVAL] Step 900 | Val Loss: 1.5051 | Val Acc: 0.3594
2026-01-07 22:27:54,910 [INFO] Step 910/4740 | Loss: 1.5379 | Acc: 0.3750 | LR: 3.91e-05
2026-01-07 22:27:59,334 [INFO] Step 920/4740 | Loss: 1.4354 | Acc: 0.4688 | LR: 3.91e-05
2026-01-07 22:28:02,220 [INFO] Epoch 4 complete | Avg Loss: 1.5966 | Avg Acc: 0.3618 | Updates: 229 | Micro-batches: 237 | Skipped: 8 (loss=8, logits=0, grads=0)
2026-01-07 22:28:02,220 [INFO] Epoch 5/20
2026-01-07 22:28:03,078 [WARNING] Skipping batch due to non-finite loss at step=928 (loss=nan, epoch=5).
2026-01-07 22:28:03,267 [WARNING] Skipping batch due to non-finite loss at step=928 (loss=nan, epoch=5).
2026-01-07 22:28:04,468 [INFO] Step 930/4740 | Loss: 1.5891 | Acc: 0.3750 | LR: 3.90e-05
2026-01-07 22:28:08,547 [INFO] Step 940/4740 | Loss: 1.6620 | Acc: 0.2812 | LR: 3.90e-05
2026-01-07 22:28:12,891 [INFO] Step 950/4740 | Loss: 1.6170 | Acc: 0.3125 | LR: 3.89e-05
2026-01-07 22:28:17,214 [INFO] Step 960/4740 | Loss: 1.6497 | Acc: 0.2812 | LR: 3.89e-05
2026-01-07 22:28:21,543 [INFO] Step 970/4740 | Loss: 1.5205 | Acc: 0.3750 | LR: 3.88e-05
2026-01-07 22:28:25,708 [INFO] Step 980/4740 | Loss: 1.5973 | Acc: 0.3750 | LR: 3.88e-05
2026-01-07 22:28:26,738 [WARNING] Skipping batch due to non-finite loss at step=982 (loss=nan, epoch=5).
2026-01-07 22:28:30,268 [INFO] Step 990/4740 | Loss: 1.6779 | Acc: 0.3125 | LR: 3.87e-05
2026-01-07 22:28:35,226 [INFO] Step 1000/4740 | Loss: 1.5410 | Acc: 0.3125 | LR: 3.87e-05
2026-01-07 22:28:41,200 [INFO] [EVAL] Step 1000 | Val Loss: 1.4917 | Val Acc: 0.3726
2026-01-07 22:28:41,241 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_step_1000.npz
2026-01-07 22:28:45,785 [INFO] Step 1010/4740 | Loss: 1.5768 | Acc: 0.3750 | LR: 3.86e-05
2026-01-07 22:28:50,185 [INFO] Step 1020/4740 | Loss: 1.5518 | Acc: 0.3438 | LR: 3.86e-05
2026-01-07 22:28:52,968 [WARNING] Skipping batch due to non-finite loss at step=1026 (loss=nan, epoch=5).
2026-01-07 22:28:54,044 [WARNING] Skipping batch due to non-finite loss at step=1028 (loss=nan, epoch=5).
2026-01-07 22:28:54,978 [INFO] Step 1030/4740 | Loss: 1.4908 | Acc: 0.5000 | LR: 3.85e-05
2026-01-07 22:28:57,432 [WARNING] Skipping batch due to non-finite loss at step=1035 (loss=nan, epoch=5).
2026-01-07 22:28:58,151 [WARNING] Skipping batch due to non-finite loss at step=1036 (loss=nan, epoch=5).
2026-01-07 22:28:58,335 [WARNING] Skipping batch due to non-finite loss at step=1036 (loss=nan, epoch=5).
2026-01-07 22:28:59,903 [WARNING] Skipping batch due to non-finite loss at step=1039 (loss=nan, epoch=5).
2026-01-07 22:29:00,394 [INFO] Step 1040/4740 | Loss: 1.5310 | Acc: 0.3750 | LR: 3.85e-05
2026-01-07 22:29:01,546 [WARNING] Skipping batch due to non-finite loss at step=1042 (loss=nan, epoch=5).
2026-01-07 22:29:05,813 [INFO] Step 1050/4740 | Loss: 1.4162 | Acc: 0.5625 | LR: 3.84e-05
2026-01-07 22:29:10,297 [INFO] Step 1060/4740 | Loss: 1.4590 | Acc: 0.3750 | LR: 3.84e-05
2026-01-07 22:29:16,451 [INFO] Step 1070/4740 | Loss: 1.5655 | Acc: 0.4062 | LR: 3.83e-05
2026-01-07 22:29:21,346 [INFO] Step 1080/4740 | Loss: 1.4729 | Acc: 0.3750 | LR: 3.82e-05
2026-01-07 22:29:26,996 [INFO] Step 1090/4740 | Loss: 1.6110 | Acc: 0.3438 | LR: 3.82e-05
2026-01-07 22:29:31,995 [INFO] Step 1100/4740 | Loss: 1.5091 | Acc: 0.3125 | LR: 3.81e-05
2026-01-07 22:29:38,236 [INFO] [EVAL] Step 1100 | Val Loss: 1.4706 | Val Acc: 0.4035
2026-01-07 22:29:38,269 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_best.npz
2026-01-07 22:29:38,271 [INFO] New best validation accuracy: 0.4035
2026-01-07 22:29:43,069 [INFO] Step 1110/4740 | Loss: 1.4580 | Acc: 0.4375 | LR: 3.80e-05
2026-01-07 22:29:47,848 [INFO] Step 1120/4740 | Loss: 1.5163 | Acc: 0.4375 | LR: 3.80e-05
2026-01-07 22:29:52,396 [INFO] Step 1130/4740 | Loss: 1.6068 | Acc: 0.3125 | LR: 3.79e-05
2026-01-07 22:29:53,528 [INFO] Epoch 5 complete | Avg Loss: 1.5488 | Avg Acc: 0.3874 | Updates: 206 | Micro-batches: 237 | Skipped: 31 (loss=31, logits=0, grads=0)
2026-01-07 22:29:53,528 [INFO] Epoch 6/20
2026-01-07 22:29:55,406 [WARNING] Skipping batch due to non-finite loss at step=1136 (loss=nan, epoch=6).
2026-01-07 22:29:57,190 [INFO] Step 1140/4740 | Loss: 1.4448 | Acc: 0.4375 | LR: 3.79e-05
2026-01-07 22:30:00,100 [WARNING] Skipping batch due to non-finite loss at step=1146 (loss=nan, epoch=6).
2026-01-07 22:30:01,834 [INFO] Step 1150/4740 | Loss: 1.5153 | Acc: 0.4375 | LR: 3.78e-05
2026-01-07 22:30:06,378 [INFO] Step 1160/4740 | Loss: 1.5522 | Acc: 0.4688 | LR: 3.77e-05
2026-01-07 22:30:10,936 [INFO] Step 1170/4740 | Loss: 1.4454 | Acc: 0.5312 | LR: 3.77e-05
2026-01-07 22:30:12,049 [WARNING] Skipping batch due to non-finite loss at step=1172 (loss=nan, epoch=6).
2026-01-07 22:30:12,294 [WARNING] Skipping batch due to non-finite loss at step=1172 (loss=nan, epoch=6).
2026-01-07 22:30:12,937 [WARNING] Skipping batch due to non-finite loss at step=1173 (loss=nan, epoch=6).
2026-01-07 22:30:15,972 [INFO] Step 1180/4740 | Loss: 1.6473 | Acc: 0.3438 | LR: 3.76e-05
2026-01-07 22:30:19,371 [WARNING] Skipping batch due to non-finite loss at step=1187 (loss=nan, epoch=6).
2026-01-07 22:30:20,799 [INFO] Step 1190/4740 | Loss: 1.6611 | Acc: 0.3125 | LR: 3.75e-05
2026-01-07 22:30:25,492 [INFO] Step 1200/4740 | Loss: 1.4849 | Acc: 0.4375 | LR: 3.74e-05
2026-01-07 22:30:31,496 [INFO] [EVAL] Step 1200 | Val Loss: 1.4522 | Val Acc: 0.4171
2026-01-07 22:30:31,547 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_best.npz
2026-01-07 22:30:31,550 [INFO] New best validation accuracy: 0.4171
2026-01-07 22:30:35,722 [INFO] Step 1210/4740 | Loss: 1.7008 | Acc: 0.1875 | LR: 3.74e-05
2026-01-07 22:30:40,142 [INFO] Step 1220/4740 | Loss: 1.6232 | Acc: 0.3750 | LR: 3.73e-05
2026-01-07 22:30:44,572 [INFO] Step 1230/4740 | Loss: 1.4566 | Acc: 0.3438 | LR: 3.72e-05
2026-01-07 22:30:48,892 [INFO] Step 1240/4740 | Loss: 1.3126 | Acc: 0.5000 | LR: 3.71e-05
2026-01-07 22:30:53,284 [INFO] Step 1250/4740 | Loss: 1.6643 | Acc: 0.3125 | LR: 3.71e-05
2026-01-07 22:30:57,600 [INFO] Step 1260/4740 | Loss: 1.6036 | Acc: 0.4062 | LR: 3.70e-05
2026-01-07 22:31:02,095 [INFO] Step 1270/4740 | Loss: 1.4642 | Acc: 0.4375 | LR: 3.69e-05
2026-01-07 22:31:06,638 [INFO] Step 1280/4740 | Loss: 1.4353 | Acc: 0.4688 | LR: 3.68e-05
2026-01-07 22:31:10,940 [INFO] Step 1290/4740 | Loss: 1.5591 | Acc: 0.3438 | LR: 3.68e-05
2026-01-07 22:31:15,756 [INFO] Step 1300/4740 | Loss: 1.3811 | Acc: 0.4688 | LR: 3.67e-05
2026-01-07 22:31:21,667 [INFO] [EVAL] Step 1300 | Val Loss: 1.4461 | Val Acc: 0.4171
2026-01-07 22:31:26,043 [INFO] Step 1310/4740 | Loss: 1.5188 | Acc: 0.4062 | LR: 3.66e-05
2026-01-07 22:31:30,509 [INFO] Step 1320/4740 | Loss: 1.6073 | Acc: 0.3750 | LR: 3.65e-05
2026-01-07 22:31:35,103 [INFO] Step 1330/4740 | Loss: 1.4914 | Acc: 0.5000 | LR: 3.64e-05
2026-01-07 22:31:39,194 [INFO] Step 1340/4740 | Loss: 1.5669 | Acc: 0.4062 | LR: 3.64e-05
2026-01-07 22:31:43,668 [INFO] Step 1350/4740 | Loss: 1.4673 | Acc: 0.4375 | LR: 3.63e-05
2026-01-07 22:31:48,384 [INFO] Step 1360/4740 | Loss: 1.3432 | Acc: 0.5000 | LR: 3.62e-05
2026-01-07 22:31:49,936 [INFO] Epoch 6 complete | Avg Loss: 1.5171 | Avg Acc: 0.4085 | Updates: 231 | Micro-batches: 237 | Skipped: 6 (loss=6, logits=0, grads=0)
2026-01-07 22:31:49,937 [INFO] Epoch 7/20
2026-01-07 22:31:52,995 [INFO] Step 1370/4740 | Loss: 1.5185 | Acc: 0.3438 | LR: 3.61e-05
2026-01-07 22:31:57,365 [INFO] Step 1380/4740 | Loss: 1.5957 | Acc: 0.2500 | LR: 3.60e-05
2026-01-07 22:32:01,792 [INFO] Step 1390/4740 | Loss: 1.6276 | Acc: 0.3750 | LR: 3.59e-05
2026-01-07 22:32:03,964 [WARNING] Skipping batch due to non-finite loss at step=1394 (loss=nan, epoch=7).
2026-01-07 22:32:07,202 [INFO] Step 1400/4740 | Loss: 1.5554 | Acc: 0.3438 | LR: 3.58e-05
2026-01-07 22:32:13,113 [INFO] [EVAL] Step 1400 | Val Loss: 1.3972 | Val Acc: 0.4363
2026-01-07 22:32:13,147 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_best.npz
2026-01-07 22:32:13,148 [INFO] New best validation accuracy: 0.4363
2026-01-07 22:32:17,606 [INFO] Step 1410/4740 | Loss: 1.4471 | Acc: 0.3750 | LR: 3.57e-05
2026-01-07 22:32:19,059 [WARNING] Skipping batch due to non-finite loss at step=1413 (loss=nan, epoch=7).
2026-01-07 22:32:21,869 [WARNING] Skipping batch due to non-finite loss at step=1419 (loss=nan, epoch=7).
2026-01-07 22:32:22,297 [INFO] Step 1420/4740 | Loss: 1.3670 | Acc: 0.5625 | LR: 3.57e-05
2026-01-07 22:32:23,400 [WARNING] Skipping batch due to non-finite loss at step=1422 (loss=nan, epoch=7).
2026-01-07 22:32:26,868 [INFO] Step 1430/4740 | Loss: 1.6385 | Acc: 0.3438 | LR: 3.56e-05
2026-01-07 22:32:29,407 [WARNING] Skipping batch due to non-finite loss at step=1435 (loss=nan, epoch=7).
2026-01-07 22:32:31,452 [WARNING] Skipping batch due to non-finite loss at step=1439 (loss=nan, epoch=7).
2026-01-07 22:32:31,960 [INFO] Step 1440/4740 | Loss: 1.6502 | Acc: 0.2500 | LR: 3.55e-05
2026-01-07 22:32:36,464 [INFO] Step 1450/4740 | Loss: 1.4325 | Acc: 0.5000 | LR: 3.54e-05
2026-01-07 22:32:38,424 [WARNING] Skipping batch due to non-finite loss at step=1454 (loss=nan, epoch=7).
2026-01-07 22:32:41,029 [INFO] Step 1460/4740 | Loss: 1.4087 | Acc: 0.4062 | LR: 3.53e-05
2026-01-07 22:32:45,687 [INFO] Step 1470/4740 | Loss: 1.4751 | Acc: 0.4062 | LR: 3.52e-05
2026-01-07 22:32:50,173 [INFO] Step 1480/4740 | Loss: 1.5449 | Acc: 0.2812 | LR: 3.51e-05
2026-01-07 22:32:54,508 [INFO] Step 1490/4740 | Loss: 1.4871 | Acc: 0.4688 | LR: 3.50e-05
2026-01-07 22:32:57,205 [WARNING] Skipping batch due to non-finite loss at step=1496 (loss=nan, epoch=7).
2026-01-07 22:32:57,915 [WARNING] Skipping batch due to non-finite loss at step=1497 (loss=nan, epoch=7).
2026-01-07 22:32:58,119 [WARNING] Skipping batch due to non-finite loss at step=1497 (loss=nan, epoch=7).
2026-01-07 22:33:00,399 [INFO] Step 1500/4740 | Loss: 1.5237 | Acc: 0.3125 | LR: 3.49e-05
2026-01-07 22:33:06,436 [INFO] [EVAL] Step 1500 | Val Loss: 1.4125 | Val Acc: 0.4225
2026-01-07 22:33:06,474 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_step_1500.npz
2026-01-07 22:33:11,415 [INFO] Step 1510/4740 | Loss: 1.5410 | Acc: 0.4375 | LR: 3.48e-05
2026-01-07 22:33:15,559 [INFO] Step 1520/4740 | Loss: 1.5601 | Acc: 0.4062 | LR: 3.47e-05
2026-01-07 22:33:19,791 [INFO] Step 1530/4740 | Loss: 1.4601 | Acc: 0.4062 | LR: 3.46e-05
2026-01-07 22:33:25,175 [INFO] Step 1540/4740 | Loss: 1.2192 | Acc: 0.6875 | LR: 3.45e-05
2026-01-07 22:33:29,996 [INFO] Step 1550/4740 | Loss: 1.5665 | Acc: 0.4062 | LR: 3.44e-05
2026-01-07 22:33:34,277 [INFO] Step 1560/4740 | Loss: 1.5532 | Acc: 0.3438 | LR: 3.43e-05
2026-01-07 22:33:38,757 [INFO] Step 1570/4740 | Loss: 1.5278 | Acc: 0.3750 | LR: 3.42e-05
2026-01-07 22:33:43,151 [INFO] Step 1580/4740 | Loss: 1.6683 | Acc: 0.3125 | LR: 3.41e-05
2026-01-07 22:33:43,479 [INFO] Epoch 7 complete | Avg Loss: 1.4902 | Avg Acc: 0.4240 | Updates: 217 | Micro-batches: 237 | Skipped: 20 (loss=20, logits=0, grads=0)
2026-01-07 22:33:43,479 [INFO] Epoch 8/20
2026-01-07 22:33:47,798 [INFO] Step 1590/4740 | Loss: 1.4246 | Acc: 0.3750 | LR: 3.40e-05
2026-01-07 22:33:52,716 [INFO] Step 1600/4740 | Loss: 1.5537 | Acc: 0.5000 | LR: 3.39e-05
2026-01-07 22:33:58,653 [INFO] [EVAL] Step 1600 | Val Loss: 1.4656 | Val Acc: 0.3954
2026-01-07 22:34:02,763 [INFO] Step 1610/4740 | Loss: 1.6920 | Acc: 0.4375 | LR: 3.38e-05
2026-01-07 22:34:07,118 [INFO] Step 1620/4740 | Loss: 1.4676 | Acc: 0.4375 | LR: 3.37e-05
2026-01-07 22:34:11,613 [INFO] Step 1630/4740 | Loss: 1.5184 | Acc: 0.4062 | LR: 3.36e-05
2026-01-07 22:34:16,100 [INFO] Step 1640/4740 | Loss: 1.3431 | Acc: 0.5000 | LR: 3.35e-05
2026-01-07 22:34:20,308 [INFO] Step 1650/4740 | Loss: 1.2780 | Acc: 0.6250 | LR: 3.34e-05
2026-01-07 22:34:24,660 [INFO] Step 1660/4740 | Loss: 1.5477 | Acc: 0.2812 | LR: 3.32e-05
2026-01-07 22:34:29,269 [INFO] Step 1670/4740 | Loss: 1.5901 | Acc: 0.3438 | LR: 3.31e-05
2026-01-07 22:34:33,869 [INFO] Step 1680/4740 | Loss: 1.5523 | Acc: 0.4375 | LR: 3.30e-05
2026-01-07 22:34:38,490 [INFO] Step 1690/4740 | Loss: 1.5945 | Acc: 0.3125 | LR: 3.29e-05
2026-01-07 22:34:43,254 [INFO] Step 1700/4740 | Loss: 1.4465 | Acc: 0.5000 | LR: 3.28e-05
2026-01-07 22:34:49,138 [INFO] [EVAL] Step 1700 | Val Loss: 1.4040 | Val Acc: 0.4375
2026-01-07 22:34:49,173 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_best.npz
2026-01-07 22:34:49,174 [INFO] New best validation accuracy: 0.4375
2026-01-07 22:34:53,764 [INFO] Step 1710/4740 | Loss: 1.3115 | Acc: 0.5000 | LR: 3.27e-05
2026-01-07 22:34:58,185 [INFO] Step 1720/4740 | Loss: 1.3741 | Acc: 0.4375 | LR: 3.26e-05
2026-01-07 22:35:02,507 [INFO] Step 1730/4740 | Loss: 1.5424 | Acc: 0.4375 | LR: 3.25e-05
2026-01-07 22:35:06,833 [INFO] Step 1740/4740 | Loss: 1.4582 | Acc: 0.5312 | LR: 3.23e-05
2026-01-07 22:35:11,168 [INFO] Step 1750/4740 | Loss: 1.3622 | Acc: 0.5625 | LR: 3.22e-05
2026-01-07 22:35:15,761 [INFO] Step 1760/4740 | Loss: 1.5507 | Acc: 0.4062 | LR: 3.21e-05
2026-01-07 22:35:20,303 [INFO] Step 1770/4740 | Loss: 1.5578 | Acc: 0.4062 | LR: 3.20e-05
2026-01-07 22:35:24,411 [INFO] Step 1780/4740 | Loss: 1.4566 | Acc: 0.4688 | LR: 3.19e-05
2026-01-07 22:35:28,826 [INFO] Step 1790/4740 | Loss: 1.6241 | Acc: 0.3438 | LR: 3.18e-05
2026-01-07 22:35:33,314 [INFO] Step 1800/4740 | Loss: 1.3636 | Acc: 0.5000 | LR: 3.16e-05
2026-01-07 22:35:39,141 [INFO] [EVAL] Step 1800 | Val Loss: 1.4165 | Val Acc: 0.4243
2026-01-07 22:35:43,344 [INFO] Step 1810/4740 | Loss: 1.5250 | Acc: 0.4062 | LR: 3.15e-05
2026-01-07 22:35:46,744 [INFO] Epoch 8 complete | Avg Loss: 1.4691 | Avg Acc: 0.4408 | Updates: 237 | Micro-batches: 237 | Skipped: 0 (loss=0, logits=0, grads=0)
2026-01-07 22:35:46,745 [INFO] Epoch 9/20
2026-01-07 22:35:47,900 [INFO] Step 1820/4740 | Loss: 1.2409 | Acc: 0.6250 | LR: 3.14e-05
2026-01-07 22:35:52,318 [INFO] Step 1830/4740 | Loss: 1.4643 | Acc: 0.4062 | LR: 3.13e-05
2026-01-07 22:35:56,668 [INFO] Step 1840/4740 | Loss: 1.3468 | Acc: 0.5312 | LR: 3.12e-05
2026-01-07 22:36:01,033 [INFO] Step 1850/4740 | Loss: 1.4288 | Acc: 0.4375 | LR: 3.10e-05
2026-01-07 22:36:05,551 [INFO] Step 1860/4740 | Loss: 1.6737 | Acc: 0.1875 | LR: 3.09e-05
2026-01-07 22:36:10,051 [INFO] Step 1870/4740 | Loss: 1.3720 | Acc: 0.4375 | LR: 3.08e-05
2026-01-07 22:36:14,459 [INFO] Step 1880/4740 | Loss: 1.4383 | Acc: 0.4375 | LR: 3.07e-05
2026-01-07 22:36:18,706 [INFO] Step 1890/4740 | Loss: 1.5249 | Acc: 0.5000 | LR: 3.06e-05
2026-01-07 22:36:23,732 [INFO] Step 1900/4740 | Loss: 1.4609 | Acc: 0.4062 | LR: 3.04e-05
2026-01-07 22:36:29,544 [INFO] [EVAL] Step 1900 | Val Loss: 1.3993 | Val Acc: 0.4351
2026-01-07 22:36:34,064 [INFO] Step 1910/4740 | Loss: 1.4780 | Acc: 0.5000 | LR: 3.03e-05
2026-01-07 22:36:38,539 [INFO] Step 1920/4740 | Loss: 1.5144 | Acc: 0.4062 | LR: 3.02e-05
2026-01-07 22:36:42,819 [INFO] Step 1930/4740 | Loss: 1.5269 | Acc: 0.3438 | LR: 3.01e-05
2026-01-07 22:36:47,403 [INFO] Step 1940/4740 | Loss: 1.4229 | Acc: 0.5312 | LR: 2.99e-05
2026-01-07 22:36:52,066 [INFO] Step 1950/4740 | Loss: 1.2959 | Acc: 0.5000 | LR: 2.98e-05
2026-01-07 22:36:56,520 [INFO] Step 1960/4740 | Loss: 1.4450 | Acc: 0.4688 | LR: 2.97e-05
2026-01-07 22:37:01,175 [INFO] Step 1970/4740 | Loss: 1.6678 | Acc: 0.2188 | LR: 2.95e-05
2026-01-07 22:37:05,630 [INFO] Step 1980/4740 | Loss: 1.5829 | Acc: 0.2812 | LR: 2.94e-05
2026-01-07 22:37:10,024 [INFO] Step 1990/4740 | Loss: 1.4936 | Acc: 0.4375 | LR: 2.93e-05
2026-01-07 22:37:14,967 [INFO] Step 2000/4740 | Loss: 1.3984 | Acc: 0.5938 | LR: 2.92e-05
2026-01-07 22:37:20,788 [INFO] [EVAL] Step 2000 | Val Loss: 1.3548 | Val Acc: 0.4423
2026-01-07 22:37:20,822 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_best.npz
2026-01-07 22:37:20,824 [INFO] New best validation accuracy: 0.4423
2026-01-07 22:37:20,861 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_step_2000.npz
2026-01-07 22:37:25,424 [INFO] Step 2010/4740 | Loss: 1.4196 | Acc: 0.5000 | LR: 2.90e-05
2026-01-07 22:37:29,659 [INFO] Step 2020/4740 | Loss: 1.3111 | Acc: 0.5312 | LR: 2.89e-05
2026-01-07 22:37:33,894 [INFO] Step 2030/4740 | Loss: 1.4662 | Acc: 0.4688 | LR: 2.88e-05
2026-01-07 22:37:38,494 [INFO] Step 2040/4740 | Loss: 1.6090 | Acc: 0.3438 | LR: 2.86e-05
2026-01-07 22:37:42,681 [INFO] Step 2050/4740 | Loss: 1.3164 | Acc: 0.5000 | LR: 2.85e-05
2026-01-07 22:37:44,763 [INFO] Epoch 9 complete | Avg Loss: 1.4422 | Avg Acc: 0.4528 | Updates: 237 | Micro-batches: 237 | Skipped: 0 (loss=0, logits=0, grads=0)
2026-01-07 22:37:44,763 [INFO] Epoch 10/20
2026-01-07 22:37:47,430 [INFO] Step 2060/4740 | Loss: 1.5636 | Acc: 0.4062 | LR: 2.84e-05
2026-01-07 22:37:52,000 [INFO] Step 2070/4740 | Loss: 1.4289 | Acc: 0.4375 | LR: 2.82e-05
2026-01-07 22:37:56,474 [INFO] Step 2080/4740 | Loss: 1.4676 | Acc: 0.3438 | LR: 2.81e-05
2026-01-07 22:38:00,893 [INFO] Step 2090/4740 | Loss: 1.4562 | Acc: 0.5312 | LR: 2.80e-05
2026-01-07 22:38:04,010 [WARNING] Skipping batch due to non-finite loss at step=2096 (loss=nan, epoch=10).
2026-01-07 22:38:06,248 [INFO] Step 2100/4740 | Loss: 1.5794 | Acc: 0.4688 | LR: 2.78e-05
2026-01-07 22:38:12,009 [INFO] [EVAL] Step 2100 | Val Loss: 1.3914 | Val Acc: 0.4279
2026-01-07 22:38:16,480 [INFO] Step 2110/4740 | Loss: 1.2837 | Acc: 0.4688 | LR: 2.77e-05
2026-01-07 22:38:20,715 [INFO] Step 2120/4740 | Loss: 1.3167 | Acc: 0.5000 | LR: 2.76e-05
2026-01-07 22:38:24,863 [INFO] Step 2130/4740 | Loss: 1.5433 | Acc: 0.4375 | LR: 2.74e-05
2026-01-07 22:38:29,163 [INFO] Step 2140/4740 | Loss: 1.5032 | Acc: 0.4688 | LR: 2.73e-05
2026-01-07 22:38:33,732 [INFO] Step 2150/4740 | Loss: 1.4330 | Acc: 0.4062 | LR: 2.72e-05
2026-01-07 22:38:38,255 [INFO] Step 2160/4740 | Loss: 1.4278 | Acc: 0.4688 | LR: 2.70e-05
2026-01-07 22:38:42,529 [INFO] Step 2170/4740 | Loss: 1.5135 | Acc: 0.3438 | LR: 2.69e-05
2026-01-07 22:38:46,998 [INFO] Step 2180/4740 | Loss: 1.1568 | Acc: 0.6250 | LR: 2.68e-05
2026-01-07 22:38:51,333 [INFO] Step 2190/4740 | Loss: 1.5068 | Acc: 0.3750 | LR: 2.66e-05
2026-01-07 22:38:56,144 [INFO] Step 2200/4740 | Loss: 1.6707 | Acc: 0.3438 | LR: 2.65e-05
2026-01-07 22:39:02,045 [INFO] [EVAL] Step 2200 | Val Loss: 1.3471 | Val Acc: 0.4603
2026-01-07 22:39:02,072 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_best.npz
2026-01-07 22:39:02,075 [INFO] New best validation accuracy: 0.4603
2026-01-07 22:39:06,714 [INFO] Step 2210/4740 | Loss: 1.4222 | Acc: 0.5000 | LR: 2.63e-05
2026-01-07 22:39:11,068 [INFO] Step 2220/4740 | Loss: 1.4957 | Acc: 0.4375 | LR: 2.62e-05
2026-01-07 22:39:15,559 [INFO] Step 2230/4740 | Loss: 1.3723 | Acc: 0.4375 | LR: 2.61e-05
2026-01-07 22:39:20,027 [INFO] Step 2240/4740 | Loss: 1.2927 | Acc: 0.5938 | LR: 2.59e-05
2026-01-07 22:39:24,621 [INFO] Step 2250/4740 | Loss: 1.4442 | Acc: 0.5312 | LR: 2.58e-05
2026-01-07 22:39:24,787 [WARNING] Skipping batch due to non-finite loss at step=2250 (loss=nan, epoch=10).
2026-01-07 22:39:28,925 [WARNING] Skipping batch due to non-finite loss at step=2259 (loss=nan, epoch=10).
2026-01-07 22:39:29,423 [INFO] Step 2260/4740 | Loss: 1.3809 | Acc: 0.4688 | LR: 2.57e-05
2026-01-07 22:39:33,553 [WARNING] Skipping batch due to non-finite loss at step=2269 (loss=nan, epoch=10).
2026-01-07 22:39:33,767 [WARNING] Skipping batch due to non-finite loss at step=2269 (loss=nan, epoch=10).
2026-01-07 22:39:34,303 [INFO] Step 2270/4740 | Loss: 1.4074 | Acc: 0.4375 | LR: 2.55e-05
2026-01-07 22:39:38,756 [INFO] Step 2280/4740 | Loss: 1.3819 | Acc: 0.5938 | LR: 2.54e-05
2026-01-07 22:39:41,568 [INFO] Epoch 10 complete | Avg Loss: 1.4254 | Avg Acc: 0.4631 | Updates: 232 | Micro-batches: 237 | Skipped: 5 (loss=5, logits=0, grads=0)
2026-01-07 22:39:41,568 [INFO] Epoch 11/20
2026-01-07 22:39:43,328 [INFO] Step 2290/4740 | Loss: 1.5039 | Acc: 0.4062 | LR: 2.52e-05
2026-01-07 22:39:48,202 [INFO] Step 2300/4740 | Loss: 1.4248 | Acc: 0.4688 | LR: 2.51e-05
2026-01-07 22:39:54,129 [INFO] [EVAL] Step 2300 | Val Loss: 1.3253 | Val Acc: 0.4738
2026-01-07 22:39:54,178 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_best.npz
2026-01-07 22:39:54,180 [INFO] New best validation accuracy: 0.4738
2026-01-07 22:39:58,714 [INFO] Step 2310/4740 | Loss: 1.4696 | Acc: 0.4688 | LR: 2.50e-05
2026-01-07 22:40:03,098 [INFO] Step 2320/4740 | Loss: 1.3619 | Acc: 0.5000 | LR: 2.48e-05
2026-01-07 22:40:03,837 [WARNING] Skipping batch due to non-finite loss at step=2321 (loss=nan, epoch=11).
2026-01-07 22:40:07,876 [INFO] Step 2330/4740 | Loss: 1.4695 | Acc: 0.4062 | LR: 2.47e-05
2026-01-07 22:40:09,945 [WARNING] Skipping batch due to non-finite loss at step=2334 (loss=nan, epoch=11).
2026-01-07 22:40:12,532 [INFO] Step 2340/4740 | Loss: 1.5425 | Acc: 0.4375 | LR: 2.45e-05
2026-01-07 22:40:17,074 [INFO] Step 2350/4740 | Loss: 1.4845 | Acc: 0.3438 | LR: 2.44e-05
2026-01-07 22:40:19,083 [WARNING] Skipping batch due to non-finite loss at step=2354 (loss=nan, epoch=11).
2026-01-07 22:40:20,260 [WARNING] Skipping batch due to non-finite loss at step=2356 (loss=nan, epoch=11).
2026-01-07 22:40:22,057 [INFO] Step 2360/4740 | Loss: 1.4174 | Acc: 0.4375 | LR: 2.42e-05
2026-01-07 22:40:22,311 [WARNING] Skipping batch due to non-finite loss at step=2360 (loss=nan, epoch=11).
2026-01-07 22:40:23,302 [WARNING] Skipping batch due to non-finite loss at step=2362 (loss=nan, epoch=11).
2026-01-07 22:40:24,396 [WARNING] Skipping batch due to non-finite loss at step=2364 (loss=nan, epoch=11).
2026-01-07 22:40:27,239 [INFO] Step 2370/4740 | Loss: 1.3842 | Acc: 0.3438 | LR: 2.41e-05
2026-01-07 22:40:28,679 [WARNING] Skipping batch due to non-finite loss at step=2373 (loss=nan, epoch=11).
2026-01-07 22:40:32,051 [INFO] Step 2380/4740 | Loss: 1.5817 | Acc: 0.3750 | LR: 2.40e-05
2026-01-07 22:40:32,675 [WARNING] Skipping batch due to non-finite loss at step=2381 (loss=nan, epoch=11).
2026-01-07 22:40:36,919 [INFO] Step 2390/4740 | Loss: 1.3560 | Acc: 0.4688 | LR: 2.38e-05
2026-01-07 22:40:41,895 [INFO] Step 2400/4740 | Loss: 1.3763 | Acc: 0.4062 | LR: 2.37e-05
2026-01-07 22:40:47,712 [INFO] [EVAL] Step 2400 | Val Loss: 1.3358 | Val Acc: 0.4625
2026-01-07 22:40:49,461 [WARNING] Skipping batch due to non-finite loss at step=2403 (loss=nan, epoch=11).
2026-01-07 22:40:52,892 [INFO] Step 2410/4740 | Loss: 1.2107 | Acc: 0.6562 | LR: 2.35e-05
2026-01-07 22:40:57,147 [INFO] Step 2420/4740 | Loss: 1.1100 | Acc: 0.6875 | LR: 2.34e-05
2026-01-07 22:41:01,465 [INFO] Step 2430/4740 | Loss: 1.3046 | Acc: 0.5625 | LR: 2.33e-05
2026-01-07 22:41:05,872 [INFO] Step 2440/4740 | Loss: 1.2419 | Acc: 0.5312 | LR: 2.31e-05
2026-01-07 22:41:09,976 [INFO] Step 2450/4740 | Loss: 1.4341 | Acc: 0.3750 | LR: 2.30e-05
2026-01-07 22:41:15,150 [INFO] Step 2460/4740 | Loss: 1.5478 | Acc: 0.4688 | LR: 2.28e-05
2026-01-07 22:41:19,757 [INFO] Step 2470/4740 | Loss: 1.5725 | Acc: 0.4062 | LR: 2.27e-05
2026-01-07 22:41:24,998 [INFO] Step 2480/4740 | Loss: 1.3029 | Acc: 0.5625 | LR: 2.25e-05
2026-01-07 22:41:29,736 [INFO] Step 2490/4740 | Loss: 1.2673 | Acc: 0.5938 | LR: 2.24e-05
2026-01-07 22:41:35,148 [INFO] Step 2500/4740 | Loss: 1.3530 | Acc: 0.5312 | LR: 2.22e-05
2026-01-07 22:41:41,196 [INFO] [EVAL] Step 2500 | Val Loss: 1.3312 | Val Acc: 0.4712
2026-01-07 22:41:41,235 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_step_2500.npz
2026-01-07 22:41:44,102 [INFO] Epoch 11 complete | Avg Loss: 1.4083 | Avg Acc: 0.4727 | Updates: 220 | Micro-batches: 237 | Skipped: 17 (loss=17, logits=0, grads=0)
2026-01-07 22:41:44,102 [INFO] Epoch 12/20
2026-01-07 22:41:45,767 [INFO] Step 2510/4740 | Loss: 1.4033 | Acc: 0.4688 | LR: 2.21e-05
2026-01-07 22:41:49,091 [WARNING] Skipping batch due to non-finite loss at step=2517 (loss=nan, epoch=12).
2026-01-07 22:41:50,104 [WARNING] Skipping batch due to non-finite loss at step=2519 (loss=nan, epoch=12).
2026-01-07 22:41:50,656 [INFO] Step 2520/4740 | Loss: 1.2340 | Acc: 0.5625 | LR: 2.20e-05
2026-01-07 22:41:52,346 [WARNING] Skipping batch due to non-finite loss at step=2523 (loss=nan, epoch=12).
2026-01-07 22:41:54,816 [WARNING] Skipping batch due to non-finite loss at step=2528 (loss=nan, epoch=12).
2026-01-07 22:41:55,744 [INFO] Step 2530/4740 | Loss: 1.2520 | Acc: 0.5625 | LR: 2.18e-05
2026-01-07 22:41:55,912 [WARNING] Skipping batch due to non-finite loss at step=2530 (loss=nan, epoch=12).
2026-01-07 22:41:57,511 [WARNING] Skipping batch due to non-finite loss at step=2533 (loss=nan, epoch=12).
2026-01-07 22:41:57,754 [WARNING] Skipping batch due to non-finite loss at step=2533 (loss=nan, epoch=12).
2026-01-07 22:41:58,980 [WARNING] Skipping batch due to non-finite loss at step=2535 (loss=nan, epoch=12).
2026-01-07 22:42:01,216 [INFO] Step 2540/4740 | Loss: 1.2676 | Acc: 0.5625 | LR: 2.17e-05
2026-01-07 22:42:01,377 [WARNING] Skipping batch due to non-finite loss at step=2540 (loss=nan, epoch=12).
2026-01-07 22:42:01,656 [WARNING] Skipping batch due to non-finite loss at step=2540 (loss=nan, epoch=12).
2026-01-07 22:42:06,979 [INFO] Step 2550/4740 | Loss: 1.3915 | Acc: 0.5312 | LR: 2.15e-05
2026-01-07 22:42:11,659 [INFO] Step 2560/4740 | Loss: 1.4750 | Acc: 0.4375 | LR: 2.14e-05
2026-01-07 22:42:16,358 [INFO] Step 2570/4740 | Loss: 1.4985 | Acc: 0.4375 | LR: 2.12e-05
2026-01-07 22:42:21,171 [INFO] Step 2580/4740 | Loss: 1.3729 | Acc: 0.4375 | LR: 2.11e-05
2026-01-07 22:42:26,329 [INFO] Step 2590/4740 | Loss: 1.5105 | Acc: 0.4375 | LR: 2.09e-05
2026-01-07 22:42:31,713 [INFO] Step 2600/4740 | Loss: 1.3615 | Acc: 0.5312 | LR: 2.08e-05
2026-01-07 22:42:37,777 [INFO] [EVAL] Step 2600 | Val Loss: 1.3371 | Val Acc: 0.4637
2026-01-07 22:42:42,215 [INFO] Step 2610/4740 | Loss: 1.2782 | Acc: 0.5625 | LR: 2.07e-05
2026-01-07 22:42:46,928 [INFO] Step 2620/4740 | Loss: 1.5973 | Acc: 0.3438 | LR: 2.05e-05
2026-01-07 22:42:51,393 [INFO] Step 2630/4740 | Loss: 1.4886 | Acc: 0.4688 | LR: 2.04e-05
2026-01-07 22:42:55,839 [INFO] Step 2640/4740 | Loss: 1.3548 | Acc: 0.5625 | LR: 2.02e-05
2026-01-07 22:43:00,519 [INFO] Step 2650/4740 | Loss: 1.2278 | Acc: 0.5625 | LR: 2.01e-05
2026-01-07 22:43:05,257 [INFO] Step 2660/4740 | Loss: 1.4567 | Acc: 0.4062 | LR: 1.99e-05
2026-01-07 22:43:09,433 [INFO] Step 2670/4740 | Loss: 1.4194 | Acc: 0.4375 | LR: 1.98e-05
2026-01-07 22:43:13,906 [INFO] Step 2680/4740 | Loss: 1.3301 | Acc: 0.4688 | LR: 1.96e-05
2026-01-07 22:43:18,589 [INFO] Step 2690/4740 | Loss: 1.1737 | Acc: 0.6562 | LR: 1.95e-05
2026-01-07 22:43:23,373 [INFO] Step 2700/4740 | Loss: 1.4149 | Acc: 0.5312 | LR: 1.94e-05
2026-01-07 22:43:29,121 [INFO] [EVAL] Step 2700 | Val Loss: 1.3183 | Val Acc: 0.4663
2026-01-07 22:43:33,404 [INFO] Step 2710/4740 | Loss: 1.5518 | Acc: 0.3750 | LR: 1.92e-05
2026-01-07 22:43:37,539 [INFO] Step 2720/4740 | Loss: 1.3721 | Acc: 0.4375 | LR: 1.91e-05
2026-01-07 22:43:37,539 [INFO] Epoch 12 complete | Avg Loss: 1.3890 | Avg Acc: 0.4805 | Updates: 213 | Micro-batches: 237 | Skipped: 24 (loss=24, logits=0, grads=0)
2026-01-07 22:43:37,539 [INFO] Epoch 13/20
2026-01-07 22:43:42,497 [INFO] Step 2730/4740 | Loss: 1.3475 | Acc: 0.4688 | LR: 1.89e-05
2026-01-07 22:43:43,044 [WARNING] Skipping batch due to non-finite loss at step=2731 (loss=nan, epoch=13).
2026-01-07 22:43:47,010 [INFO] Step 2740/4740 | Loss: 1.2995 | Acc: 0.5000 | LR: 1.88e-05
2026-01-07 22:43:51,543 [INFO] Step 2750/4740 | Loss: 1.4087 | Acc: 0.5000 | LR: 1.86e-05
2026-01-07 22:43:55,933 [INFO] Step 2760/4740 | Loss: 1.3416 | Acc: 0.4375 | LR: 1.85e-05
2026-01-07 22:44:00,518 [INFO] Step 2770/4740 | Loss: 1.3127 | Acc: 0.5312 | LR: 1.84e-05
2026-01-07 22:44:05,041 [INFO] Step 2780/4740 | Loss: 1.2995 | Acc: 0.5938 | LR: 1.82e-05
2026-01-07 22:44:09,371 [INFO] Step 2790/4740 | Loss: 1.4197 | Acc: 0.5625 | LR: 1.81e-05
2026-01-07 22:44:14,072 [INFO] Step 2800/4740 | Loss: 1.3550 | Acc: 0.5312 | LR: 1.79e-05
2026-01-07 22:44:20,023 [INFO] [EVAL] Step 2800 | Val Loss: 1.3116 | Val Acc: 0.4760
2026-01-07 22:44:20,066 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_best.npz
2026-01-07 22:44:20,068 [INFO] New best validation accuracy: 0.4760
2026-01-07 22:44:24,462 [INFO] Step 2810/4740 | Loss: 1.4203 | Acc: 0.3750 | LR: 1.78e-05
2026-01-07 22:44:29,164 [INFO] Step 2820/4740 | Loss: 1.3538 | Acc: 0.5938 | LR: 1.76e-05
2026-01-07 22:44:33,627 [INFO] Step 2830/4740 | Loss: 1.3040 | Acc: 0.4062 | LR: 1.75e-05
2026-01-07 22:44:38,185 [INFO] Step 2840/4740 | Loss: 1.5197 | Acc: 0.4062 | LR: 1.73e-05
2026-01-07 22:44:42,619 [INFO] Step 2850/4740 | Loss: 1.4208 | Acc: 0.3750 | LR: 1.72e-05
2026-01-07 22:44:47,124 [INFO] Step 2860/4740 | Loss: 1.3659 | Acc: 0.5000 | LR: 1.71e-05
2026-01-07 22:44:51,542 [INFO] Step 2870/4740 | Loss: 1.3909 | Acc: 0.4062 | LR: 1.69e-05
2026-01-07 22:44:55,785 [INFO] Step 2880/4740 | Loss: 1.3431 | Acc: 0.5312 | LR: 1.68e-05
2026-01-07 22:44:57,205 [WARNING] Skipping batch due to non-finite loss at step=2883 (loss=nan, epoch=13).
2026-01-07 22:44:58,897 [WARNING] Skipping batch due to non-finite loss at step=2886 (loss=nan, epoch=13).
2026-01-07 22:45:00,549 [INFO] Step 2890/4740 | Loss: 1.3719 | Acc: 0.4688 | LR: 1.66e-05
2026-01-07 22:45:03,400 [WARNING] Skipping batch due to non-finite loss at step=2896 (loss=nan, epoch=13).
2026-01-07 22:45:05,715 [INFO] Step 2900/4740 | Loss: 1.1390 | Acc: 0.6250 | LR: 1.65e-05
2026-01-07 22:45:11,637 [INFO] [EVAL] Step 2900 | Val Loss: 1.3058 | Val Acc: 0.4736
2026-01-07 22:45:15,983 [INFO] Step 2910/4740 | Loss: 1.4934 | Acc: 0.4688 | LR: 1.64e-05
2026-01-07 22:45:20,614 [INFO] Step 2920/4740 | Loss: 1.3098 | Acc: 0.5312 | LR: 1.62e-05
2026-01-07 22:45:25,031 [INFO] Step 2930/4740 | Loss: 1.1616 | Acc: 0.5938 | LR: 1.61e-05
2026-01-07 22:45:29,408 [INFO] Step 2940/4740 | Loss: 1.4469 | Acc: 0.5312 | LR: 1.59e-05
2026-01-07 22:45:33,769 [INFO] Step 2950/4740 | Loss: 1.2906 | Acc: 0.5625 | LR: 1.58e-05
2026-01-07 22:45:34,835 [INFO] Epoch 13 complete | Avg Loss: 1.3723 | Avg Acc: 0.4952 | Updates: 233 | Micro-batches: 237 | Skipped: 4 (loss=4, logits=0, grads=0)
2026-01-07 22:45:34,835 [INFO] Epoch 14/20
2026-01-07 22:45:36,485 [WARNING] Skipping batch due to non-finite loss at step=2955 (loss=nan, epoch=14).
2026-01-07 22:45:38,658 [WARNING] Skipping batch due to non-finite loss at step=2959 (loss=nan, epoch=14).
2026-01-07 22:45:39,202 [INFO] Step 2960/4740 | Loss: 1.4672 | Acc: 0.3750 | LR: 1.57e-05
2026-01-07 22:45:43,640 [INFO] Step 2970/4740 | Loss: 1.4198 | Acc: 0.4375 | LR: 1.55e-05
2026-01-07 22:45:48,076 [INFO] Step 2980/4740 | Loss: 1.4027 | Acc: 0.5625 | LR: 1.54e-05
2026-01-07 22:45:48,720 [WARNING] Skipping batch due to non-finite loss at step=2981 (loss=nan, epoch=14).
2026-01-07 22:45:53,129 [INFO] Step 2990/4740 | Loss: 1.5610 | Acc: 0.5000 | LR: 1.52e-05
2026-01-07 22:45:58,125 [INFO] Step 3000/4740 | Loss: 1.1922 | Acc: 0.6562 | LR: 1.51e-05
2026-01-07 22:46:04,116 [INFO] [EVAL] Step 3000 | Val Loss: 1.3482 | Val Acc: 0.4483
2026-01-07 22:46:04,153 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_step_3000.npz
2026-01-07 22:46:08,607 [INFO] Step 3010/4740 | Loss: 1.3418 | Acc: 0.5938 | LR: 1.50e-05
2026-01-07 22:46:13,074 [INFO] Step 3020/4740 | Loss: 1.3392 | Acc: 0.4375 | LR: 1.48e-05
2026-01-07 22:46:17,489 [INFO] Step 3030/4740 | Loss: 1.3344 | Acc: 0.4062 | LR: 1.47e-05
2026-01-07 22:46:21,511 [INFO] Step 3040/4740 | Loss: 1.3185 | Acc: 0.5312 | LR: 1.45e-05
2026-01-07 22:46:25,708 [INFO] Step 3050/4740 | Loss: 1.4250 | Acc: 0.4375 | LR: 1.44e-05
2026-01-07 22:46:30,123 [INFO] Step 3060/4740 | Loss: 1.3024 | Acc: 0.4688 | LR: 1.43e-05
2026-01-07 22:46:34,333 [INFO] Step 3070/4740 | Loss: 1.3156 | Acc: 0.4062 | LR: 1.41e-05
2026-01-07 22:46:36,294 [WARNING] Skipping batch due to non-finite loss at step=3074 (loss=nan, epoch=14).
2026-01-07 22:46:39,212 [INFO] Step 3080/4740 | Loss: 1.3723 | Acc: 0.5312 | LR: 1.40e-05
2026-01-07 22:46:41,317 [WARNING] Skipping batch due to non-finite loss at step=3084 (loss=nan, epoch=14).
2026-01-07 22:46:43,972 [INFO] Step 3090/4740 | Loss: 1.3314 | Acc: 0.5938 | LR: 1.39e-05
2026-01-07 22:46:44,745 [WARNING] Skipping batch due to non-finite loss at step=3091 (loss=nan, epoch=14).
2026-01-07 22:46:49,163 [INFO] Step 3100/4740 | Loss: 1.4250 | Acc: 0.5000 | LR: 1.37e-05
2026-01-07 22:46:54,868 [INFO] [EVAL] Step 3100 | Val Loss: 1.2615 | Val Acc: 0.5078
2026-01-07 22:46:54,914 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_best.npz
2026-01-07 22:46:54,916 [INFO] New best validation accuracy: 0.5078
2026-01-07 22:46:59,679 [INFO] Step 3110/4740 | Loss: 1.3166 | Acc: 0.5000 | LR: 1.36e-05
2026-01-07 22:47:00,262 [WARNING] Skipping batch due to non-finite loss at step=3111 (loss=nan, epoch=14).
2026-01-07 22:47:00,873 [WARNING] Skipping batch due to non-finite loss at step=3112 (loss=nan, epoch=14).
2026-01-07 22:47:04,372 [INFO] Step 3120/4740 | Loss: 1.2227 | Acc: 0.5625 | LR: 1.35e-05
2026-01-07 22:47:04,986 [WARNING] Skipping batch due to non-finite loss at step=3121 (loss=nan, epoch=14).
2026-01-07 22:47:05,578 [WARNING] Skipping batch due to non-finite loss at step=3122 (loss=nan, epoch=14).
2026-01-07 22:47:09,077 [INFO] Step 3130/4740 | Loss: 1.2805 | Acc: 0.5312 | LR: 1.33e-05
2026-01-07 22:47:13,834 [INFO] Step 3140/4740 | Loss: 1.2195 | Acc: 0.5938 | LR: 1.32e-05
2026-01-07 22:47:18,780 [INFO] Step 3150/4740 | Loss: 1.4202 | Acc: 0.4375 | LR: 1.31e-05
2026-01-07 22:47:23,109 [INFO] Step 3160/4740 | Loss: 1.5741 | Acc: 0.3438 | LR: 1.29e-05
2026-01-07 22:47:27,528 [INFO] Step 3170/4740 | Loss: 1.2531 | Acc: 0.5312 | LR: 1.28e-05
2026-01-07 22:47:28,908 [INFO] Epoch 14 complete | Avg Loss: 1.3607 | Avg Acc: 0.4976 | Updates: 220 | Micro-batches: 237 | Skipped: 17 (loss=17, logits=0, grads=0)
2026-01-07 22:47:28,908 [INFO] Epoch 15/20
2026-01-07 22:47:32,365 [INFO] Step 3180/4740 | Loss: 1.5415 | Acc: 0.4688 | LR: 1.27e-05
2026-01-07 22:47:36,692 [INFO] Step 3190/4740 | Loss: 1.1365 | Acc: 0.6250 | LR: 1.25e-05
2026-01-07 22:47:39,402 [WARNING] Skipping batch due to non-finite loss at step=3195 (loss=nan, epoch=15).
2026-01-07 22:47:40,025 [WARNING] Skipping batch due to non-finite loss at step=3196 (loss=nan, epoch=15).
2026-01-07 22:47:42,320 [INFO] Step 3200/4740 | Loss: 1.2812 | Acc: 0.5625 | LR: 1.24e-05
2026-01-07 22:47:48,165 [INFO] [EVAL] Step 3200 | Val Loss: 1.2803 | Val Acc: 0.4972
2026-01-07 22:47:52,622 [INFO] Step 3210/4740 | Loss: 1.4700 | Acc: 0.4062 | LR: 1.23e-05
2026-01-07 22:47:55,788 [WARNING] Skipping batch due to non-finite loss at step=3217 (loss=nan, epoch=15).
2026-01-07 22:47:57,363 [INFO] Step 3220/4740 | Loss: 1.5470 | Acc: 0.4375 | LR: 1.21e-05
2026-01-07 22:48:01,062 [WARNING] Skipping batch due to non-finite loss at step=3228 (loss=nan, epoch=15).
2026-01-07 22:48:02,048 [INFO] Step 3230/4740 | Loss: 1.4673 | Acc: 0.4688 | LR: 1.20e-05
2026-01-07 22:48:02,628 [WARNING] Skipping batch due to non-finite loss at step=3231 (loss=nan, epoch=15).
2026-01-07 22:48:06,208 [WARNING] Skipping batch due to non-finite loss at step=3239 (loss=nan, epoch=15).
2026-01-07 22:48:06,674 [INFO] Step 3240/4740 | Loss: 1.4374 | Acc: 0.4062 | LR: 1.19e-05
2026-01-07 22:48:07,814 [WARNING] Skipping batch due to non-finite loss at step=3242 (loss=nan, epoch=15).
2026-01-07 22:48:09,840 [WARNING] Skipping batch due to non-finite loss at step=3246 (loss=nan, epoch=15).
2026-01-07 22:48:11,613 [INFO] Step 3250/4740 | Loss: 1.3886 | Acc: 0.4062 | LR: 1.17e-05
2026-01-07 22:48:13,684 [WARNING] Skipping batch due to non-finite loss at step=3254 (loss=nan, epoch=15).
2026-01-07 22:48:13,956 [WARNING] Skipping batch due to non-finite loss at step=3254 (loss=nan, epoch=15).
2026-01-07 22:48:16,884 [INFO] Step 3260/4740 | Loss: 1.4647 | Acc: 0.5000 | LR: 1.16e-05
2026-01-07 22:48:22,826 [INFO] Step 3270/4740 | Loss: 1.2632 | Acc: 0.5312 | LR: 1.15e-05
2026-01-07 22:48:28,135 [INFO] Step 3280/4740 | Loss: 1.2647 | Acc: 0.5625 | LR: 1.14e-05
2026-01-07 22:48:32,688 [INFO] Step 3290/4740 | Loss: 1.1825 | Acc: 0.6562 | LR: 1.12e-05
2026-01-07 22:48:38,322 [INFO] Step 3300/4740 | Loss: 1.2626 | Acc: 0.5000 | LR: 1.11e-05
2026-01-07 22:48:44,153 [INFO] [EVAL] Step 3300 | Val Loss: 1.2608 | Val Acc: 0.4755
2026-01-07 22:48:48,428 [INFO] Step 3310/4740 | Loss: 1.3955 | Acc: 0.5312 | LR: 1.10e-05
2026-01-07 22:48:53,489 [INFO] Step 3320/4740 | Loss: 1.2467 | Acc: 0.6875 | LR: 1.08e-05
2026-01-07 22:48:57,615 [INFO] Step 3330/4740 | Loss: 1.3235 | Acc: 0.5312 | LR: 1.07e-05
2026-01-07 22:49:02,145 [INFO] Step 3340/4740 | Loss: 1.2278 | Acc: 0.6562 | LR: 1.06e-05
2026-01-07 22:49:06,757 [INFO] Step 3350/4740 | Loss: 1.4453 | Acc: 0.5000 | LR: 1.05e-05
2026-01-07 22:49:11,426 [INFO] Step 3360/4740 | Loss: 1.3130 | Acc: 0.5312 | LR: 1.03e-05
2026-01-07 22:49:15,809 [INFO] Step 3370/4740 | Loss: 1.2138 | Acc: 0.5312 | LR: 1.02e-05
2026-01-07 22:49:20,026 [INFO] Step 3380/4740 | Loss: 1.2402 | Acc: 0.5000 | LR: 1.01e-05
2026-01-07 22:49:21,383 [INFO] Epoch 15 complete | Avg Loss: 1.3428 | Avg Acc: 0.5150 | Updates: 210 | Micro-batches: 237 | Skipped: 27 (loss=27, logits=0, grads=0)
2026-01-07 22:49:21,383 [INFO] Epoch 16/20
2026-01-07 22:49:24,791 [INFO] Step 3390/4740 | Loss: 1.4826 | Acc: 0.4375 | LR: 9.98e-06
2026-01-07 22:49:29,498 [INFO] Step 3400/4740 | Loss: 1.5015 | Acc: 0.4375 | LR: 9.86e-06
2026-01-07 22:49:35,240 [INFO] [EVAL] Step 3400 | Val Loss: 1.2613 | Val Acc: 0.4863
2026-01-07 22:49:39,589 [INFO] Step 3410/4740 | Loss: 1.3606 | Acc: 0.5000 | LR: 9.74e-06
2026-01-07 22:49:43,850 [WARNING] Skipping batch due to non-finite loss at step=3419 (loss=nan, epoch=16).
2026-01-07 22:49:44,311 [INFO] Step 3420/4740 | Loss: 1.2300 | Acc: 0.7188 | LR: 9.62e-06
2026-01-07 22:49:44,844 [WARNING] Skipping batch due to non-finite loss at step=3421 (loss=nan, epoch=16).
2026-01-07 22:49:48,898 [INFO] Step 3430/4740 | Loss: 1.3355 | Acc: 0.5000 | LR: 9.50e-06
2026-01-07 22:49:49,495 [WARNING] Skipping batch due to non-finite loss at step=3431 (loss=nan, epoch=16).
2026-01-07 22:49:52,919 [WARNING] Skipping batch due to non-finite loss at step=3438 (loss=nan, epoch=16).
2026-01-07 22:49:53,117 [WARNING] Skipping batch due to non-finite loss at step=3438 (loss=nan, epoch=16).
2026-01-07 22:49:54,169 [INFO] Step 3440/4740 | Loss: 1.4822 | Acc: 0.4375 | LR: 9.38e-06
2026-01-07 22:49:56,243 [WARNING] Skipping batch due to non-finite loss at step=3444 (loss=nan, epoch=16).
2026-01-07 22:49:59,061 [INFO] Step 3450/4740 | Loss: 1.2757 | Acc: 0.6250 | LR: 9.26e-06
2026-01-07 22:50:00,700 [WARNING] Skipping batch due to non-finite loss at step=3453 (loss=nan, epoch=16).
2026-01-07 22:50:03,822 [INFO] Step 3460/4740 | Loss: 1.1162 | Acc: 0.6562 | LR: 9.14e-06
2026-01-07 22:50:08,090 [INFO] Step 3470/4740 | Loss: 1.3655 | Acc: 0.4688 | LR: 9.03e-06
2026-01-07 22:50:09,132 [WARNING] Skipping batch due to non-finite loss at step=3472 (loss=nan, epoch=16).
2026-01-07 22:50:10,209 [WARNING] Skipping batch due to non-finite loss at step=3474 (loss=nan, epoch=16).
2026-01-07 22:50:13,044 [INFO] Step 3480/4740 | Loss: 1.4040 | Acc: 0.3750 | LR: 8.91e-06
2026-01-07 22:50:17,909 [INFO] Step 3490/4740 | Loss: 1.1730 | Acc: 0.6250 | LR: 8.79e-06
2026-01-07 22:50:21,718 [WARNING] Skipping batch due to non-finite loss at step=3498 (loss=nan, epoch=16).
2026-01-07 22:50:23,093 [INFO] Step 3500/4740 | Loss: 1.2891 | Acc: 0.5938 | LR: 8.68e-06
2026-01-07 22:50:28,986 [INFO] [EVAL] Step 3500 | Val Loss: 1.2617 | Val Acc: 0.4935
2026-01-07 22:50:29,009 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_step_3500.npz
2026-01-07 22:50:33,497 [INFO] Step 3510/4740 | Loss: 1.2998 | Acc: 0.5000 | LR: 8.56e-06
2026-01-07 22:50:38,087 [INFO] Step 3520/4740 | Loss: 1.3712 | Acc: 0.5312 | LR: 8.45e-06
2026-01-07 22:50:42,813 [INFO] Step 3530/4740 | Loss: 1.5174 | Acc: 0.4688 | LR: 8.34e-06
2026-01-07 22:50:47,421 [INFO] Step 3540/4740 | Loss: 1.1036 | Acc: 0.7188 | LR: 8.22e-06
2026-01-07 22:50:51,819 [INFO] Step 3550/4740 | Loss: 1.4778 | Acc: 0.4062 | LR: 8.11e-06
2026-01-07 22:50:56,156 [INFO] Step 3560/4740 | Loss: 1.2151 | Acc: 0.5938 | LR: 8.00e-06
2026-01-07 22:51:01,079 [INFO] Step 3570/4740 | Loss: 1.1566 | Acc: 0.7188 | LR: 7.89e-06
2026-01-07 22:51:05,568 [INFO] Step 3580/4740 | Loss: 1.3117 | Acc: 0.5312 | LR: 7.78e-06
2026-01-07 22:51:09,842 [INFO] Step 3590/4740 | Loss: 1.5404 | Acc: 0.4375 | LR: 7.67e-06
2026-01-07 22:51:14,770 [INFO] Step 3600/4740 | Loss: 1.4462 | Acc: 0.4062 | LR: 7.56e-06
2026-01-07 22:51:20,617 [INFO] [EVAL] Step 3600 | Val Loss: 1.2563 | Val Acc: 0.5000
2026-01-07 22:51:23,859 [INFO] Epoch 16 complete | Avg Loss: 1.3389 | Avg Acc: 0.5153 | Updates: 224 | Micro-batches: 237 | Skipped: 13 (loss=13, logits=0, grads=0)
2026-01-07 22:51:23,859 [INFO] Epoch 17/20
2026-01-07 22:51:25,659 [INFO] Step 3610/4740 | Loss: 1.3875 | Acc: 0.4375 | LR: 7.46e-06
2026-01-07 22:51:30,000 [INFO] Step 3620/4740 | Loss: 1.1724 | Acc: 0.6250 | LR: 7.35e-06
2026-01-07 22:51:34,592 [INFO] Step 3630/4740 | Loss: 1.4130 | Acc: 0.4688 | LR: 7.24e-06
2026-01-07 22:51:39,093 [INFO] Step 3640/4740 | Loss: 1.4054 | Acc: 0.5312 | LR: 7.14e-06
2026-01-07 22:51:43,693 [INFO] Step 3650/4740 | Loss: 1.2539 | Acc: 0.6562 | LR: 7.03e-06
2026-01-07 22:51:45,601 [WARNING] Skipping batch due to non-finite loss at step=3654 (loss=nan, epoch=17).
2026-01-07 22:51:48,184 [INFO] Step 3660/4740 | Loss: 1.2609 | Acc: 0.5625 | LR: 6.93e-06
2026-01-07 22:51:52,658 [INFO] Step 3670/4740 | Loss: 1.4856 | Acc: 0.3750 | LR: 6.82e-06
2026-01-07 22:51:56,412 [WARNING] Skipping batch due to non-finite loss at step=3678 (loss=nan, epoch=17).
2026-01-07 22:51:57,314 [INFO] Step 3680/4740 | Loss: 1.2474 | Acc: 0.5625 | LR: 6.72e-06
2026-01-07 22:51:59,725 [WARNING] Skipping batch due to non-finite loss at step=3685 (loss=nan, epoch=17).
2026-01-07 22:52:01,980 [INFO] Step 3690/4740 | Loss: 1.2147 | Acc: 0.6562 | LR: 6.62e-06
2026-01-07 22:52:07,051 [INFO] Step 3700/4740 | Loss: 1.3185 | Acc: 0.5312 | LR: 6.52e-06
2026-01-07 22:52:12,969 [INFO] [EVAL] Step 3700 | Val Loss: 1.2474 | Val Acc: 0.5024
2026-01-07 22:52:13,614 [WARNING] Skipping batch due to non-finite loss at step=3701 (loss=nan, epoch=17).
2026-01-07 22:52:17,466 [INFO] Step 3710/4740 | Loss: 1.3657 | Acc: 0.4688 | LR: 6.42e-06
2026-01-07 22:52:21,827 [INFO] Step 3720/4740 | Loss: 1.2360 | Acc: 0.5625 | LR: 6.32e-06
2026-01-07 22:52:26,173 [INFO] Step 3730/4740 | Loss: 1.2287 | Acc: 0.6875 | LR: 6.22e-06
2026-01-07 22:52:26,892 [WARNING] Skipping batch due to non-finite loss at step=3731 (loss=nan, epoch=17).
2026-01-07 22:52:27,995 [WARNING] Skipping batch due to non-finite loss at step=3733 (loss=nan, epoch=17).
2026-01-07 22:52:31,108 [INFO] Step 3740/4740 | Loss: 1.2945 | Acc: 0.5625 | LR: 6.12e-06
2026-01-07 22:52:35,617 [INFO] Step 3750/4740 | Loss: 1.4333 | Acc: 0.5312 | LR: 6.02e-06
2026-01-07 22:52:39,366 [WARNING] Skipping batch due to non-finite loss at step=3758 (loss=nan, epoch=17).
2026-01-07 22:52:40,325 [INFO] Step 3760/4740 | Loss: 1.2113 | Acc: 0.5000 | LR: 5.93e-06
2026-01-07 22:52:44,635 [INFO] Step 3770/4740 | Loss: 1.4825 | Acc: 0.4375 | LR: 5.83e-06
2026-01-07 22:52:49,086 [INFO] Step 3780/4740 | Loss: 1.2299 | Acc: 0.6250 | LR: 5.74e-06
2026-01-07 22:52:53,344 [INFO] Step 3790/4740 | Loss: 1.3291 | Acc: 0.4688 | LR: 5.64e-06
2026-01-07 22:52:57,986 [INFO] Step 3800/4740 | Loss: 1.4820 | Acc: 0.4062 | LR: 5.55e-06
2026-01-07 22:53:03,848 [INFO] [EVAL] Step 3800 | Val Loss: 1.2464 | Val Acc: 0.5108
2026-01-07 22:53:03,873 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_best.npz
2026-01-07 22:53:03,875 [INFO] New best validation accuracy: 0.5108
2026-01-07 22:53:08,194 [INFO] Step 3810/4740 | Loss: 1.4239 | Acc: 0.4688 | LR: 5.46e-06
2026-01-07 22:53:12,657 [INFO] Step 3820/4740 | Loss: 1.4449 | Acc: 0.5000 | LR: 5.37e-06
2026-01-07 22:53:17,426 [INFO] Step 3830/4740 | Loss: 1.3313 | Acc: 0.5000 | LR: 5.28e-06
2026-01-07 22:53:20,262 [INFO] Epoch 17 complete | Avg Loss: 1.3204 | Avg Acc: 0.5284 | Updates: 230 | Micro-batches: 237 | Skipped: 7 (loss=7, logits=0, grads=0)
2026-01-07 22:53:20,262 [INFO] Epoch 18/20
2026-01-07 22:53:21,908 [INFO] Step 3840/4740 | Loss: 1.2324 | Acc: 0.5938 | LR: 5.19e-06
2026-01-07 22:53:24,627 [WARNING] Skipping batch due to non-finite loss at step=3846 (loss=nan, epoch=18).
2026-01-07 22:53:26,604 [INFO] Step 3850/4740 | Loss: 1.3736 | Acc: 0.5625 | LR: 5.10e-06
2026-01-07 22:53:30,260 [WARNING] Skipping batch due to non-finite loss at step=3858 (loss=nan, epoch=18).
2026-01-07 22:53:31,089 [INFO] Step 3860/4740 | Loss: 1.2434 | Acc: 0.6562 | LR: 5.01e-06
2026-01-07 22:53:35,385 [INFO] Step 3870/4740 | Loss: 1.5008 | Acc: 0.4688 | LR: 4.92e-06
2026-01-07 22:53:39,726 [INFO] Step 3880/4740 | Loss: 1.2165 | Acc: 0.5625 | LR: 4.84e-06
2026-01-07 22:53:44,358 [INFO] Step 3890/4740 | Loss: 1.1904 | Acc: 0.6562 | LR: 4.75e-06
2026-01-07 22:53:49,611 [INFO] Step 3900/4740 | Loss: 1.4383 | Acc: 0.4375 | LR: 4.66e-06
2026-01-07 22:53:55,511 [INFO] [EVAL] Step 3900 | Val Loss: 1.2519 | Val Acc: 0.4988
2026-01-07 22:53:55,700 [WARNING] Skipping batch due to non-finite loss at step=3900 (loss=nan, epoch=18).
2026-01-07 22:54:00,366 [INFO] Step 3910/4740 | Loss: 1.3304 | Acc: 0.6250 | LR: 4.58e-06
2026-01-07 22:54:04,876 [INFO] Step 3920/4740 | Loss: 1.3020 | Acc: 0.5625 | LR: 4.50e-06
2026-01-07 22:54:09,569 [INFO] Step 3930/4740 | Loss: 1.1632 | Acc: 0.6250 | LR: 4.42e-06
2026-01-07 22:54:14,104 [INFO] Step 3940/4740 | Loss: 1.3544 | Acc: 0.5312 | LR: 4.33e-06
2026-01-07 22:54:18,529 [INFO] Step 3950/4740 | Loss: 1.4843 | Acc: 0.4688 | LR: 4.25e-06
2026-01-07 22:54:22,950 [INFO] Step 3960/4740 | Loss: 1.5425 | Acc: 0.4375 | LR: 4.17e-06
2026-01-07 22:54:27,467 [INFO] Step 3970/4740 | Loss: 1.3520 | Acc: 0.5000 | LR: 4.10e-06
2026-01-07 22:54:32,116 [INFO] Step 3980/4740 | Loss: 1.4141 | Acc: 0.4062 | LR: 4.02e-06
2026-01-07 22:54:36,506 [INFO] Step 3990/4740 | Loss: 1.2997 | Acc: 0.4688 | LR: 3.94e-06
2026-01-07 22:54:41,367 [INFO] Step 4000/4740 | Loss: 1.1716 | Acc: 0.6562 | LR: 3.87e-06
2026-01-07 22:54:47,431 [INFO] [EVAL] Step 4000 | Val Loss: 1.2470 | Val Acc: 0.5048
2026-01-07 22:54:47,454 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_step_4000.npz
2026-01-07 22:54:52,095 [INFO] Step 4010/4740 | Loss: 1.3101 | Acc: 0.4688 | LR: 3.79e-06
2026-01-07 22:54:56,473 [INFO] Step 4020/4740 | Loss: 1.3122 | Acc: 0.5312 | LR: 3.72e-06
2026-01-07 22:54:56,678 [WARNING] Skipping batch due to non-finite loss at step=4020 (loss=nan, epoch=18).
2026-01-07 22:55:01,145 [INFO] Step 4030/4740 | Loss: 1.4420 | Acc: 0.4375 | LR: 3.64e-06
2026-01-07 22:55:05,775 [INFO] Step 4040/4740 | Loss: 1.3563 | Acc: 0.5938 | LR: 3.57e-06
2026-01-07 22:55:10,342 [INFO] Step 4050/4740 | Loss: 1.2985 | Acc: 0.6562 | LR: 3.50e-06
2026-01-07 22:55:14,687 [INFO] Step 4060/4740 | Loss: 1.3715 | Acc: 0.5625 | LR: 3.43e-06
2026-01-07 22:55:15,785 [WARNING] Skipping batch due to non-finite loss at step=4062 (loss=nan, epoch=18).
2026-01-07 22:55:18,633 [INFO] Epoch 18 complete | Avg Loss: 1.3245 | Avg Acc: 0.5353 | Updates: 232 | Micro-batches: 237 | Skipped: 5 (loss=5, logits=0, grads=0)
2026-01-07 22:55:18,633 [INFO] Epoch 19/20
2026-01-07 22:55:19,383 [INFO] Step 4070/4740 | Loss: 1.1581 | Acc: 0.6562 | LR: 3.36e-06
2026-01-07 22:55:23,884 [INFO] Step 4080/4740 | Loss: 1.3517 | Acc: 0.5000 | LR: 3.29e-06
2026-01-07 22:55:28,261 [INFO] Step 4090/4740 | Loss: 1.2777 | Acc: 0.4375 | LR: 3.22e-06
2026-01-07 22:55:33,322 [INFO] Step 4100/4740 | Loss: 1.2167 | Acc: 0.5312 | LR: 3.16e-06
2026-01-07 22:55:39,093 [INFO] [EVAL] Step 4100 | Val Loss: 1.2471 | Val Acc: 0.4964
2026-01-07 22:55:43,442 [INFO] Step 4110/4740 | Loss: 1.2981 | Acc: 0.4688 | LR: 3.09e-06
2026-01-07 22:55:47,793 [INFO] Step 4120/4740 | Loss: 1.3136 | Acc: 0.5938 | LR: 3.03e-06
2026-01-07 22:55:50,081 [WARNING] Skipping batch due to non-finite loss at step=4125 (loss=nan, epoch=19).
2026-01-07 22:55:50,735 [WARNING] Skipping batch due to non-finite loss at step=4126 (loss=nan, epoch=19).
2026-01-07 22:55:50,935 [WARNING] Skipping batch due to non-finite loss at step=4126 (loss=nan, epoch=19).
2026-01-07 22:55:51,135 [WARNING] Skipping batch due to non-finite loss at step=4126 (loss=nan, epoch=19).
2026-01-07 22:55:52,388 [WARNING] Skipping batch due to non-finite loss at step=4128 (loss=nan, epoch=19).
2026-01-07 22:55:53,195 [INFO] Step 4130/4740 | Loss: 1.3915 | Acc: 0.5312 | LR: 2.96e-06
2026-01-07 22:55:56,949 [WARNING] Skipping batch due to non-finite loss at step=4138 (loss=nan, epoch=19).
2026-01-07 22:55:57,985 [INFO] Step 4140/4740 | Loss: 1.3748 | Acc: 0.4688 | LR: 2.90e-06
2026-01-07 22:56:02,476 [INFO] Step 4150/4740 | Loss: 1.4231 | Acc: 0.5625 | LR: 2.84e-06
2026-01-07 22:56:07,071 [INFO] Step 4160/4740 | Loss: 1.3247 | Acc: 0.5312 | LR: 2.78e-06
2026-01-07 22:56:11,389 [INFO] Step 4170/4740 | Loss: 1.3780 | Acc: 0.5000 | LR: 2.72e-06
2026-01-07 22:56:15,781 [INFO] Step 4180/4740 | Loss: 1.3934 | Acc: 0.5000 | LR: 2.66e-06
2026-01-07 22:56:19,873 [INFO] Step 4190/4740 | Loss: 1.3234 | Acc: 0.5312 | LR: 2.60e-06
2026-01-07 22:56:24,441 [INFO] Step 4200/4740 | Loss: 1.2166 | Acc: 0.6250 | LR: 2.55e-06
2026-01-07 22:56:30,265 [INFO] [EVAL] Step 4200 | Val Loss: 1.2629 | Val Acc: 0.5000
2026-01-07 22:56:34,586 [INFO] Step 4210/4740 | Loss: 1.3939 | Acc: 0.5625 | LR: 2.49e-06
2026-01-07 22:56:38,873 [INFO] Step 4220/4740 | Loss: 1.2999 | Acc: 0.4688 | LR: 2.43e-06
2026-01-07 22:56:43,218 [INFO] Step 4230/4740 | Loss: 1.4979 | Acc: 0.3438 | LR: 2.38e-06
2026-01-07 22:56:44,733 [WARNING] Skipping batch due to non-finite loss at step=4233 (loss=nan, epoch=19).
2026-01-07 22:56:47,798 [INFO] Step 4240/4740 | Loss: 1.4376 | Acc: 0.5312 | LR: 2.33e-06
2026-01-07 22:56:52,212 [INFO] Step 4250/4740 | Loss: 1.1145 | Acc: 0.5938 | LR: 2.28e-06
2026-01-07 22:56:53,828 [WARNING] Skipping batch due to non-finite loss at step=4253 (loss=nan, epoch=19).
2026-01-07 22:56:57,232 [INFO] Step 4260/4740 | Loss: 1.3839 | Acc: 0.5625 | LR: 2.23e-06
2026-01-07 22:57:01,685 [INFO] Step 4270/4740 | Loss: 1.2431 | Acc: 0.5000 | LR: 2.18e-06
2026-01-07 22:57:06,106 [INFO] Step 4280/4740 | Loss: 1.3738 | Acc: 0.4062 | LR: 2.13e-06
2026-01-07 22:57:10,529 [INFO] Step 4290/4740 | Loss: 1.3197 | Acc: 0.5312 | LR: 2.08e-06
2026-01-07 22:57:13,864 [INFO] Epoch 19 complete | Avg Loss: 1.3134 | Avg Acc: 0.5300 | Updates: 229 | Micro-batches: 237 | Skipped: 8 (loss=8, logits=0, grads=0)
2026-01-07 22:57:13,864 [INFO] Epoch 20/20
2026-01-07 22:57:15,632 [INFO] Step 4300/4740 | Loss: 1.1880 | Acc: 0.6250 | LR: 2.03e-06
2026-01-07 22:57:21,636 [INFO] [EVAL] Step 4300 | Val Loss: 1.2518 | Val Acc: 0.5012
2026-01-07 22:57:26,079 [INFO] Step 4310/4740 | Loss: 1.3427 | Acc: 0.5312 | LR: 1.99e-06
2026-01-07 22:57:29,160 [WARNING] Skipping batch due to non-finite loss at step=4317 (loss=nan, epoch=20).
2026-01-07 22:57:30,471 [INFO] Step 4320/4740 | Loss: 1.4207 | Acc: 0.4375 | LR: 1.94e-06
2026-01-07 22:57:35,092 [INFO] Step 4330/4740 | Loss: 1.3761 | Acc: 0.4375 | LR: 1.90e-06
2026-01-07 22:57:39,472 [INFO] Step 4340/4740 | Loss: 1.3900 | Acc: 0.5000 | LR: 1.85e-06
2026-01-07 22:57:43,814 [INFO] Step 4350/4740 | Loss: 1.2707 | Acc: 0.5938 | LR: 1.81e-06
2026-01-07 22:57:48,547 [INFO] Step 4360/4740 | Loss: 1.4804 | Acc: 0.4375 | LR: 1.77e-06
2026-01-07 22:57:52,955 [INFO] Step 4370/4740 | Loss: 1.3611 | Acc: 0.3750 | LR: 1.73e-06
2026-01-07 22:57:56,781 [WARNING] Skipping batch due to non-finite loss at step=4378 (loss=nan, epoch=20).
2026-01-07 22:57:57,793 [INFO] Step 4380/4740 | Loss: 1.2558 | Acc: 0.5000 | LR: 1.69e-06
2026-01-07 22:58:02,191 [INFO] Step 4390/4740 | Loss: 1.3256 | Acc: 0.5938 | LR: 1.66e-06
2026-01-07 22:58:02,922 [WARNING] Skipping batch due to non-finite loss at step=4391 (loss=nan, epoch=20).
2026-01-07 22:58:07,669 [INFO] Step 4400/4740 | Loss: 1.2792 | Acc: 0.5625 | LR: 1.62e-06
2026-01-07 22:58:13,449 [INFO] [EVAL] Step 4400 | Val Loss: 1.2494 | Val Acc: 0.5084
2026-01-07 22:58:17,783 [INFO] Step 4410/4740 | Loss: 1.1595 | Acc: 0.6562 | LR: 1.58e-06
2026-01-07 22:58:22,234 [INFO] Step 4420/4740 | Loss: 1.3736 | Acc: 0.3750 | LR: 1.55e-06
2026-01-07 22:58:26,904 [INFO] Step 4430/4740 | Loss: 1.2632 | Acc: 0.5625 | LR: 1.52e-06
2026-01-07 22:58:31,466 [INFO] Step 4440/4740 | Loss: 1.1783 | Acc: 0.6250 | LR: 1.48e-06
2026-01-07 22:58:35,905 [INFO] Step 4450/4740 | Loss: 1.2566 | Acc: 0.5625 | LR: 1.45e-06
2026-01-07 22:58:40,346 [INFO] Step 4460/4740 | Loss: 1.3306 | Acc: 0.4688 | LR: 1.42e-06
2026-01-07 22:58:44,980 [INFO] Step 4470/4740 | Loss: 1.2626 | Acc: 0.5312 | LR: 1.39e-06
2026-01-07 22:58:49,335 [INFO] Step 4480/4740 | Loss: 1.4053 | Acc: 0.5625 | LR: 1.36e-06
2026-01-07 22:58:54,058 [INFO] Step 4490/4740 | Loss: 1.1874 | Acc: 0.6875 | LR: 1.34e-06
2026-01-07 22:58:54,289 [WARNING] Skipping batch due to non-finite loss at step=4490 (loss=nan, epoch=20).
2026-01-07 22:58:58,921 [INFO] Step 4500/4740 | Loss: 1.3489 | Acc: 0.5625 | LR: 1.31e-06
2026-01-07 22:59:04,830 [INFO] [EVAL] Step 4500 | Val Loss: 1.2467 | Val Acc: 0.5060
2026-01-07 22:59:04,875 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_step_4500.npz
2026-01-07 22:59:09,361 [WARNING] Skipping batch due to non-finite loss at step=4509 (loss=nan, epoch=20).
2026-01-07 22:59:09,742 [INFO] Step 4510/4740 | Loss: 1.3659 | Acc: 0.5312 | LR: 1.28e-06
2026-01-07 22:59:09,929 [WARNING] Skipping batch due to non-finite loss at step=4510 (loss=nan, epoch=20).
2026-01-07 22:59:14,501 [INFO] Step 4520/4740 | Loss: 1.3321 | Acc: 0.5312 | LR: 1.26e-06
2026-01-07 22:59:18,497 [INFO] Epoch 20 complete | Avg Loss: 1.3095 | Avg Acc: 0.5346 | Updates: 231 | Micro-batches: 237 | Skipped: 6 (loss=6, logits=0, grads=0)
2026-01-07 22:59:24,862 [INFO] Final validation: Loss=1.2597, Acc=0.5060
2026-01-07 22:59:24,908 [INFO] Saved encoder weights (254 arrays) to checkpoints/emotion_v13_higher_lr/encoder_step_4529.npz
2026-01-07 22:59:24,910 [INFO] Training completed in 2352.49s (0.65h)
2026-01-07 22:59:24,910 [INFO] Best validation accuracy: 0.5108
